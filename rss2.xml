<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CH DEVLOG</title>
    <link>https://changhoi.kim/</link>
    
    <atom:link href="https://changhoi.kim/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>개발 과정 기록</description>
    <pubDate>Wed, 02 Nov 2022 15:00:00 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>etcd deep dive - 데이터 모델</title>
      <link>https://changhoi.kim/posts/database/etcd-data-model/</link>
      <guid>https://changhoi.kim/posts/database/etcd-data-model/</guid>
      <pubDate>Wed, 02 Nov 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;etcd 공심 페이지에 가보면 “A distributed, reliable key-value store for the most critical data of a distributed system”라고 설명하고 있다. ZooKeeper와 유사하지만 gRPC를 베이스로 하는 현대적인 코디네이터 역할을 한다. 메타 데이터를 담기 위한 Key-Value 저장소로 사용이 되는 편이고 가장 유명한 활용처는 쿠버네티스가 아닐까 싶다. 최근 사용할 일이 생기고 있어서 깊게 공부해보려고 하나씩 파헤치고 있다. 첫 글은 etcd의 데이터 모델이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>etcd 공심 페이지에 가보면 “A distributed, reliable key-value store for the most critical data of a distributed system”라고 설명하고 있다. ZooKeeper와 유사하지만 gRPC를 베이스로 하는 현대적인 코디네이터 역할을 한다. 메타 데이터를 담기 위한 Key-Value 저장소로 사용이 되는 편이고 가장 유명한 활용처는 쿠버네티스가 아닐까 싶다. 최근 사용할 일이 생기고 있어서 깊게 공부해보려고 하나씩 파헤치고 있다. 첫 글은 etcd의 데이터 모델이다.</p><span id="more"></span><p>etcd는 고맙게도 공식 페이지나 CNCF 발표 영상 등에서 구체적인 디자인들에 대해 여러 방법으로 알려주고 있다. 이번 글은 etcd의 공식 문서의 <a href="https://etcd.io/docs/v3.5/learning/">Learning</a> 섹션에서 제공해주는 etcd data model을 정리한 글이다.</p><hr><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>etcd는 멀티 버전 Key-Value 스토리지이다. 즉, 이전 버전의 키값 쌍을 새 값으로 대체하기 전까지 보존한다. etcd는 여러 버전의 데이터를 효율적이고 불변 데이터 형태로 관리한다. 불변 데이터라고 하면 In-Place 형태로 디스크의 데이터를 업데이트하지 않고 아니라 항상 새로운 버전을 만드는 것을 말한다. In-Place 방식 보다 공간 측면에서는 덜 효율적일 것 같긴 한데 “효율적”이라는 키워드를 사용한 이유는 이후 후술한다. 아무튼 이렇게 과거 버전도 모두 가지고 있게 되므로 특정 키에 대한 과거 버전 데이터들은 나중에도 접근이 가능하고 Watchable 하다. 한편으로는 과거 버전이 무한히 늘어나는 것을 막기 위해 Compaction을 진행하기도 한다.</p><h1 id="Logical-View"><a href="#Logical-View" class="headerlink" title="Logical View"></a>Logical View</h1><p>etcd를 논리적인 측면에서 봤을 때 간단히 말하자면 <strong>바이너리 키 공간</strong>이다. 키는 복수의 <strong>Revision</strong>(<strong>리비전</strong>)을 가지고 있을 수 있다. 리비전은 스토리지의 트랜잭션 번호라고 생각해도 된다. 정수 형태이며 스토어가 세팅되면 초기 리비전 값은 1부터 시작하게 된다. Atomic한 요청 단위(트랜잭션)이 수행될 때마다 새로운 리비전으로 값을 쓰게 된다. 즉, 트랜잭션마다 리비전이 단조 증가하게 된다. 과거의 리비전 역시 스토리지 내에서 일정 기간 보유하고 있어서 실제 쿼리를 통해 접근이 가능하며, 리비전 정보 역시 인덱싱 되어 있어서 특정 리비전을 기준으로 쿼리하거나 Watch 하는 것도 빠르게 처리할 수 있다. 만약 저장소가 압축을 수행하면 압축 이전의 리비전들은 모두 삭제되며 쿼리할 수 없게 된다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ etcdctl compact 5</span><br><span class="line">compacted revision 5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 수동으로 리비전을 압축하면 그 이후 리비전을 기준으로 쿼리할 때 찾을 수 없다는 rpc 에러를 만난다.</span></span><br><span class="line">$ etcdctl get --rev=4 foo</span><br><span class="line">Error:  rpc error: code = 11 desc = etcdserver: mvcc: required revision has been compacted</span><br></pre></td></tr></table></figure><blockquote><p>그러면 리비전 Overflow가 생길 수 있는 건가?라고 생각했는데, 역시나 이런 생각을 한 사람이 있었고 <a href="https://github.com/etcd-io/etcd/issues/11187">이슈</a>에서 찾아볼 수 있었다. 그러나 그러한 걱정은 하덜 말라는 답변. 초당 2만번씩 53억년 동안 Mutation이 발생해야 오버플로우가 발생한다고 한다.</p></blockquote><p>etcd는 단순히 <code>put</code>과 <code>delete</code>로 스토리지 안의 키를 변경한다. 키에 대한 값은 리비전에 대한 정보 뿐 아니라 키의 변경 버전을 기록한다. Protocol Buffer 메시지 타입은 다음과 같이 생겼다.</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">KeyValue</span> </span>&#123;</span><br><span class="line">  <span class="built_in">bytes</span> key = <span class="number">1</span>; <span class="comment">// key in bytes. An empty key is not allowed.</span></span><br><span class="line">  <span class="built_in">int64</span> create_revision = <span class="number">2</span>;</span><br><span class="line">  <span class="built_in">int64</span> mod_revision = <span class="number">3</span>;</span><br><span class="line">  <span class="built_in">int64</span> version = <span class="number">4</span>;</span><br><span class="line">  <span class="built_in">bytes</span> value = <span class="number">5</span>;</span><br><span class="line">  <span class="built_in">int64</span> lease = <span class="number">6</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>키를 생성하면 키의 버전이 증가하는 것과 동일하다. 만약 기존에 해당 키가 존재하지 않았다면 1부터 시작하게 하는 것이고 기존에 해당 키로 이미 값이 존재한다면 그 키에 대해 버전을 올리는 것과 같다. 키를 삭제하는 것은 해당 키에 대한 <strong>Tombstone</strong>을 만들고 해당 키의 버전을 0으로 만드는 것과 같다. 압축이 발생하면 압축 이전의 모든 세대가 제거되고 가장 최근 버전만 남게 된다.</p><p><img src="/images/2022-11-03-etcd-data-model/revision-and-version.png?style=centerme" alt="리비전과 버전"></p><blockquote><p>글에서는 생명 주기로 표현하는데, 굳이 생명 주기라고 할만한 건 없는 것 같다. 그냥 키가 리비전을 통해 여러 버전을 가지고 있을 수 있고 해당 변경 사항들이 불변 데이터처럼 쌓인다는 게 본질적인 내용이다.</p></blockquote><blockquote><p><strong>Tombstone</strong>은 Append Only Log 같은 데이터에서 삭제 표기를 하기 위해 사용하는 데이터이다.</p></blockquote><h1 id="Physical-View"><a href="#Physical-View" class="headerlink" title="Physical View"></a>Physical View</h1><p>실제 구현 레벨에서 etcd는 크게 두 가지 레이어를 통해 스토리지를 구성한다.</p><ul><li>Persistent B+tree</li><li>In-memory B Tree</li></ul><h2 id="Persistent-B-Tree"><a href="#Persistent-B-Tree" class="headerlink" title="Persistent B+Tree"></a>Persistent B+Tree</h2><p>영구 저장소로 B+Tree를 사용하고 있다. B+Tree에 키를 저장할 때 다음과 같이 3개의 튜플로 키를 만들어준다.</p><ul><li><strong>Major</strong>: 해당 키를 들고 있는 Revision을 의미한다.</li><li><strong>Sub</strong>: 같은 리비전 내의 다른 키들과 구분을 위해 사용된다. (아마 개발자가 설정하는 값이 아닐까)</li><li><strong>Type</strong>: 특수한 값을 위한 Optional한 값이다. (ex. tombstone)</li></ul><p>키에 대한 값은 효율성을 위해 이전 리비전과의 차이(<code>delta</code>)만 담고 있다. B+Tree는 키를 단순 Byte Order로 정렬한다. 따라서 특정 리비전으로부터 다른 리비전의 수정 사항을 빠르게 찾을 수 있다. 컴팩션이 발생하면 Outdated Key-Value 쌍은 삭제되는 구조이다.</p><blockquote><p>Compaction은 위에서처럼 수동으로 수행할 수도 있지만 특정 시점마다 컴팩션을 수행하도록 할 수도 있다. Compaction이 키가 사용하는 스토리지 공간을 줄여주는 것은 맞지만, 데이터를 쓰고 지우면서 생기는 단편화 문제를 해결해주지는 않는다. 단편화를 해결하려면 defragmentation(<code>defrag</code> 명령어)을 해줘야 한다. 이 글에서 해당 내용을 깊게 다루지는 않는데 <a href="https://etcd.io/docs/v3.5/op-guide/maintenance/">문서</a>를 참고하면 좋을 것 같다.</p></blockquote><h2 id="In-memory-B-Tree"><a href="#In-memory-B-Tree" class="headerlink" title="In-memory B Tree"></a>In-memory B Tree</h2><p>etcd는 일반적인 데이터베이스들처럼 캐시 레이어를 가지고 있는데, 이 부분이 In-memory B Tree이다. B Tree 인덱스의 키들이 실제 유저들(개발자)에게 노출되는 키이다. 해당 B Tree의 값으로는 키에 대한 Persistent B+Tree의 수정 내역을 가리키는 포인터를 들고 있다. Compaction이 발생하면 삭제되었던 키들(dead pointers)을 삭제하게 된다.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://etcd.io/docs/v3.5/learning/data_model/">https://etcd.io/docs/v3.5/learning/data_model/</a></li><li><a href="https://etcd.io/docs/v3.5/op-guide/maintenance/">https://etcd.io/docs/v3.5/op-guide/maintenance/</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/database/">database</category>
      
      
      <category domain="https://changhoi.kim/tags/distributed-system/">distributed_system</category>
      
      <category domain="https://changhoi.kim/tags/etcd/">etcd</category>
      
      
      <comments>https://changhoi.kim/posts/database/etcd-data-model/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>코드로 인프라 관리하기</title>
      <link>https://changhoi.kim/posts/books/infrastructure-as-code/</link>
      <guid>https://changhoi.kim/posts/books/infrastructure-as-code/</guid>
      <pubDate>Thu, 29 Sep 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;이번년도에도 한빛 미디어의 &lt;strong&gt;나는 리뷰어다&lt;/strong&gt;에 선정되어 매달 책 한 권씩을 읽을 수 있게 됐다. 9월에는 Infrastructure as Code 책을 받아서 보게 되었다. 이 글은 해당 책에 대한 간단한 리뷰이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>이번년도에도 한빛 미디어의 <strong>나는 리뷰어다</strong>에 선정되어 매달 책 한 권씩을 읽을 수 있게 됐다. 9월에는 Infrastructure as Code 책을 받아서 보게 되었다. 이 글은 해당 책에 대한 간단한 리뷰이다.</p><span id="more"></span><p>이 책은 IaC의 아주 폭넓은 관점으로의 학습을 도와주는 책이다. 특정 프레임워크를 가르쳐 주는 느낌은 아니다. 마치 데이터베이스 인터널이라는 책처럼 특정 데이터베이스에 대해 한정된 얘기가 아니라 IaC 라는 것 자체에 대해 가르쳐준다. 장점은 개념 적립과 코어한 컨셉에 대해 학습하기 좋다는 건데, 단점은 이것만으로 IaC를 경험하기는 어려울 것 같다. 이전에 Terraform 이라든지 CloudFormation 등을 사용한 경험이 있는 사람들이 읽어보면 기존 지식과 맞물려 시너지가 있을 것 같다. 책 내용 중에 제일 좋았던 건 인프라 스택을 설계하는 방법에 대해서도 학습할 수 있었다는 점이다. 보통 IaC 관련된 책을 봤을 때는 어떻게 기술을 써야 하는지를 학습하는데 이 책에서는 어떻게 구조를 나눠야 할지 어떤 패턴으로 작성할 수 있는지를 설명해준다. IaC에 대해 어느 정도 지식이 있고 IaC를 더 나은 방식으로 사용하길 원하는 개발자들에게 추천해주고 싶은 책이다.</p>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/books/">books</category>
      
      
      <category domain="https://changhoi.kim/tags/review/">review</category>
      
      
      <comments>https://changhoi.kim/posts/books/infrastructure-as-code/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>클라우드 네이티브 애플리케이션 디자인 패턴</title>
      <link>https://changhoi.kim/posts/books/design-pattern-for-cloud-native-application-review/</link>
      <guid>https://changhoi.kim/posts/books/design-pattern-for-cloud-native-application-review/</guid>
      <pubDate>Sat, 23 Jul 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;이번년도에도 한빛 미디어의 &lt;strong&gt;나는 리뷰어다&lt;/strong&gt;에 선정되어 매달 책 한 권씩을 읽을 수 있게 됐다. 7월 미션으로 나온 책 중에 하나인 &lt;strong&gt;클라우드 네이티브 애플리케이션 디자인 패턴&lt;/strong&gt;을 받게 됐고, 이번 달에 읽어보게 됐다. 이 글은 이 책에 대한 간단한 리뷰이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>이번년도에도 한빛 미디어의 <strong>나는 리뷰어다</strong>에 선정되어 매달 책 한 권씩을 읽을 수 있게 됐다. 7월 미션으로 나온 책 중에 하나인 <strong>클라우드 네이티브 애플리케이션 디자인 패턴</strong>을 받게 됐고, 이번 달에 읽어보게 됐다. 이 글은 이 책에 대한 간단한 리뷰이다.</p><span id="more"></span><p>내가 개발을 시작할 시점부터 이미 클라우드가 활발히 도입되어 있었고, 실제로 내가 개발을 하는 공간 역시 모두 AWS 위에서만 개발했지만, 무엇이 클라우드 네이티브적 특성을 갖는지 알 수 없었다. 이 책을 읽으면서도 뭔가 이게 클라우드와 연관된 것인지 그냥 MSA를 구성하기 위한 여러 방법들을 나열한 것인가 싶었다. 간간히 클라우드 컴포넌트에 대한 명시적인 언급이 있긴 했지만, 보다 어울리는 제목은 MSA 디자인 패턴이 아니었을까 싶다.</p><p>그런 관점에서 이 책은 지식을 넓히기에 적합했다. 굉장히 얇은 느낌으로 이해하고 있던 부분들이 이번 기회에 아주 명확한 표현으로 이해할 수 있었던 것 같다. 현재 실제 업무로 사용하고 있는 사이드카 패턴, BFF, Event Driven 등 개념을 적립하게 도움이 많이 된다. 이 책의 유일한 단점은 책 이름이 책의 일부분에 치중한 느낌이라는 점이고 (이것은 내가 잘 모르기 때문에 이렇게 느끼는 것일 수도 있다고 생각한다.) 특정 규모 이상의 서비스를 만드는 팀에 합류했는데 그곳에서 사용되는 인프라 아키텍처에 대해 생소한 감이 드는 개발자들에게 추천해주고 싶은 책이다.</p>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/books/">books</category>
      
      
      <category domain="https://changhoi.kim/tags/review/">review</category>
      
      
      <comments>https://changhoi.kim/posts/books/design-pattern-for-cloud-native-application-review/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Go Scheduler</title>
      <link>https://changhoi.kim/posts/go/go-scheduler/</link>
      <guid>https://changhoi.kim/posts/go/go-scheduler/</guid>
      <pubDate>Tue, 24 May 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;Go는 많은 것들을 “알아서” 해준다. 그래서 Go는 빌드 또는 실행 옵션이 다른 언어에 비해서 적은 편이다. Go의 가장 핵심적인 부분이라고 할 수 있는 고루틴 역시 Go의 런타임에서 알아서 관리해주고 있다. Go를 사용하면서 Go의 스케줄러를 알고 있어야만 하는 경우는 많지 않지만, 더 잘 쓰기 위해 조금 디테일한 런타임 동작에 대해 알아보자.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>Go는 많은 것들을 “알아서” 해준다. 그래서 Go는 빌드 또는 실행 옵션이 다른 언어에 비해서 적은 편이다. Go의 가장 핵심적인 부분이라고 할 수 있는 고루틴 역시 Go의 런타임에서 알아서 관리해주고 있다. Go를 사용하면서 Go의 스케줄러를 알고 있어야만 하는 경우는 많지 않지만, 더 잘 쓰기 위해 조금 디테일한 런타임 동작에 대해 알아보자.</p><span id="more"></span><h1 id="Go-Runtime-Scheduler"><a href="#Go-Runtime-Scheduler" class="headerlink" title="Go Runtime Scheduler"></a>Go Runtime Scheduler</h1><p>고루틴은 런타임 스케줄러에 의해 관리된다. 아래 원칙을 기준으로 고루틴을 적절히 스케줄링 한다.</p><ul><li>OS Thread는 비싸기 때문에 되도록 적은 수를 유지한다.</li><li>많은 수의 고루틴을 실행해 높은 동시성을 유지한다.</li><li>N 코어의 머신에서 N개의 고루틴이 병렬적으로 동작할 수 있게 한다.</li></ul><p>스케줄러가 동작하는 4가지 이벤트가 있다. 이 이벤트를 마주하면 스케줄러가 동작할 기회를 얻게 된다.</p><ul><li><code>go</code> 키워드를 사용해 새로운 고루틴을 만들고자 할 때</li><li>GC가 동작할 때</li><li>시스템 콜을 사용할 때</li><li>동기화 코드(mutex, atomic, channel)가 동작할 때</li></ul><blockquote><p>GC는 일정 시간마다 트리깅 되도록 되어있기도 하고, 힙 영역을 할당할 때 특정 값을 넘어섰는지 확인하면서 필요한 경우 GC를 트리거 할 수 있다. <a href="https://changhoi.github.io/posts/go/go-gc">링크</a></p></blockquote><h1 id="Goroutine이-관리되는-방식"><a href="#Goroutine이-관리되는-방식" class="headerlink" title="Goroutine이 관리되는 방식"></a>Goroutine이 관리되는 방식</h1><p>Go는 <code>G</code>, <code>M</code>, <code>P</code> 구조체를 가지고 M:N 스레딩 모델을 구현하고 있다. 각각은 다음 의미를 갖고 있다.</p><ul><li>G: Goroutine</li><li>M: Machine (OS Thread)</li><li>P: Processor (고루틴을 동작시키는 가상 프로세서)</li></ul><p>P가 G, M 사이에서 스케줄링 역할을 담당하고 OS Thread가 코드를 동작할 수 있도록 한다. 보통 아래와 같은 이미지로 표현된다.</p><p><img src="/images/2022-05-25-go-scheduler/GMP.png?style=centerme" alt="G, M, P 구조체"></p><h2 id="Goroutine의-상태"><a href="#Goroutine의-상태" class="headerlink" title="Goroutine의 상태"></a>Goroutine의 상태</h2><p>고루틴의 상태는 크게 세 가지로 나눠진다.</p><ol><li><strong>Waiting</strong>: 이벤트 대기 상태. 시스템 콜, 동기화 콜(atomic, mutext, channel)에 의한 정지 상태.</li><li><strong>Runnable</strong>: 실행할 수 있는 상태. M 위에서 돌아가길 원하는 상태이다.</li><li><strong>Executing</strong>: 실행 중 상태. G가 P와 M과 붙어있는 상태를 의미한다.</li></ol><p>위 그림을 확인해보면 Local RunQueue 안에 들어가 있는 고루틴이 <code>Runnable</code> 상태, M과 연결된 고루틴이 <code>Executing</code> 상태라고 볼 수 있다.</p><h2 id="OS-스레드는-필요할-때-만들고-재사용을-위해-남겨둔다"><a href="#OS-스레드는-필요할-때-만들고-재사용을-위해-남겨둔다" class="headerlink" title="OS 스레드는 필요할 때 만들고, 재사용을 위해 남겨둔다."></a>OS 스레드는 필요할 때 만들고, 재사용을 위해 남겨둔다.</h2><p>스케줄러의 목적에 맞게 OS Thread는 최소로 유지된다. 다만 N개의 코어에서 최대 병렬 실행을 위한 수만큼은 생성된다. 그리고 만든 스레드는 스레드 종료 시스템 콜(<code>pthread_exit</code>)을 수행하지 않기 위해 유휴 상태로 남겨둔다. 이를 <code>thread parking</code>이라고 한다. 이렇게 유지되는 스레드를 활용해 빠르게 고루틴을 스레드에 스케줄링할 수 있다.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1. main-goroutine 실행</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"> ...</span><br><span class="line"> <span class="keyword">go</span> g1() <span class="comment">//2. g1-goroutine 실행</span></span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line"> <span class="keyword">go</span> g2() <span class="comment">//3. g1이 완료되고 나서 g2-goroutine 실행되었다고 가정</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>위 코드는 아래와 같이 동작하게 된다.</p><ol><li>메인 고루틴을 제외하고는 다른 고루틴이 없는 상태이므로, 현재 OS 스레드 상태는 <code>m-main</code> 한 개</li><li><code>g1</code> 고루틴을 생성 후 RunQueue에 담는다.<ol><li>런타임은 <code>g1</code>을 실행할 OS Thread인 <code>m1</code> 스레드를 만든다.</li><li>P는 RunQueue에 있는 <code>g1</code>을 <code>m1</code>과 붙여준다.</li><li><code>m1</code>은 <code>g1</code> 프로세스가 종료되더라도 사라지지 않고 Parking(idle) 상태가 된다.</li></ol></li><li>새로 <code>g2</code> 고루틴이 RunQueue에 올라간다. (이 시점에서 <code>g1</code>은 종료되었다고 가정한다. 만약 종료되지 않았다면 <code>m2</code>를 생성하고 붙여주는 위와 동일한 작업을 수행함.)<ol><li>런타임은 Parking 상태인 <code>m1</code>을 Unparking 후 <code>g2</code>를 붙여준다.</li></ol></li></ol><blockquote><p>이때 2-2의 P는 처음 고루틴을 만들고 RunQueue에 담아준 P일 수도 있고, M이 만들어진 다음 새롭게 붙은 P일 수도 있다. 일단 여러 P 구조체가 접근할 수 있는 Global Level의 RunQueue처럼 이해하고, 이후 P의 Work Stealing을 이해한 다음 다시 생각해보자.</p></blockquote><p>그런데 위에 잠깐 언급된 것처럼, 동시 실행되는 고루틴이 아주 많이 생기면 계속해서 OS Thread를 만드는 상황이 생길 수 있다. 이 문제를 해결하기 위해서는 RunQueue가 접근하는 스레드 수를 제한할 필요가 있다.</p><h2 id="스레드-수를-제한한다"><a href="#스레드-수를-제한한다" class="headerlink" title="스레드 수를 제한한다."></a>스레드 수를 제한한다.</h2><p>스레드 수를 제한하지 않으면 스레드를 계속 생성하는 문제가 발생할 수 있다. 그래서 만약 스레드 수 제한에 도달하면 더 이상 스레드를 생성하지 않고 고루틴을 런큐에서 대기하도록 한다. Go에서는 이 제한값을 설정할 수 있는데 <code>GOMAXPROCS</code>라는 환경 변숫값을 사용한다. 최근 버전에서는 이 값이 머신의 CPU 코어 수로 설정되어 있다. 임의로 수정할 수도 있고 런타임에서는 <code>runtime.GOMAXPROCS</code> 함수를 사용해 설정할 수 있다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ GOMAXPROCS=10 go run main.go</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"> runtime.GOMAXPROCS(<span class="number">10</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>예를 들어 <code>GOMAXPROCS</code> 값이 2인 상황에서 <code>g1</code>이 <code>m1</code> 위에서 돌고 있고, <code>g2</code>가 생성되어 RunQueue에 들어가 있는 상황을 생각해보자.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m0 - g0 (메인 고루틴 동작 중) | RQ : [g2]</span><br><span class="line">m1 - g1 (g1 고루틴 동작 중)</span><br></pre></td></tr></table></figure><p>현재 <code>GOMAXPROCS</code> 만큼 M이 있기 때문에 <code>g2</code>는 대기하게 된다. 만약 <code>g0</code> 고루틴에서 동기화 블락이 발생하면 (ex. 동기 채널로 <code>g2</code>가 보낸 데이터를 기다린다든지…) <code>g0</code>은 메인 스레드에서 빠져나오게 되고 <code>g2</code>가 메인 스레드로 가서 실행되게 된다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m0 - g2 (g2 동작 중) | channel wait queue: [g0]</span><br><span class="line">m1 - g1 (g1 동작 중)</span><br></pre></td></tr></table></figure><hr><p>왜 스레드를 조절하는 이름을 꼭 프로세스 조절 이름처럼 만들었을까? 이유는 이 값의 목적은 위에서 말한 것처럼 “OS Thread 수 조절”이 맞지만 실제 동작은 “<strong>가상 프로세서 P 숫자를 제어</strong>“하기 때문이다. 말 그대로 “최대 프로세서 수”라는 뜻이다. 무슨 차이가 있는 걸까?</p><p>위에서 고루틴이 실행 상태이기 위해서는 P와 M이 붙은 상황이어야 한다고 했다. 스케줄러 역할을 해줄 P와 실제 코드를 실행해줄 M이 필요하다는 뜻이다. 즉, 실행 상태인 고루틴은 P의 숫자에 종속적이다. 따라서 스레드 수는 늘어나도 그 스레드 M이 P와 함께 있는 상황이 아니면 코드를 실행할 수 없다는 뜻이다. M과 P가 붙어있을 수 없는 상황은 바로 시스템 콜을 수행 중인 M인 경우이다. 고루틴에서 시스템 콜을 호출해 OS 스레드가 블락되게 되면 해당하는 M과 G는 P 구조체와 분리되고 P는 새로운 M과 연결되면서 RunQueue에 있는 다른 고루틴을 스케줄링한다. 블락된 고루틴은 시스템 콜 작업이 끝나면 RunQueue로 돌아오게 된다. 이렇게 스레드가 블락 되었을 때 P를 M과 G에서 떼어내는 작업을 <code>handsoff</code>라고 한다. 이 특징 덕분에 P가 멈추지 않고 다른 고루틴을 새로운 M에 붙여줄 수 있게 되므로 고루틴이 기아 상태에 빠지지 않도록 해준다.</p><p>고 런타임에서는 블락된 고루틴을 확인하기 위해 백그라운드 모니터 스레드를 별도로 사용하고 있다. 이 스레드는 고루틴들이 블락되는 것을 감지했을 때 유휴 상태 스레드가 없다면 새로운 M을 만들어 P에 붙여주고 만약 유휴 상태의 스레드가 있으면 해당 M과 P를 활성화한다</p><p>이러한 구조때문에 Go는 M:P:N 멀티 스레딩 모델이라고도 불린다.</p><p><img src="/images/2022-05-25-go-scheduler/MPN.png?style=centerme" alt="M:P:N Threading Model"></p><blockquote><p>위 내용은 <code>src/runtime/proc.go</code> 파일의 <a href="https://github.com/golang/go/blob/0a1a092c4b56a1d4033372fbd07924dad8cbb50b/src/runtime/proc.go#L2345"><code>handsoffp</code> 함수</a> 주석에서 자세히 확인할 수 있다.</p></blockquote><p>이런 특징이 코드를 짤 때 어떤 문제를 발생시킬 수 있을까? 우리는 <code>GOMAXPROCS</code>를 가지고 OS Thread 수를 컨트롤할 수 있다고 생각할 수 있지만, 실제로는 그렇지 않다는 점이다. 예를 들어서 파일 100개를 고루틴으로 동시에 열어서 작업을 수행하는 것을 가정해보자. 이 경우 블락된 OS 스레드에서 P를 분리하고 새로운 OS 스레드 M을 만드는 작업을 하므로 이론상 100개가 넘는 스레드가 만들어질 수 있다.</p><p>다음 예시 코드는 100개의 고루틴을 돌려서 파일을 만들고 쓰는 작업을 한다.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> (  </span><br><span class="line">   <span class="string">&quot;fmt&quot;</span>  </span><br><span class="line">   <span class="string">&quot;os&quot;</span>   </span><br><span class="line">   <span class="string">&quot;runtime/pprof&quot;</span>   </span><br><span class="line">   <span class="string">&quot;sync&quot;</span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;  </span><br><span class="line">   threadProfile := pprof.Lookup(<span class="string">&quot;threadcreate&quot;</span>)  </span><br><span class="line">   fmt.Printf(<span class="string">&quot;thread count before start: %d\n&quot;</span>, threadProfile.Count())  </span><br><span class="line">   <span class="keyword">var</span> wg sync.WaitGroup  </span><br><span class="line">   wg.Add(<span class="number">100</span>)  </span><br><span class="line">   <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">100</span>; i++ &#123;  </span><br><span class="line">      <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(n <span class="keyword">int</span>)</span></span> &#123;  </span><br><span class="line">         <span class="keyword">defer</span> wg.Done()  </span><br><span class="line">         filename := fmt.Sprintf(<span class="string">&quot;files/%d-file&quot;</span>, n)  </span><br><span class="line">         f, err := os.Create(filename)  </span><br><span class="line">         <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;  </span><br><span class="line">            <span class="built_in">panic</span>(err)  </span><br><span class="line">         &#125;  </span><br><span class="line">  </span><br><span class="line">         <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;  </span><br><span class="line">            <span class="keyword">if</span> err := f.Close(); err != <span class="literal">nil</span> &#123;  </span><br><span class="line">               fmt.Println(err)  </span><br><span class="line">            &#125;  </span><br><span class="line">  </span><br><span class="line">            err := os.Remove(filename)  </span><br><span class="line">            <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;  </span><br><span class="line">               fmt.Println(err)  </span><br><span class="line">            &#125;  </span><br><span class="line">         &#125;()  </span><br><span class="line">  </span><br><span class="line">         <span class="keyword">var</span> str []<span class="keyword">byte</span>  </span><br><span class="line">         <span class="keyword">for</span> j := <span class="number">0</span>; j &lt; <span class="number">1000</span>; j++ &#123;  </span><br><span class="line">            str = <span class="built_in">append</span>(str, <span class="keyword">byte</span>(j))  </span><br><span class="line">         &#125;  </span><br><span class="line">         _, err = f.Write(str)  </span><br><span class="line">         <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;  </span><br><span class="line">            <span class="built_in">panic</span>(err)  </span><br><span class="line">         &#125;  </span><br><span class="line">  </span><br><span class="line">      &#125;(i)  </span><br><span class="line">   &#125;  </span><br><span class="line">  </span><br><span class="line">   wg.Wait()  </span><br><span class="line">  </span><br><span class="line">   fmt.Printf(<span class="string">&quot;threads count aftre program: %d\n&quot;</span>, threadProfile.Count())  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ go run main.go</span><br><span class="line">thread count before start: 5</span><br><span class="line">threads count aftre program: 77</span><br></pre></td></tr></table></figure><blockquote><p>시스템 콜 중 Non-Blocking I/O를 사용하는 경우가 있다. 가장 대표적으로 네트워크 I/O의 경우에는 epoll을 사용해 Non-Block으로 응답을 대기한다. 이 경우에는 M이 다른 고루틴을 수행할 수 있다. 네트워크 I/O로 블락이 발생한 고루틴은 Net Poller라고 하는 컴포넌트에서 대기하게 된다. Net Poller는 OS의 알림을 받고 고루틴을 다시 RunQueue로(특히, Local RunQueue로) 보낸다.</p></blockquote><hr><h2 id="분산-RunQueue로-Lock-제거"><a href="#분산-RunQueue로-Lock-제거" class="headerlink" title="분산 RunQueue로 Lock 제거"></a>분산 RunQueue로 Lock 제거</h2><p>RunQueue가 Global RunQueue 형태였다면 여러 P에서 고루틴을 가져오기 위해 Lock을 사용해야 한다. Go는 Global RunQueue(GRQ) 역시 사용하기는 하는데 일단 기본적으로 지금까지 설명한 내용은 Local RunQueue(LRQ)를 사용한다. 각 P 구조체마다 RunQueue를 가지고 P와 연결된 스레드의 스택을 최대한 사용한다.</p><p>또한 P가 가지고 있는 G 안에서 새로운 고루틴을 만들게 되면 이 고루틴 역시 해당 P의 LRQ에 들어가게 된다. GRQ가 사용되는 시점은 몇 가지 있지만 대표적으로 LRQ가 가득 찬 상태에서 또 새로운 고루틴을 생성하려고 할 대 GRQ로 들어가게 된다.</p><p>P가 만약 G를 M에 붙이지 않은 상태라면 M은 현재 놀고 있는 스레드라는 뜻이다. 이 상태에 있는 P와 M은 “<strong>Spinning Thread</strong>“라고 한다. 이 상태에서 P는 M에 붙여줄 고루틴을 찾아야 한다. LRQ를 가장 먼저 확인하는데 만약 P가 LRQ에 고루틴을 가지고 있지 않은 상태가 되면 임의의 P의 LRQ에 있는 작업 절반을 훔친다. 이 과정을 Work Stealing이라고 한다. 이 과정을 통해 전체 작업을 고르게 분산할 수 있게 된다. 만약 Work Steal할 대상도 없는 경우에는 GRQ를 바라본다. 그래도 가져올 게 없으면 M과 P는 Parking 된다.</p><p>Work-Stealing은 작업을 고르게 처리하도록 도와주지만, Locality를 떨어뜨린다. 고루틴은 생성 시 사용된 스레드에서 실행되어야 캐시도 활용하고 같은 메모리 스택을 사용하게 되는데 훔쳐지면 이 이점을 살릴 수 없다. 따라서 LRQ의 구조는 단순히 FIFO 구조가 아니라 맨 앞에는 LIFO 형태로 동작하는 버퍼를 사용한다.</p><p><img src="/images/2022-05-25-go-scheduler/LRQ.png?style=centerme" alt="LRQ 버퍼"></p><p>위 이미지처럼 LIFO 버퍼가 비어있는 경우 그 버퍼에 들어가고 만약 새로운 고루틴이 바로 더 들어오면 버퍼에서 밀려 FIFO 큐로 기존 고루틴이 들어가게 되고 새롭게 Enqueue되는 고루틴이 해당 버퍼 자리를 가져간다.</p><p>이 우선순위가 있는 버퍼와 함께 새로운 고루틴이 3ms 가량 Work-Steeling 되지 않는다는 규칙이 있어서 어느 정도 Work-Stealing으로 인한 지역성 저하를 보완한다.</p><h2 id="Fairness"><a href="#Fairness" class="headerlink" title="Fairness"></a>Fairness</h2><p>스케줄링의 굉장히 중요한 요소 중 하나인 공평성이 보장되기 위해 여러 기법을 적용하고 있다. 이러한 특징을 Fairness라고 부른다.</p><ol><li>스레드를 사용하는 고루틴이 10ms 이상 실행되지 않도록 한다. 이 타임 스판을 넘어가면 선점되어 GRQ로 들어가게 된다.</li><li>LRQ의 구조를 보면 2개의 고루틴이 계속 반복적으로 스레드를 독차지할 수도 있는 구조라는 것을 알 수 있다. 이를 방지하기 위해 버퍼에 들어간 고루틴은 스레드를 반납하더라도 타임 스판이 초기화되지 않는다. 따라서 한 고루틴이 이 버퍼를 차지할 수 있는 시간은 10ms이다.</li><li>P 구조체가 고루틴을 찾는 과정이 LRQ, Work-Stealing, GRQ 순서이기 때문에 GRQ의 고루틴이 기아 상태에 빠질 수 있다. 이를 방지하기 위해서 스케줄러는 61번마다 한 번씩 LRQ보다 GRQ를 우선해서 확인한다. 61이라는 숫자는 소수 중 경험적 테스트를 통해 나온 값이라고 한다.</li><li>Net Poller 같은 경우엔 응답을 확인하는 별도의 스레드를 사용한다 이 스레드는 G M P 구조와 별도로 동작하므로 고 런타임에 의한 기아 상태에 빠지지 않는다.</li></ol><blockquote><p>Go 스케줄러는 기본적으로 비선점적 방식이기 때문에 10ms, 3ms 등의 이벤트는 Best-Effort에 해당한다. 완전히 정확한 타이밍으로 동작하는 것은 아니다. 다만 1.12 버전 이후로 무거운 Loop가 돌면서 선점되지 않는 고루틴이 발생하는 것을 막기 위해 선점적 스케줄링 방식이 일부 도입되었다.</p></blockquote><h2 id="고루틴-재활용"><a href="#고루틴-재활용" class="headerlink" title="고루틴 재활용"></a>고루틴 재활용</h2><p>고루틴이 담고 있던 코드 흐름이 모두 완료되고 나면 고루틴을 보관한다.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> p <span class="keyword">struct</span> &#123;</span><br><span class="line"> ...</span><br><span class="line"> <span class="comment">// Available G&#x27;s (status == Gdead)</span></span><br><span class="line">  gFree <span class="keyword">struct</span> &#123;</span><br><span class="line">  gList</span><br><span class="line">  n <span class="keyword">int32</span></span><br><span class="line">  &#125;</span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>위 구조체는 P 구조체인데, <code>gFree</code>에 유휴 상태의 고루틴을 모아둔다. 이 리스트를 유지함으로써 유휴 상태의 고루틴을 저장하거나 뺄 때 Lock같은 동작이 필요 없게 된다.</p><p>더 나은 고루틴 관리와 분배를 위해 스케줄러 자체적으로 글로벌하게 관리하는 리스트 두 개가 있는데, 하나는 재활용이 가능한 스택이 할당된 고루틴을 보관하는 리스트와 스택 재활용이 불가능해 스택을 해제한 고루틴을 보관하는 리스트이다. P가 관리하는 유휴 상태의 고루틴이 64개가 넘어가면 고루틴의 절반이 중앙 리스트로 이동하게 된다. 이때 고루틴이 추가적인 메모리를 할당 받아 2KB보다 큰 메모리 사이즈를 가지고 있는 경우가 재활용 불가능한 고루틴으로 판단되어 메모리를 할당 해제 후 보관하고, 그렇지 않은 경우 스택 메모리도 재활용해 사용한다.</p><hr><p>이렇게 재활용하는 특성은 OS 스레드를 계속 만드는 것처럼 비슷한 문제를 야기할 수 있다. 즉, 고루틴을 계속 만들어내는 문제가 생길 수 있다.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">read</span><span class="params">(wg *sync.WaitGroup, gid <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"> sem &lt;- <span class="keyword">struct</span>&#123;&#125;&#123;&#125; <span class="comment">// semaphore P() (Wait())</span></span><br><span class="line"> processing() <span class="comment">// long process</span></span><br><span class="line"> fmt.Println(<span class="string">&quot;Done&quot;</span>, gid)</span><br><span class="line"> wg.Done()</span><br><span class="line"> &lt;-sem <span class="comment">// semaphore V() (Signal())</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"> <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line"> wg.Add(<span class="number">100</span>)</span><br><span class="line"> <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">100</span>; i++ &#123;</span><br><span class="line">  <span class="keyword">go</span> read(&amp;wg, i)</span><br><span class="line"> &#125;</span><br><span class="line"> wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>위 코드는 일단 고루틴이 생성된 다음 실행 흐름을 판단하기 때문에, 고루틴은 무조건 계속 만들어진다. </p><p><img src="/images/2022-05-25-go-scheduler/many-goroutine.png?style=centerme" alt="많은 고루틴이 만들어진 모습"></p><p>따라서 고루틴이 만들어지는 시점과 흐름을 제어해야 하는 시점을 잘 판단해서 코드를 짜야 한다.</p><h1 id="Overall"><a href="#Overall" class="headerlink" title="Overall"></a>Overall</h1><p>지금까지의 이야기로 다음 이미지를 이해할 수 있게 되었다. 이 이미지를 이해하기 글에서 각 컴포넌트들을 다시 살펴보자</p><p><img src="/images/2022-05-25-go-scheduler/overall.png?style=centerme" alt="전체적인 모습"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://morsmachine.dk/netpoller">https://morsmachine.dk/netpoller</a></li><li><a href="https://ssup2.github.io/theory_analysis/Golang_Goroutine_Scheduling/">https://ssup2.github.io/theory_analysis/Golang_Goroutine_Scheduling/</a></li><li><a href="https://www.youtube.com/watch?v=KBZlN0izeiY&amp;ab_channel=GopherAcademy">https://www.youtube.com/watch?v=KBZlN0izeiY&amp;ab_channel=GopherAcademy</a></li><li><a href="https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html">https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html</a></li><li><a href="https://rakyll.org/scheduler/">https://rakyll.org/scheduler/</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/go/">go</category>
      
      
      <category domain="https://changhoi.kim/tags/programming/">programming</category>
      
      
      <comments>https://changhoi.kim/posts/go/go-scheduler/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>초보를 위한 테라폼</title>
      <link>https://changhoi.kim/posts/etc/terraform-for-newbie/</link>
      <guid>https://changhoi.kim/posts/etc/terraform-for-newbie/</guid>
      <pubDate>Sat, 07 May 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;서비스의 복잡도가 증가하면서 인프라를 어떻게 더 쉽게 관리할 수 있을까에 대한 고민은 지속해서 증가했다. 정적인 상태와 안전한 코드로서 인프라를 관리하고 인프라에서 해야 하는 작업을 확장성있는 방식으로 구성하기 위해 개발자들은 인프라를 코드로써 표현하려고 했다. 이를 IaC (Infra as Code)라고 한다. 현재는 Terraform이 주류를 잡고 있는 듯 하다. 이 글은 IaC에 대한 이야기부터 테라폼의 얕은 이야기를 다룰 예정이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>서비스의 복잡도가 증가하면서 인프라를 어떻게 더 쉽게 관리할 수 있을까에 대한 고민은 지속해서 증가했다. 정적인 상태와 안전한 코드로서 인프라를 관리하고 인프라에서 해야 하는 작업을 확장성있는 방식으로 구성하기 위해 개발자들은 인프라를 코드로써 표현하려고 했다. 이를 IaC (Infra as Code)라고 한다. 현재는 Terraform이 주류를 잡고 있는 듯 하다. 이 글은 IaC에 대한 이야기부터 테라폼의 얕은 이야기를 다룰 예정이다.</p><span id="more"></span><blockquote><p>이번 글은 테라폼이 무엇일지 대략적인 감을 잡기 위한 글이다. <code>tfstate</code>, 협업하는 방법, Best Practice같은 얘기는 이번 글에서 다루지 않는다.</p></blockquote><h1 id="IaC-Infrastructure-as-Code"><a href="#IaC-Infrastructure-as-Code" class="headerlink" title="IaC (Infrastructure as Code)"></a>IaC (Infrastructure as Code)</h1><p>말 그대로 인프라를 코드로 관리하는 방법이다. 이런 구성의 목적은 무엇일까?</p><ul><li><p><strong>재사용성</strong>: 손으로 하던 작업을 코드로 변경하게 되면 대표적으로 바뀌는 점은 반복 가능하다는 점이다. 그리고 코드를 어떻게 짜는지에 따라 다르겠지만, 작은 단위마다 재사용이 가능하다. 예를 들어서 웹 서버를 클러스터 형태로 배포하고 앞에 로드 밸런서를 달아둔다고 해보자. 이 구성은 여러 서비스를 새로 배포할 때마다 몇 가지 설정을 제외하고 모두 같은 과정을 거치게 된다. 만약 코드가 있다면 이 과정을 반복하는 지루한 일을 할 필요 없다.</p></li><li><p><strong>안정성</strong>: 코드를 재사용할 수 있다는 것은 안전한 흐름을 재사용하는 것과 같다. 안전하다는 것은 테스트를 통해 확인할 수 있고, 테라폼 역시 테스트 코드를 만들 수 있다. 어찌 됐든 안전한 작은 흐름을 모아 크고 안전한 흐름을 구성할 수 있게 해준다.</p></li><li><p><strong>가시성</strong>: 가시성이라고 표현할만한지 사실 잘 모르겠지만 코드로 인프라를 구성하는 것은 인프라의 구성을 파악하기 훨씬 쉬워진다고 생각한다. 또한 Orphan이 된 인프라를 손쉽게 제거할 수도 있고, 사람이 보지 못해서 생기는 문제들을 줄여준다.</p></li></ul><p>이외에도 여러 장점이 있겠지만 제일 중요한 포인트는 재사용성인 것 같다. 재사용이 가능하다는 것은 여러 스테이지로 현재 서비스 구성을 복사할 수도 있다는 것을 의미하고, 완전히 동일한 인프라 구성에서 테스트 스테이지를 구성할 수도 있다는 것을 뜻한다. IaC의 장점은 이렇게 쉽게 환경을 만들고 부술 수 있는 능력에 있다고 생각한다.</p><h1 id="IaC-구분"><a href="#IaC-구분" class="headerlink" title="IaC 구분"></a>IaC 구분</h1><p>IaC는 크게 다섯 가지로 구분한다. 애드훅 스크립트, 구성 관리 도구, 서버 템플릿 도구, 오케스트레이션 도구, 프로비전 도구로 나눌 수 있다.</p><h2 id="애드훅-스크립트"><a href="#애드훅-스크립트" class="headerlink" title="애드훅 스크립트"></a>애드훅 스크립트</h2><p>인프라 자동화의 가장 기본적인 방법이고 가장 쉽다. 서버에서 수행할 작업을 스크립트로 구성하고 직접 실행시키는 방법이다. Shell Script 또는 익숙한 코드로 필요한 내용을 작성하고 이를 동작시키는 방식이다. 소규모 인프라에서 일회성 작업이 필요한 경우 아주 적합한 방법이다. 하지만 복잡한 작업을 해야 한다면 결국 새로운 코드 베이스를 만들어 관리하는 형태가 되기 때문에 바람직하지 않다.</p><h2 id="구성-관리-도구"><a href="#구성-관리-도구" class="headerlink" title="구성 관리 도구"></a>구성 관리 도구</h2><p>타겟 서버가 가지고 있어야 하는 소프트웨어를 관리하도록 설계되어있다. 애드훅 스크립트와 비슷한데 인프라 관련된 규칙을 가진 도구이기 때문에 무슨 작업을 하는지 비교적 쉽게 코드로 파악할 수 있다. 애드훅 스크립트와 비교했을 때 가장 큰 차이점은 이 종류에 해당하는 도구들의 대부분이 멱등성을 가지고 있다는 점이다. 쉘 스크립트로 인프라에 대한 멱등성 있는 코드를 작성하는 것은 귀찮은 일이고, 코드도 복잡해진다. 이러한 도구의 가장 대표적인 도구는 <a href="https://www.ansible.com/">앤서블</a>이다.</p><h2 id="서버-템플릿-도구"><a href="#서버-템플릿-도구" class="headerlink" title="서버 템플릿 도구"></a>서버 템플릿 도구</h2><p>말 그대로 서버 구성을 스냅샷화 해서 사용하는 도구이다. 운영체제, 소프트웨어, 파일 및 기타 필요한 모든 상황에 대해 스냅샷을 만들 수 있는 도구이다. 이런 스냅샷은 보통 “이미지”라고 불린다. 서버 템플릿 도구로 만들어진 이미지를 구성 관리 도구를 사용해 서버에 다운받는 방식으로 사용할 수도 있다. 이러한 도구의 가장 대표적인 도구는 <a href="https://www.docker.com/">도커</a>와 <a href="https://www.packer.io/">패커</a>가 있다.</p><blockquote><p>서버 템플릿은 <code>Immutable Infrastructure</code>를 구성하기 위한 핵심적인 요소이다. 한 번 만들어진 스냅샷은 변하지 않고, 새로운 버전을 만들고 싶으면 아예 새로운 스냅샷을 빌드해 배포해야 한다. Snow Flake를 확실히 막는 방법이지만, 아주 작은 변경 사항마다 새 버전을 빌드하고 기존 버전의 서버를 내리는 방식은 조금 무거운 작업일 수 있다.</p></blockquote><h2 id="오케스트레이션-도구"><a href="#오케스트레이션-도구" class="headerlink" title="오케스트레이션 도구"></a>오케스트레이션 도구</h2><p>오케스트레이션은 VM및 컨테이너를 어떻게 관리할지에 관해 관심을 두는 도구이다. 몇 개의 컨테이너가 유지되어야 하는지, 어떤 컨테이너에서 장애가 발생했는지, 어디로 요청을 포워딩해야 하는지 등 여러 서비스 사이의 컨트롤 타워 역할을 한다. 가장 대표적인 도구로는 쿠버네티스가 있다.</p><blockquote><p>쿠버네티스도 IaC라고 할 수 있는 건가? 쿠버네티스는 원하는 상태를 오브젝트로 만들어 피드백 루프를 돌면서 지속해서 바람직한 상태에 있는지 확인하면서 오케스트레이션을 수행한다. 개발자는 이러한 “상태”를 yaml 구성 파일을 가지고 정의한다. 따라서 일종의 IaC라고 볼 수 있다.</p></blockquote><h2 id="프로비전-도구"><a href="#프로비전-도구" class="headerlink" title="프로비전 도구"></a>프로비전 도구</h2><p>구성 관리 도구, 서버 템플릿 도구, 오케스트레이션 도구는 크게 서비스에 대해 주된 관심을 두는 도구들이다. 서버 내부가 어떻게 되어야 하는지 또는 서비스가 어떻게 실행되고 있어야 하는지를 관리하는 도구들이다. 반면 프로비전 도구는 이름처럼 서버 자체를 생성하고 관리한다. 인스턴스의 개수, 인프라 사이의 연결 등 인프라에 대한 모든 것을 프로비저닝 하는 데 사용된다. 테라폼은 대표적인 프로비전 도구다.</p><h1 id="테라폼"><a href="#테라폼" class="headerlink" title="테라폼"></a>테라폼</h1><p>테라폼은 IaC를 위한 선언형 언어이다. 선언형 언어라는 것은 인프라의 상태를 정의하는 코드라는 뜻이다. “프로그래밍 언어”로서 기능을 한다고 생각하는데, 이유는 반복문과 조건절, 함수와 비슷한 모듈의 개념이 있기 때문이다. 테라폼 맛을 한번 보자.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;aws_instance&quot; &quot;example&quot; &#123;</span><br><span class="line"> ami = &quot;ami-something&quot;</span><br><span class="line"> instance_type = &quot;t3.micro&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource &quot;google_dns_record_set&quot; &quot;a&quot; &#123;</span><br><span class="line"> name = &quot;demo.google-example.com&quot;</span><br><span class="line"> managed_zone = &quot;example_zone&quot;</span><br><span class="line"> type = &quot;A&quot;</span><br><span class="line"> ttl = 300</span><br><span class="line"> rrdatas = [aws_instance.example.public_ip]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>AWS에서 인스턴스를 만들고 GCP에서 AWS 서버에 접속할 IP를 DNS 레코드에 넣는 작업이다. 모르는 사람이 봐도 대충 이렇겠구나 싶은 느낌이 오는 정도의 가독성을 가지고 있다.</p><h2 id="핵심적인-테라폼-흐름"><a href="#핵심적인-테라폼-흐름" class="headerlink" title="핵심적인 테라폼 흐름"></a>핵심적인 테라폼 흐름</h2><p>테라폼의 핵심적인 흐름은 다음 구성을 가지고 있다.</p><ul><li><strong>Write</strong>: 테라폼 코드를 적는 단계. 어떤 리소스들이 어떤 방식으로 구성되어있는지 선언하는 단계이다.</li><li><strong>Plan</strong>: 실제 인프라에 적용하기 전에 어떻게 변화가 생기는지 확인하는 단계이다.</li><li><strong>Apply</strong>: 인프라에 실제로 의도한 대로 변화를 가하는 단계이다.</li></ul><p>Write 단계에서는 테라폼의 문법대로 <code>tf</code> 확장자의 파일을 구성하는 방식이다. Plan은 이렇게 구성한 테라폼 파일들의 실행 계획을 확인하는 단계이다. <code>terraform plan</code>이라는 명령어를 사용한다. Apply는 위 계획대로 인프라에 적용하는 단계이다. <code>terraform apply</code> 명령어로 수행한다.</p><blockquote><p>Plan 단계에서 문제없이 실행될 것처럼 보여도 실제 Apply 단계에서 문제가 발생할 수도 있다. 예를 들어 변경하려고 하는 S3 버킷의 이름이 이미 있는 이름이라든지, 여러 이유가 있을 수 있다.</p></blockquote><p><img src="https://mktg-content-api-hashicorp.vercel.app/api/assets?product=terraform&version=refs/heads/stable-website&asset=website/img/docs/intro-terraform-workflow.png" alt="테라폼 단계"></p><blockquote><p>테라폼 코드를 작성하거나 팀이 이미 작성한 테라폼 코드를 가져온 다음 테라폼 코드가 실행될 수 있도록 초기화해주는 단계가 있다. <code>terraform init</code> 명령어인데, 이 과정에서 테라폼을 실행하기 위해 필요한 플러그인을 설치하기도 하지만 신경 써야 하는 점은 테라폼 백앤드를 설정하는 과정이다. 기본은 로컬에서 동작하지만, 이는 팀과 함께 작업하기에는 부적합하다. <a href="https://www.terraform.io/cli/commands/init"><code>init</code> 명령어가 하는 역할</a>과 협업 과정에서 백앤드 초기화하기 위한 좋은 방법을 <a href="https://www.terraform.io/intro/core-workflow#working-as-a-team">이 링크</a>에서 확인해보자.</p></blockquote><h2 id="Syntax-구성-요소"><a href="#Syntax-구성-요소" class="headerlink" title="Syntax 구성 요소"></a>Syntax 구성 요소</h2><p>테라폼의 문법적 요소를 구성하는 키워드와 규칙이 크게 두 가지 있다. 하나는 <code>Argument</code>, 다른 하나는 <code>Block</code>이다.</p><h3 id="Argument"><a href="#Argument" class="headerlink" title="Argument"></a>Argument</h3><p>특정한 식별자에 할당된 값을 의미한다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image_id = &quot;1234&quot;</span><br></pre></td></tr></table></figure><p>등호를 기준으로 좌측이 식별자, 우측이 표현 식이다. 프로그래밍 언어처럼 그냥 리터럴한 값이 올 수도 있지만, 프로그램에 의해 결정되는 표현 식이 오기도 한다. Argument는 특정 컨텍스트 안에서 유효성이 결정된다. 즉, 어떤 컨텍스트 안에 속해있는지에 따라 타입, 식별자 이름 등이 유효한지 아닌지 판단된다.</p><h3 id="Block"><a href="#Block" class="headerlink" title="Block"></a>Block</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;aws_instance&quot; &quot;example&quot; &#123;</span><br><span class="line">  ami = &quot;ami-id&quot;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>위 <code>&#123; ... &#125;</code> 부분이 블록이다. 블록은 타입을 가지고 있는데 위 예시의 타입은 <code>resource</code>라는 타입이다. <code>resource</code> 타입에서는 두 가지의 라벨을 기대하고 있다. 하나는 <code>aws_instance</code>와 같이 정해진 리소스 이름이고 다른 하나는 <code>example</code>과 같이 임의로 정하는 식별자 이름이다. 지금 당장 <code>resource</code> 타입에 대해 설명하고자 하는 것은 아니니 블록에는 라벨이 붙을 수도 있고 아닐 수도 있다는 점만 알고 있자. 블록 내부와 라벨은 어떤 타입의 블록 컨텍스트인지에 따라 달라진다.</p><h2 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h2><p>테라폼은 <code>tf</code> 확장자를 가진 파일들로 만들어진다. 이 파일들이 모여 모듈이 구성되는데 모듈의 기준은 디렉토리이다. 같은 디렉토리 안에 모여있는 <code>tf</code> 파일들이 모두 모듈로 활용된다. 어떤 디렉토리의[ 하위에 위치하더라도 그 둘은 다른 모듈이다.</p><p>테라폼이 실행되는 모듈은 하나뿐이다. 이 모듈을 “<strong>루트 모듈</strong>“(<strong>Root Module</strong>)이라고 한다. 그리고 이 모듈에서 사용하는 다른 디렉토리에 위치한 모듈들을 “<strong>자식 모듈</strong>“(<strong>Child Module</strong>)이라고 부른다.</p><p>모듈은 테라폼의 함수와 같은 역할을 해준다. 작은 단위로 나누고 테스트하고 확장성 있게 만들어서 여러 스테이지에서 반복되는 코드를 쓸 필요 없도록 해준다. 구체적으로 자식 모듈을 가져와 사용하는 예시는 이후 후술한다.</p><h2 id="Provider"><a href="#Provider" class="headerlink" title="Provider"></a>Provider</h2><p>Provider는 인프라를 제공하는 클라우드 혹은 오픈 스택과 같은 인프라 차원의 API 종류를 정하는데 사용하는 블록 타입이다. 제공하는 벤더에 따라 테라폼이 실행할 때 다운로드 해 오는 코드가 달라진다. Provider는 실행하고자 하는 루트 모듈에만 있으면 된다. 자식 모듈은 실행하는 루트 모듈의 프로바이더 정보를 사용한다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">provider &quot;aws&quot; &#123;</span><br><span class="line">  profile = &quot;terraform&quot;</span><br><span class="line">  region = &quot;ap-northeast-2&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>위 코드는 AWS를 사용하겠다는 것을 의미한다. <code>provider</code> 블록은 정해진 벤더사의 이름을 넣어야 하는 라벨을 요구한다. 그리고 블록 안에서는 필수적인 Argument들이 있을 수 있다.</p><p>테라폼은 정말 많은 프로바이더를 가지고 있다. <a href="https://registry.terraform.io/browse/providers">이 링크</a>에서 확인해볼 수 있다.</p><h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p>테라폼은 인프라를 다루는 언어인 만큼 인프라 리소스를 정의할 수 있는 블록이 필요하다. 이 역할을 <code>resource</code> 타입이 해준다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;aws_instance&quot; &quot;web&quot; &#123;</span><br><span class="line">  ami = &quot;ami-id&quot;</span><br><span class="line">  instance_type = &quot;t3.small&quot;a</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>위에서 예시로도 사용됐는데, 두 가지의 라벨을 요구하는 블록 타입이다. 하나는 리소스 종류를 정해야 하고, 그다음 나오는 라벨은 로컬 네임이다. 로컬 네임은 테라폼 모듈 안에서 해당하는 리소스를 참조하기 위해 사용된다. 다른 모듈에서 같은 이름이 나오는 것은 상관없다. 리소스가 무엇이냐에 따라 안에 Argument들도 달라진다. AWS를 생각해보면 정말 수많은 리소스 종류가 있기 때문에 어떻게 작성해야 하는지를 일일히 외울 수는 없다. 공식문서에서 프로바이더마다 제공하는 리소스와 어떻게 테라폼 리소스 코드를 써야 하는지 알려주는 문서를 확인하면서 코드를 써야 한다. AWS의 경우 <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs">이 링크</a>를 통해 알 수 있다.</p><h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><p>테라폼 외부의 데이터를 사용하기 위한 타입이다. 여기서 외부라는 말은 분리된 다른 테라폼의 설정이라든지, 인프라 내에서 변경되는 값들을 의미한다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data &quot;aws_ami&quot; &quot;example&quot; &#123;</span><br><span class="line">  most_recent = true</span><br><span class="line">  owner = [&quot;self&quot;]</span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name = &quot;app-server&quot;</span><br><span class="line">    Tested = &quot;true&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>위 데이터 블록은 테라폼에게 <code>aws_ami</code>를 읽어와서 <code>example</code>이라는 이름으로 필요한 정보를 읽을 수 있게 해준다. 예를 들어 테라폼에 DB를 생성한 다음 만들어지는 주소를 웹서버에게 넘겨주기 위해 사용할 수 있다. 데이터 블록 안의 Argument들은 데이터 블록의 쿼리를 만들어주는 역할을 한다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data &quot;aws_vpc&quot; &quot;default&quot; &#123;</span><br><span class="line">  default = true</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data &quot;aws_subnet_ids&quot; &quot;default&quot; &#123;</span><br><span class="line">  vpc_id = data.aws_vpc.default.id</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>위 예시 코드는 기본 VPC를 가져와서 <code>data.aws_vpc.default</code>에서 참조할 수 있게 하는 데이터 블록을 만들고 그 블록을 사용해 해당 VPC 안에 있는 서브넷들을 가져오는 코드이다. 서브넷들은 마찬가지로 <code>data.aws_subnet_ids.default</code>로 참조할 수 있다.</p><h2 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h2><p>확장적인 인프라 모듈을 위해서는 적절한 변수들이 활용되어야 한다. 100개의 인스턴스 이름을 바꾸는 작업에 단순 작업이 필요하다면 확장이 어려운 것으로 볼 수 있다. 임의의 변수를 설정하는 것은 <code>variable</code>이라는 변수 타입으로 만들 수 있다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">variable &quot;server_port&quot; &#123;</span><br><span class="line">  description = &quot;The port for HTTP requests.</span><br><span class="line">  type = number</span><br><span class="line">  default = 8080</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">variable &quot;alb_name&quot; &#123;</span><br><span class="line">  description = &quot;The name of the ALB&quot;</span><br><span class="line">  type = string</span><br><span class="line">  default = &quot;terraform-asg&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>이 변수는 모듈에 대한 <code>input</code>이다. 루트 모듈이 자식 모듈을 불러올 때 변수를 지정할 수도 있고, 루트 모듈을 실행할 때 환경 변수 및 실행할 인자 값 등으로 넣어줄 수 있다. 만약 위 예시처럼 기본값이 정해져 있다면 따로 넣어줄 필요 없다.</p><p>위 예시에서는 <code>server_port</code>, <code>alb_name</code>이라는 이름을 모듈 안에서 <code>var.&lt;name&gt;</code> 형태로 사용할 수 있다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;alb_something&quot; &quot;example&quot; &#123;</span><br><span class="line">  port = var.server_port</span><br><span class="line">  name = &quot;$&#123;var.alb_name&#125;-cluster-lb&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h2><p>함수처럼 사용할 수 있으려면 반환 값도 필요하다. 모듈의 결과를 내보낼 수 있는 블록이 있는데, 이 블록이 <code>output</code>이다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">output &quot;asg_name&quot; &#123;</span><br><span class="line">  value = aws_autoscaling_group.example.name</span><br><span class="line">  description = &quot;The name of the ASG&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>aws_autoscaling_group.example.name</code>은 모듈 안에 있는 ASG 리소스 중 <code>example</code>이라는 식별자가 붙은 것의 이름을 의미한다. 다른 모듈에서 이 변수를 사용한다면 다음과 같이 사용하게 된다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">module.[module_name].[output_name]</span><br><span class="line">module.webclusters.asg_name</span><br></pre></td></tr></table></figure><h2 id="반복문"><a href="#반복문" class="headerlink" title="반복문"></a>반복문</h2><p>선언적 언어는 절차적인 유형의 작업을 처리하기 어렵다. 반복, 조건문 등을 지원하지 않는 경우가 많이 있다. 테라폼에서는 루프를 지원해서 이런 상황에서 사용이 가능하다. 테라폼은 다음과 같은 루프가 있다. </p><ul><li><code>for_each</code>: 리소스 내에서 리소스 또는 인라인 블록을 반복한다.</li><li><code>for</code>: 리소스와 맵 타입을 반복한다.</li><li><code>count</code>: 리소스를 지정한 수만큼 반복한다.</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">variable &quot;aws_iam_user&quot; &#123;</span><br><span class="line"> description = &quot;IAM users with these names&quot;</span><br><span class="line"> type = list(string)</span><br><span class="line"> default = [&quot;neo&quot;, &quot;trinity&quot;, &quot;morpheus&quot;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource &quot;aws_iam_user&quot; &quot;example&quot; &#123;</span><br><span class="line"> count = length(var.aws_iam_user)</span><br><span class="line"> name = var.aws_iam_user[count.index]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><code>length</code>는 내장함수이다. 여러 내장 함수가 있으므로 <a href="https://www.terraform.io/language/functions">이 링크</a>에서 학습하는 것을 추천한다.</p></blockquote><p><code>count</code>는 <code>index</code>를 통해 순회한다. 위 예시는 <code>aws_iam_user</code> 리소스를 콜렉션의 길이만큼 반복한다.</p><p><code>count</code>를 사용할 때는 다음과 같은 제약이 생긴다.</p><ul><li>리소스 안에서 특정 인라인 블록을 반복할 수는 없다. 인라인 블록은 태그나, 로컬 변수 등 블록 안에서 만들어지는 블록을 의미한다.</li><li>배열의 인덱스대로 처리한다. 만약 위 예시에서 <code>trinity</code>를 지운다면, 기존 IAM 중에서 <code>morpheus</code>를 지우고 <code>trinity</code>의 이름을 <code>morpheus</code>로 변경한다.</li></ul><blockquote><p><code>for</code>, <code>for_each</code>에 대한 설명은 이 글에서 하지 않았다. 구체적인 타입에 대한 설명과 몇 가지 내장 함수들을 설명해야 하는데, 글의 취지와 적합하지 않은 듯 하여 뺐다. 자세한 설명은 <a href="https://www.terraform.io/language/expressions/conditionals">이 링크</a>를 읽자.</p></blockquote><h2 id="조건문"><a href="#조건문" class="headerlink" title="조건문"></a>조건문</h2><p>조건문은 아쉽지만 삼항 연산자로만 표현해야 한다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">condition ? true : false</span><br></pre></td></tr></table></figure><p>위와 같이 조건이 맞으면 앞의 값을 사용하고 틀리면 뒤의 값을 사용한다. 리소스를 생성할지 말지를 결정하는 것은 <code>count</code>를 함께 사용해 구성할 수 있다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;something&quot; &quot;something&quot; &#123;</span><br><span class="line"> count = var.some_boolean ? 1 : 0</span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>만약 <code>var.some_boolean</code> 값이 <code>true</code>라면 이 리소스는 생성될 것이고 그렇지 않으면 생성되지 않는다.</p><h1 id="Usecase"><a href="#Usecase" class="headerlink" title="Usecase"></a>Usecase</h1><p>지금까지의 내용을 통해 테라폼이 어떤 느낌의 언어인지 파악할 수 있다. 선언형 언어라는 점, 프로그래밍 언어적 특성들을 어떤 방식으로 제공하고 있는지 등. 테라폼의 모든 내용을 이 글에서 배우기는 어렵고, 더 자세한 내용은 테라폼의 공식 문서가 굉장히 잘 정리해주고 있으니 참고해서 학습할 수 있다. 테라폼을 사용한 조금 구체적인 활용 예시는 다음과 같다.</p><ul><li>테라폼을 사용하면 인프라에 대한 테스트 코드를 작성할 수 있게 된다. 그렇게 되면 안정적인 인프라 구성을 할 수 있게 된다.</li><li>Stage를 분리하려고 할 때 동일한 상태를 간단하게 복사할 수 있다. 테스트 환경을 제거하는 방법도 <code>destory</code> 명령으로 간단히 해결할 수 있다.</li><li>테라폼으로 인프라를 관리함으로써 제거해야 하는 리소스를 빼먹고 남겨두는 상황을 최소화할 수 있다. 적어도 테라폼으로 삭제하지 못하게 되면 어떤 리소스가 왜 삭제되지 않았는지 파악할 수도 있다.</li></ul><hr><p>이 글로도 사실 테라폼이 어떤 건지 쉽게 감을 잡기 어려울 수 있다. 개인적인 생각으로는 직접 Example을 따라 해본다면 쉽게 이해할 수 있고, 프로그래밍 관점에서 테라폼을 바라볼 때 이 글이 도움이 될 수 있을 것 같다.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://www.terraform.io/cli/commands/init">https://www.terraform.io/cli/commands/init</a></li><li><a href="https://www.terraform.io/intro/core-workflow#working-as-a-team">https://www.terraform.io/intro/core-workflow#working-as-a-team</a></li><li><a href="https://learning.oreilly.com/library/view/terraform-up/9781492046899/">https://learning.oreilly.com/library/view/terraform-up/9781492046899/</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/etc/">etc</category>
      
      
      <category domain="https://changhoi.kim/tags/terraform/">terraform</category>
      
      <category domain="https://changhoi.kim/tags/iac/">iac</category>
      
      <category domain="https://changhoi.kim/tags/devops/">devops</category>
      
      
      <comments>https://changhoi.kim/posts/etc/terraform-for-newbie/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>DynamoDB Internals (2) - DynamoDB</title>
      <link>https://changhoi.kim/posts/database/dynamodb-internals-2/</link>
      <guid>https://changhoi.kim/posts/database/dynamodb-internals-2/</guid>
      <pubDate>Mon, 18 Apr 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;a href=&quot;/posts/database/dynamodb-internals-1/&quot;&gt;지난 글&lt;/a&gt;에서 DynamoDB를 지탱하는 큰 축인 Dynamo 시스템에 대해서 알아봤다. Dynamo 시스템은 DynamoDB가 등장하기 한참 전에 설계되었지만 이름에서 쉽게 알 수 있듯 굉장히 깊은 부분을 공유하고 있다. 그러나 DynamoDB는 관리형 인프라 서비스로 제공되는 만큼 사람들이 더 쉽고 범용적으로 사용할 수 있게 설계되었다. 구체적으로 어떻게 어떤 점이 다른지 알아보자.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><a href="/posts/database/dynamodb-internals-1/">지난 글</a>에서 DynamoDB를 지탱하는 큰 축인 Dynamo 시스템에 대해서 알아봤다. Dynamo 시스템은 DynamoDB가 등장하기 한참 전에 설계되었지만 이름에서 쉽게 알 수 있듯 굉장히 깊은 부분을 공유하고 있다. 그러나 DynamoDB는 관리형 인프라 서비스로 제공되는 만큼 사람들이 더 쉽고 범용적으로 사용할 수 있게 설계되었다. 구체적으로 어떻게 어떤 점이 다른지 알아보자.</p><span id="more"></span><blockquote><p>특정 <a href="https://www.youtube.com/watch?v=yvBR71D0nAQ">영상</a>에서 “Dynamo와 다르게 ~ “라고 하면서 특정 컴포넌트가 어떻게 다른지 설명하는 부분은 있지만, 공식적인 텍스트로 차이점에 대해 명시한 문서는 찾지 못했다. 다만 공부하면서 ‘이 부분은 이런 방법으로 변경했구나’ 같은 느낌을 많이 받을 수 있었는데, 이런 포인트에 집중해서 글을 쓰려 노력했다. 본인의 의견에 해당하는 경우 의견임을 명시했고 그 외는 Reference의 도큐먼트 또는 AWS re:Invent 영상을 참조했다.</p></blockquote><blockquote><p>글에서 DynamoDB와 Dynamo를 명확히 구분한다. Dynamo는 DynamoDB의 기반이 되는 분산 스토리지 시스템을 의미한다. 이전 글을 참고하자.</p></blockquote><h1 id="기본적인-이야기"><a href="#기본적인-이야기" class="headerlink" title="기본적인 이야기"></a>기본적인 이야기</h1><p>이 글을 읽고 있다면 DynamoDB의 기본적인 이야기에 대해서는 이미 알고 있을 확률이 높으므로, <a href="#Key-amp-Partition">다음 섹션</a>부터 읽어도 좋다.</p><h2 id="Item-Attribute-Primary-Key"><a href="#Item-Attribute-Primary-Key" class="headerlink" title="Item, Attribute, Primary Key"></a>Item, Attribute, Primary Key</h2><p>DynamoDB는 Key Value Storage NoSQL이다. Redis처럼 키값에 따라 데이터가 매칭이 되고, 해당 데이터의 스키마가 정해지지 않고 자유롭다. 하나의 데이터, 즉, RDB에서 하나의 로우라고 부를 수 있는 것을 DynamoDB에서는 아이템(Item)이라고 부른다. 이 아이템은 속성(Attribute)값으로 이루어져 있다.</p><p>Attribute가 가질 수 있는 값은 아래와 같다.</p><ul><li>Number (N)</li><li>String (S)</li><li>Boolean (BOOL)</li><li>Binary (B)</li><li>List (L)</li><li>Map (M)</li><li>String Set (SS)</li><li>Number Set (NS)</li><li>Binary Set (BS)</li></ul><p>Number, String, Boolean, Binary 같은 단순한 타입도 있지만, List, Set, Map과 같은 복합 타입도 존재한다. 이 값들을 읽고 쓰는 동작들은 모두 Atomic 하게 전달된 순서대로 동작한다.</p><blockquote><p>위 리스트의 괄호로 쳐진 값은 Attribute를 지정할 때 사용하는 코드이다. 직접 사용하다 보면 이해하기 쉽다.</p></blockquote><p>아이템의 스키마가 정해지지 않았다는 것은 아이템마다 자유롭게 속성값을 바꿀 수 있다는 것을 의미하는데, 예외가 존재한다. DynamoDB에서 테이블을 구성할 때 설정하는 Primary Key가 바로 그 예외이다. 이 값은 아이템을 식별하는 키 역할을 한다. 따라서 모든 아이템에서 Non-Nullable한 값이다.</p><p>이 키를 구성하는 방법은 기본적으로 2가지가 있다. 하나는 간단하게 <strong>Partition Key</strong>(파티션 키, PK, Hash Key)만 사용하는 것과 다른 하나는 PK와 함께 <strong>Sort Key</strong>(소트 키, SK, Range Key)를 함께 사용하는 것이다.</p><blockquote><p>이 글에서 PK는 모두 Partition Key를 의미하고, Primary Key는 줄여 쓰지 않았다.</p></blockquote><p>위 두 키를 제외하고는 쿼리를 할 수 있는 방법이 기본적으로는 없다. 만약 일반 Attribute를 가지고 필터링하려면 Scan을 사용해야 한다. 따라서 굉장히 디테일하게 애플리케이션에서 사용하는 쿼리 패턴에 대해 이해하고 키값을 설계해야 한다. DynamoDB를 설계하는 방법으로 가장 유명한 방법은 Single Table Design이 있다. 이는 과거에 한 번 <a href="/posts/database/dynamodb-single-table-design/">소개한 바</a> 있다.</p><blockquote><p>RDB에서도 키를 사용하지 않으면 Scan을 하는 것은 마찬가지이다. 하지만 RDB는 필요에 따라 인덱스를 쉽게 추가할 수 있지만 DynamoDB의 경우엔 제약 조건도 있고, 고민해야 할 포인트가 몇 가지 있다.</p></blockquote><h2 id="Secondary-Index"><a href="#Secondary-Index" class="headerlink" title="Secondary Index"></a>Secondary Index</h2><p>기본 키만으로 필요한 쿼리를 모두 할 수 없는 경우가 많기 때문에, 추가로 두 종류의 보조 인덱스를 지원한다.</p><ul><li>Local Secondary Index (LSI)</li><li>Global Secondary Index (GSI)</li></ul><p>LSI의 경우 테이블을 생성할 때 만드는 기본 인덱스를 가진 테이블(이하 베이스)과 동일한 PK를 사용해야 한다는 제약 조건이 있다. SK만을 설정할 수 있으며, 베이스가 만들어질 때만 설정할 수 있다. 테이블이 이미 운영 중인 경우엔 LSI를 추가할 수 없다. 장점으로는 GSI와 다르게 강력한 읽기 일관성을 제공한다는 점이다. 읽기 일관성에 대해 자세히 모른다면, 이하 글 내용에서 대략 알 수 있다.</p><p>LSI를 굳이 사용해야 하는 케이스는 별로 없다. 강력한 읽기 일관성이 제공되고, GSI보다 비교적 싸게 운영할 수 있다는 장점이 있지만, 파티셔닝에 제약 사항(PK값이 같은 아이템들의 크기의 합이 파티션의 최대 사이즈보다 커질 수 없다는 점)이 생기기도 하고, 생성 시점이 정해져 있다는 점 역시 큰 장애물이다. 공식 문서에서도 GSI 유즈 케이스가 더 많다고 설명하고 있다.</p><blockquote><p>강력한 읽기 일관성이 필요한 경우엔 DynamoDB 자체가 그다지 좋은 선택지가 아닐 수 있다. 일관성이 중요한 애플리케이션은 RDB를 사용하는 것이 일반적으로 더 좋은 선택일 것 같다.</p></blockquote><p>GSI의 경우 LSI와 다르게 파티셔닝의 제약도 붙지 않고, PK를 아예 별도로 설정할 수 있다. 또한 테이블이 생성된 이후에도 자유롭게 GSI를 설정할 수 있다. 다만 강력한 읽기 일관성을 제공하지 않고, 쓰기 읽기 용량을 새로 생성해야 하므로 추가적인 비용이 든다.</p><blockquote><p>LSI는 공짜라는 건 아니다. 베이스의 읽기 쓰기 용량을 공유하게 된다.</p></blockquote><h1 id="Key-amp-Partition"><a href="#Key-amp-Partition" class="headerlink" title="Key &amp; Partition"></a>Key &amp; Partition</h1><p>파티션 키는 테이블 안에서 아이템이 어떤 파티션에 속하는지를 결정하는 키다. 해시 함수를 가지고 키를 해시한 다음 해시값을 이용해 각 파티션으로 분할한다. SK는 파티션 안에서 아이템을 정렬하는 용도로 사용된다. 각 파티션의 최대 사이즈는 10GB로, 만약 파티션 키에 속하는 아이템이 10GB가 넘는다면 SK를 기준으로 파티션을 분할한다. 아이템은 400KB가 최대 사이즈이기 때문에 각 파티션마다 최소 25,000개 정도의 아이템을 담을 수 있다.</p><p><img src="/images/2022-04-19-dynamodb-internals-2/simple-get-item.png?style=centerme" alt="해시 함수를 통해 파티션을 선택"><br><small><a href="https://www.alexdebrie.com/posts/dynamodb-partitions/">이미지 출처</a></small></p><blockquote><p>SK가 없는 경우 PK가 같은 아이템이 테이블마다 하나씩 있을 수 있고, 아이템은 400KB 사이즈 제한이 있기 때문에 파티션 안에서 아이템 컬렉션(PK가 같은 아이템의 모음)이 10GB가 넘을 수 없다.</p></blockquote><blockquote><p>LSI가 설정된 테이블은 위에서 말한 것처럼 10GB 이상의 아이템 컬렉션을 유지할 수 없다. 이 값은 꽤 큰 값이고 PK를 애플리케이션에서 잘 나누면 해결할 수 있는 문제이지만, 아무튼 이런 찜찜한 제약이 생긴다.</p></blockquote><p>각 파티션은 읽기 용량과 쓰기 용량을 설정할 수 있다. On Demand 방식으로 설정한다면 들어오는 처리량을 적절히 받아주겠지만 가격이 비싸진다. 예측 불가능할 정도로 성장하는 서비스가 아니라면 보통 예측치를 기반으로 Read Capacity Unit(RCU), Write Capacity Unit(WCU)를 설정한다. 보내는 요청이 어떤 것인지(일관적인 읽기, 트랜잭션 쓰기 등)에 따라 다르지만, RCU 한 개는 기본 읽기의 경우 4KB 아이템 사이즈 기준 초당 2개의 아이템을 읽을 수 있고 WCU 한 개는 1KB 아이템을 초당 한 개 쓸 수 있다.</p><blockquote><p>On Demand 방식과 Auto Scaling에 대해서는 이 글에서 다루고 있지 않다. 간단히 설명하자면 Auto Scaling은 배달앱처럼 “점심시간에 높은 트래픽을 찍고 평시에는 낮다” 처럼 범위에 대한 이해가 있는 애플리케이션에 대해 해당 범위에 맞춰서 처리 용량을 늘이고 줄이는 설정이다. On Demand는 서비스가 예측 불가능한 속도로 성장하는데, 이를 문제 없이 받아주기 위해 넣는 설정이다. 둘의 차이가 명확히 있다. </p></blockquote><p>테이블마다 최대 RCU, WCU가 정해져 있어서 프로비저닝 당시 설정한 값에 따라 초기 파티셔닝이 결정된다. 읽기 용량은 파티션마다 최대 3,000 그리고 쓰기 용량은 파티션마다 1,000이 최대이다. 따라서 다음 식으로 초기 파티셔닝이 결정된다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">initial partition = (RCU / 3000) + (WCU / 1000)</span><br></pre></td></tr></table></figure><p>합친 값을 정수로 올림 한 값을 기본 파티션 수로 설정하고, 2개 이상의 파티션이 생성되면 Capacity Unit은 공평하게 분배된다. 예를 들어 RCU 3000, WCU 1000으로 설정하면 초기 파티션은 2개로 나눠지고, 각각 RCU 1500, WCU 500을 나눠 갖게 된다.</p><h1 id="Request-Router"><a href="#Request-Router" class="headerlink" title="Request Router"></a>Request Router</h1><p>Dynamo 논문에서는 클라이언트에서 직접 파티션을 선택해 요청을 보낼 수 있는 방법과 그 앞단에 로드밸런서를 통해 파티션을 찾아가는 방법에 관해 얘기한다. 특별히 어떻게 사용 중이라는 말은 없었지만, Client 쪽에서 어떤 스토리지 노드로 요청을 보내야 하는지 알고 있는 “Partition-Aware”를 사용하는 것으로 보였다. 하지만 DynamoDB에서는 모든 요청을 Request Router라고 불리는 중간자에 보낸다.</p><p><img src="/images/2022-04-19-dynamodb-internals-2/request-router.png?style=centerme" alt="Request Router"></p><p>Request Router는 두 가지 컴포넌트와 상호작용 후 실제 데이터가 있는 스토리지 노드에 접근하게 된다. </p><ul><li><strong>Authentication System</strong>: AWS 플랫폼에서 공통으로 사용되는 권한 확인 컴포넌트</li><li><strong>Partition Metadata System</strong>: 파티션의 리더 스토리지 노드를 관리해, Request Router가 요청을 보낼 노드를 선정</li></ul><p>Partition Metadata System 내부적으로 <strong>Auto Admin</strong>이라는 시스템이 동작하고 있다. 이는 관리형 서비스를 만들어주는 핵심적인 컴포넌트로, AWS에서는 이를 DynamoDB의 DBA라고 부른다고 한다. 구체적인 관리에 대해서는 조금 있다가 후술한다.</p><h1 id="Partition-Replication"><a href="#Partition-Replication" class="headerlink" title="Partition Replication"></a>Partition Replication</h1><p>해시 함수에 의해 정의되는 파티션은 각각 레플리카 셋(Replica Set)을 갖고 있다. 리더 노드와 두 개의 추가적인 복제 노드를 갖게 되는데, 이는 AWS의 가용 영역에 골고루 나눠서 운용된다. Dynamo 시스템에서는 Sloppy Quorum을 사용하고 어떤 스토리지 노드든 요청을 처음 받게 되는 coordinator로서 동작할 수 있다. DynamoDB에서는 이와 다르게 리더 노드를 선출한다. 이 과정은 <a href="https://ko.wikipedia.org/wiki/%ED%8C%A9%EC%86%8C%EC%8A%A4_(%EC%BB%B4%ED%93%A8%ED%84%B0_%EA%B3%BC%ED%95%99)">Paxos</a> 알고리즘으로 구성되어있다고 하는데, Paxos를 이번 글에서 다루고 있지는 않다.</p><blockquote><p>Paxos는 분산 시스템에서 특정 값이 합의되도록 하는 합의 알고리즘이다. DynamoDB에서는 파티션을 구성하는 세 개의 스토리지 노드들 사이에 “리더”가 어떤 노드인지를 합의하는 과정에 Paxos를 사용한다. Paxos는 스탠포드 대학생을 가르쳐도 이해하기 위해 1년이 걸렸다는 “이해 불가능한” 알고리즘이라는 슬픈 이야기가 있다. 이에 따라 “이해 가능한 합의 알고리즘”이라는 느낌으로 Raft가 나왔다고 한다.</p></blockquote><p>대략 설명하자면, 집단의 리더는 현재 정상 상태임을 다른 스토리지 노드에 하트 비트를 통해 알린다. 영상에서는 1.5초? 2초쯤 한 번씩 하트 비트를 보내고 있다고 하는데, 만약 다른 스토리지 노드가 이를 받지 못하면 새로운 리더를 선출하기 위해 다른 노드에 본인을 리더로 주장하는 정보를 보낸다. 이 요청을 다른 스토리지 노드가 동의하면 새로운 리더가 선출된다.</p><hr><p>어찌 됐든 리더가 있다는 사실이 중요한데, Dynamo와 다르게 쓰기 요청이 리더에게만 보내지기 때문이다. 리더는 항상 최신 데이터를 갖게 된다. 쓰기 요청을 받은 리더는 로컬 데이터를 수정하고 다른 두 레플리카에게 이 요청을 전파한다. 그리고 둘 중 하나의 성공 응답을 받으면 이 쓰기 요청이 성공했다고 응답한다.</p><p><img src="/images/2022-04-19-dynamodb-internals-2/dynamodbmultiaz.png?style=centerme" alt="여러 AZ에 나눠서 레플리카를 운영"></p><p>반면 읽기의 경우 세 개의 레플리카 중 하나에게 요청을 보낸다. 따라서 연속된 요청을 통해 값을 읽는다면 1/3 확률로 최신 데이터가 아닐 수도 있다. Dynamo와 마찬가지로 Eventual Consistency가 발생한다.</p><blockquote><p>Dynamo의 Quorum이 아예 적용 안 된 건 아니라는 것을 알 수 있다. 쓰기 쿼럼이 3개 중 2개 성공으로 설정된 것이나 다름없다. 위 설명은 모두 기본 읽기와 쓰기에 대한 설명이고, 트랜잭션 또는 강력한 읽기 일관성에 대한 옵션은 다르게 동작한다.</p></blockquote><h1 id="Storage-Node"><a href="#Storage-Node" class="headerlink" title="Storage Node"></a>Storage Node</h1><p>위에서 언급했지만, 스토리지 노드는 파티션을 구성하는 레플리카 셋이다. 내부적으로는 크게 두 가지 컴포넌트로 구성되어있다.</p><ul><li><strong>B Tree</strong>: 쿼리와 뮤테이션이 발생할 때 사용되는 자료구조</li><li><strong>Replication Log</strong>: 파티션에서 발생하는 모든 Mutation Log를 기록하는 시스템</li></ul><p>B 트리의 경우 우리가 흔히 아는 그 자료구조가 맞다. RDB에서 인덱스로 사용되는 트리 자료구조가 똑같이 사용된다. Replication Log도 다른 DB에서 레플리카 셋을 유지할 때 복구를 위해 사용되는 컴포넌트와 똑같다. 위에서 잠깐 말했던 Auto Admin이 이 복구 과정에 개입한다. Auto Admin은 레플리카 셋의 리더와 그 위치를 관리하고 스토리지 노드를 모니터링하는데 스토리지 노드에 장애가 발생해서 다운되면 새로운 스토리지 노드를 생성하고 다른 스토리지 노드의 Replication Log를 가지고 자료구조를 복사해간다. 새로운 스토리지 노드의 Replication Log가 성공적으로 B 트리에 적용되면 파티션에 합류할 자격이 생긴 것으로 보고 레플리카 셋에 합류시킨다.</p><h1 id="Secondary-Index-1"><a href="#Secondary-Index-1" class="headerlink" title="Secondary Index"></a>Secondary Index</h1><p>위 기본 내용에 보조 인덱스에 대한 이야기를 짧게 했는데 이 구조가 어떻게 되어있는지 확인해보자. 프로세스는 일반적인 테이블과 비슷하다. PK를 해시 해서 각 파티션으로 나눠 보낸다. 다른 점은 보조 인덱스는 베이스 테이블과 독립적으로 파티션을 구성한다는 점이다. 그리고 테이블 내에서 보조 인덱스에 해당하는 Attribute이 수정되면 이 작업은 <strong>Log Propagator</strong>라고 하는 컴포넌트에 의해 보조 인덱스 파티션의 리더 스토리지 노드에 전파된다.</p><p><img src="/images/2022-04-19-dynamodb-internals-2/secondary-index.png?style=centerme" alt="보조 인덱스와 Log Propagator"></p><p>Log Propagator는 스토리지 노드의 Replication Log를 바라보고 있다가 보조 인덱스 수정이 발생하면 Request Router가 베이스 테이블에 요청하듯 보조 인덱스 파티션에게 변경을 요청하게 된다. 이렇게 비동기적으로 전파되는 구조이므로 보조 인덱스의 Eventual Consistency는 필수적이다.</p><hr><p>해시 기반으로 샤딩 된 데이터를 수정할 때 원래 위치한 스토리지 노드에서 데이터를 삭제하고 해시 된 위치에 맞는 스토리지 노드에 새로 쓰는 작업을 해야 하기 때문에 쓰기 작업이 생각보다는 무겁다.</p><p><img src="/images/2022-04-19-dynamodb-internals-2/secondary-index.png?style=centerme" alt="실제 업데이트는 두 개의 파티션을 수정한다"></p><p>파티션에 뮤테이션을 만드는 작업은 레플리카 셋 3개에 동일한 작업을 하는 것과 같기 때문에 베이스 파티션 레플리카 셋, 보조 인덱스에서 삭제될 파티션 레플리카 셋, 보조 인덱스에 추가될 파티션 레플리카 셋에 뮤테이션이 발생한다. 즉 하나의 보조 인덱스를 수정하는 작업은 9개의 스토리지 노드의 수정을 가져온다.</p><blockquote><p>따라서 Secondary Index의 수정은 자주 발생하지 않는 것이 좋다. 이는 샤딩을 할 때 기준이 되는 필드가 자주 수정이 발생하면 안 된다는 얘기와 같다.</p></blockquote><blockquote><p>영상에서 별다른 설명은 없었지만, 위 설명은 GSI에 해당하는 설명일 것이라 생각한다. LSI는 테이블이 생성될 때 같이 생성되어야 한다는 점, PK는 베이스 테이블과 같아야 한다는 점, 강력한 읽기 일관성이 제공된다는 점, 베이스 테이블의 RCU와 WCU를 공유한다는 점, 그리고 이름에서 알 수 있듯, 베이스 테이블과 같은 파티션을 공유하는 것 같다.</p></blockquote><h1 id="Provisioning-amp-Adaptive-Capacity"><a href="#Provisioning-amp-Adaptive-Capacity" class="headerlink" title="Provisioning &amp; Adaptive Capacity"></a>Provisioning &amp; Adaptive Capacity</h1><p>처리 용량 프로비저닝에 대해서는 위에 파티셔닝에 대해 설명하면서 함께 얘기했다. 이 섹션에서는 조금 구체적인 동작 방식에 대해서 짧게 설명한다.</p><p>RCU, WCU는 쿼터를 정할 때 흔히 사용되는 Token Bucket 알고리즘으로 구성되어있다. 매초 RCU 수만큼 토큰이 버킷에 쌓이는데 버킷의 총용량은 설정한 RCU의 300배 정도이다. 따라서 아무것도 안 하면 5분 정도는 토큰이 쌓인다. 다만 버킷의 용량을 초과하면 토큰은 버려진다. 이런 구조로 트래픽이 치솟는 상황에서도 일시적으로나마 스로틀링이 생기는 것을 막아준다.</p><p>위에서 잠깐 언급한 적 있는데 RCU, WCU는 파티션에 골고루 분산된다. 만약 파티션이 3개이고 RCU가 300이라면 각 파티션은 100씩 RCU를 나눠 갖는다. 이렇게 나눠진 파티션에서 실제 운영할 때 아래 이미지처럼 25 RCU, 150 RCU, 50 RCU를 사용한다고 가정해보자.</p><p><img src="/images/2022-04-19-dynamodb-internals-2/unbalanced-load-1.png?style=centerme" alt="Hot Partition이 발생한 상황"></p><p>위와 같은 상황에서 두 번째 파티션의 RCU가 50만큼 부족하고 나머지는 남는 상황이다. 총합은 75 RCU 만큼 남기 때문에 위 요청량이 잘 처리되어야 하지만 데이터가 고르게 분산되지 않아 Hot Partition이 생길 수 있다.</p><p>AWS에서는 이 문제를 해결하고자 Adaptive Capacity를 도입했다. Adaptive Capacity는 Adaptive Multiplier라는 실숫값을 RCU, WCU에 곱해 일시적으로 처리 용량을 수정해주는 방식이다. Adaptive Multiplier는 피드백 루프를 돌며 지속해서 조절되는데, 이런 조절 루프를 돌리는 컴포넌트를 <a href="https://ko.wikipedia.org/wiki/PID_%EC%A0%9C%EC%96%B4%EA%B8%B0">PID Controller</a>라고 한다. DynamoDB에서 PID Controller는 인풋으로 소비된 용량, 프로비전된 용량, 스로틀링 속도, 현재 Multiplier 값을 받아서 결과로 새로운 Multiplier 값을 넘겨준다.</p><p><img src="/images/2022-04-19-dynamodb-internals-2/unbalanced-load-2.png?style=centerme" alt="Adaptive Capacity 적용 후"></p><p>위 예시에서는 1.5 정도 값이 Multiplier로 설정되면 스로틀링이 해결된다. 하지만 처리 용량은 테이블에 적용되는 개념이기 때문에 파티션마다 부족한 값에 대해 Multiplier를 곱하는 구조가 아니고, 테이블의 전체 처리 용량에 곱해진다. 따라서 위 예시에서는 총 150만큼 처리 용량 초과가 발생한다. 그러나 이 상태는 잠깐 지속되고 PID Controller에 의해 정상화된다. 일시적으로 스로틀링을 해결해주는 장치라고 볼 수 있다.</p><blockquote><p>즉, Adaptive Capacity는 Hot Partition을 완전히 해결해주는 장치는 아니다. 애초에 Hot Partition이 나오지 않도록 데이터 분산을 잘 만들어야 하고 특별히 많은 요청을 처리해야 하는 파티션이 있다면 아예 별도로 테이블을 관리하는 것도 좋은 방법이다.</p></blockquote><hr><p>이번 글은 DynamoDB를 가장 기본적으로 사용하는 상황에서 거치게 되는 컴포넌트 구성에 대해 작성했다. 특히 파티셔닝 얘기와 프로비저닝 얘기는 우리가 <a href="/posts/database/dynamodb-single-table-design/">어떻게 키를 설계해야 할지</a> 대략적인 감을 잡을 수 있게 해준다. 이 외에도 설명하지 않은 Auto Scaling, Stream, 강력한 읽기 일관성, 트랜잭션 등 여러 기능이 DynamoDB에 있다. 특수한 유즈 케이스가 있다면 따로 AWS 문서를 확인해보자.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://en.wikipedia.org/wiki/Amazon_DynamoDB">https://en.wikipedia.org/wiki/Amazon_DynamoDB</a></li><li><a href="https://www.alexdebrie.com/posts/dynamodb-partitions/">https://www.alexdebrie.com/posts/dynamodb-partitions/</a></li><li><a href="https://dzone.com/articles/partitioning-behavior-of-dynamodb">https://dzone.com/articles/partitioning-behavior-of-dynamodb</a></li><li><a href="https://www.allthingsdistributed.com/2012/01/amazon-dynamodb.html">https://www.allthingsdistributed.com/2012/01/amazon-dynamodb.html</a></li><li><a href="https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/ServiceQuotas.html#default-limits-throughput-capacity-modes">https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/ServiceQuotas.html#default-limits-throughput-capacity-modes</a></li><li><a href="https://www.dynamodbguide.com/">https://www.dynamodbguide.com</a></li><li><a href="https://www.youtube.com/watch?v=yvBR71D0nAQ">AWS re:Invent 2018: Amazon DynamoDB Under the Hood: How We Built a Hyper-Scale Database (DAT321)</a></li><li><a href="https://www.youtube.com/watch?v=HaEPXoXVf2k">AWS re:Invent 2018: Amazon DynamoDB Deep Dive: Advanced Design Patterns for DynamoDB (DAT401)</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/database/">database</category>
      
      
      <category domain="https://changhoi.kim/tags/serverless/">serverless</category>
      
      <category domain="https://changhoi.kim/tags/dynamodb/">dynamodb</category>
      
      
      <comments>https://changhoi.kim/posts/database/dynamodb-internals-2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2021년, 개발 3년차 회고</title>
      <link>https://changhoi.kim/posts/logs/20220417/</link>
      <guid>https://changhoi.kim/posts/logs/20220417/</guid>
      <pubDate>Sat, 16 Apr 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;개발을 시작했다고 볼만한 시점부터 2022년 01월 01일 기준으로 3년이 채워졌다. 시작도 2019년 01월 01일부터 했기 때문에 3년을 딱 맞게 채웠다. 조금 늦은 감이 있지만 생일 기념으로, 그리고 매년 하는 일인 만큼 지난해 무슨 일들이 가장 유의미했는지 정리해봤다. &lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>개발을 시작했다고 볼만한 시점부터 2022년 01월 01일 기준으로 3년이 채워졌다. 시작도 2019년 01월 01일부터 했기 때문에 3년을 딱 맞게 채웠다. 조금 늦은 감이 있지만 생일 기념으로, 그리고 매년 하는 일인 만큼 지난해 무슨 일들이 가장 유의미했는지 정리해봤다. </p><span id="more"></span><blockquote><p>다른 개발자의 회고 내용에 기대하듯, 이 주니어 개발자는 무엇을 하며 1년을 보냈을까? 를 기대하며 이 글을 읽는다면 조금 실망하실 수 있습니다. 개발자보다는 개인적인 회고에 가깝습니다. 그러나 저는 개발자입니다.</p></blockquote><h1 id="졸업-전-창업-해보기"><a href="#졸업-전-창업-해보기" class="headerlink" title="졸업 전 창업 해보기"></a>졸업 전 창업 해보기</h1><p><img src="/images/2022-04-17-20220417/spacesuite.svg?style=centerme" alt="우주 갈꺼니까"></p><p>예전부터 만들어보고 싶었던 서비스가 있었다. 프로젝트 관리 SaaS를 만들어보고 싶었다. 간단히 설명하자면 지금 Jira가 충분히 만족스럽지 않고, 태스크 사이의 관계들을 더 잘 파악하도록 바뀌었으면 좋겠다는 생각을 자주 해왔다. 나는 그 방법이 트리 구조에 있으리라 생각했고, 뭐 비슷한 방법으로 문제를 풀어보려고 노력했다.</p><p>결과적으로는 실패를 경험했고, 그 과정은 이전에 “<a href="https://changhoi.github.io/posts/logs/20210501/">4개월간 서비스 개발 후기 (사업화 실패하는 데 성공)</a>“ 이라는 글에 배운 점과 느낀 점을 나름 디테일하게 서술했다.</p><p>과정에서 많은 것들을 배우고 얻었지만, 사람들을 많이 얻은 것 같아서 좋다. 팀원들을 포함해서 내가 만들고자 하는 것을 응원해주고 같이 고민해준 사람들도 있고… 일단 교수님하고 친해져서 좋았다. 교수님은 서비스 자체에 대해서는 잘 모르셨지만, 공간을 빌려주시고 최대한 도움을 주시려고 많이 노력해주셨다. 수업 중에 나서지도 않는 학생이어서 이름도 잘 기억 못하실 법한데 이렇게 도움을 주셔서 정말 감사했다.</p><p>구체적인 내용들은 이미 다른 회고에서 작성했으니 이 정도로 마무리…</p><h1 id="취준"><a href="#취준" class="headerlink" title="취준"></a>취준</h1><p><img src="/images/2022-04-17-20220417/justdoit.JPG?style=centerme" alt="그냥 하는 거지"></p><p>사실 취준 과정이 엄청 고통스럽거나 힘들지는 않았다. 취업할 자신도 있었고 취업 준비 과정이 딱히 그전 생활과 다르지도 않았다. 물론 CS에 집중해서 공부했다든지, 포트폴리오 정리하고 자기소개서를 쓴다든지 하는 것들은 있었지만, 그전에도 개발 공부하고 자유시간 갖고 반복하던 삶을 살았기 때문에 특별히 다르다는 느낌은 없었다.</p><h2 id="CS-스터디-멘토링"><a href="#CS-스터디-멘토링" class="headerlink" title="CS 스터디, 멘토링"></a>CS 스터디, 멘토링</h2><p>스터디를 2개 열어서 진행했는데, 하나는 CS 전반적인 내용에 대한 스터디였고 하나는 시스템 프로그래밍을 주제로 한 멘토링이었다.</p><h3 id="CS-스터디"><a href="#CS-스터디" class="headerlink" title="CS 스터디"></a>CS 스터디</h3><p>과거에 취업 준비를 한다고 생각하면 Github에 올라가 있는 CS 토막 상식 같은 링크를 보곤 했다. 물론 훌륭한 레포지토리들이라 보면서 끄덕끄덕 기억을 살려내곤 했는데, 뭔가 CS에 대해 잘 알게 되었다는 느낌을 받지는 못했다. 그래서 학교에서 사용했던 교과서를 다시 보면서 CS를 정리하기로 했다.</p><p>교과서 스터디는 워낙 양이 많아서 취준을 하던 다른 개발자 친구, 이미 개발하는 친구와 함께 스터디를 진행했다. <a href="https://www.notion.so/changhoi/Deep-CS-a36ac1380d4843c69867b184b36a50c3">Notion에 정리</a>하기로 하고, 학부에서 배운 수준의 교과서 레벨을 커버한다는 느낌으로 OS와 네트워크까지 잘 정리했다. DB, 자료구조까지 정리했으면 좋았을 것 같은데, 친구들이 바빠지고 취업도 되고 하면서 흐지부지 정리됐다. DB는 따로 학습하긴 했으나 정리되지는 않았고 조금 깊숙한 얘기들에 관해 공부해볼 계획이다.</p><p>일단 그래도 OS와 네트워크에 대해서는 배운 내용들이 잘 정리된 느낌이었고, 실제로 면접에 큰 도움이 되었다. 구멍들이 느껴지긴 하지만, 차차 해결해가면 되겠지.</p><h3 id="멘토링"><a href="#멘토링" class="headerlink" title="멘토링"></a>멘토링</h3><p>학교에 연이 깊은 듯 얕은 듯 한 개발 동아리가 있다. 이 개발 동아리에서는 매 학기 멘토를 모집한다. 멘토는 주제를 선정하고 멘티들이 이 주제에 투표하는 구조이다. 평소에 리눅스 시스템을 조금 잘 써보고 싶다는 생각을 항상 하고 있어서 파일 시스템을 다루거나 소켓을 다루는 등의 프로그래밍에 대해 알아본 적이 있었다. 이런 걸 학습하는 주제가 Unix 시스템 프로그래밍이라는 것을 알게 되었고, 그 당시 Go에 흥미가 많아서 Go를 가지고 시스템 프로그래밍하는 내용으로 수업을 준비했다.</p><p>해당 동아리는 비전공자 또는 초보인 분들이 많은 특성이 있어서 관심을 끌기에는 조금 어려운 주제가 아닐까 하는 생각이 들었다. 다행히도 조금 고인물 분들이 나타나 스터디를 재밌게 끌어주셨다.</p><p>일단 교재는 <a href="https://www.oreilly.com/library/view/go-systems-programming/9781787125643/">Go System Programming</a>이라는 책을 사용했다. 시스템 프로그래밍의 이론적인 이야기라든지, 유닉스 시스템이 파일시스템을 구성하고 있는지 등 자세한 설명이 부족한 책이었다. 다만 Go를 가지고 시스템 프로그래밍을 어떻게 할 수 있는지 등 조금 실전적인 이야기가 많이 담긴 책이었다.</p><p>조금 이론적인 이야기도 궁금해서 <a href="https://www.oreilly.com/library/view/advanced-programming-in/9780321638014/">Advanced Programming in the Unix Environment</a> 책을 같이 참조하면서 공부했다. 꼼꼼히 읽어보면 좋을 것 같은데, 스터디 진행이 꽤 빨라서 꼼꼼하게 읽어보지는 못했다.</p><p>스터디 진행은 멘토가 Go언어 자체에 대한, 또는 Go를 통해 어떻게 시스템 프로그래밍을 할 수 있는지 설명해주는 시간과 멘토가 정해준 주제에 대해 멘티들이 특정 주제에 대한 발표를 준비해오고 이를 세션 형식으로 발표하는 형태로 진행되었다. 준비 과정이 진짜 어려웠는데, 사람들이 잘 따라와 주고 발표 준비도 잘 해주셔서 재밌게 마무리 지을 수 있었다.</p><p>취준을 위해 했다고 할 수는 없어서 분류가 조금 애매하긴 한데, 아무튼 시스템 프로그래밍도 CS의 한 부분이기 때문에 취업에 도움이 안 되었다고 볼 수도 없을 것 같다.</p><h2 id="알고리즘"><a href="#알고리즘" class="headerlink" title="알고리즘"></a>알고리즘</h2><p>개발 공부 중에 추가된 것이라고 하면 알고리즘이 있을 것 같다. 알고리즘을 잘하는 편도 아니고, 경험이 많이 있는 편도 아니었다. 알고리즘 자체에 대한 경험을 쌓으려고 하루에 2, 3문제씩 풀었던 것 같다.</p><p><img src="/images/2022-04-17-20220417/boj.png?style=centerme" alt="백준... 한 문제만 더 풀어야겠다"><br><img src="/images/2022-04-17-20220417/programmers.png?style=centerme" alt="프로그래머스"></p><p>대충 200문제 넘어가고 나니까 알고리즘은 어떻게 푸는 거구나 느낌이 생겼던 것 같다. 물론 지금도 골드 1, 2만 만나면 좌절을 맛보고 있다. 그래도 어느 정도 코딩 테스트라고 하는 부분에서 막히던 걸 많이 해결해줬다.</p><p>알고리즘을 처음 공부할 때는 카테고리별로 공부했던 것 같다. 예를 들어서 Brute Force 문제, Greedy 문제, 이분 탐색, DP 이런 식으로 정해진 카테고리 문제들을 풀면서 이런 경우는 이 알고리즘이 도입되는 거구나? 이런 느낌으로 알고리즘을 풀었던 것 같다. 이 부분이 어느 정도 진행되고 나서부터는 그냥 프로그래머스 연습문제 2, 3단계에 있는 걸 쭉 풀었다.</p><p>알고리즘을 공부하면서 느낀 점은 알고리즘이 코딩하는 것과 크게 다른가? 라는 점이다. 이 부분은 아주 갑론을박 말이 많다. “알고리즘을 잘 못 한다고 개발을 못 하는 건 아니다.” 라든지 “사실 개발하면서 알고리즘을 제대로 써본 적이 없다.”든지…</p><p>본인은 알고리즘이 개발과 아주 유관하다고 생각하는 편이다. 그전에는 알고리즘은 아주 다른 영역이라고 생각했지만, 사실 기본적인 문제들을 해결하는 능력은 논리적 사고 능력일 뿐이다. 물론 굉장히 스킬을 가미하며 알고리즘을 해결해야 하는 경우는 조금 현실성 없다고 느낄 수도 있지만, 논리적 사고 연습이라는 측면에서 알고리즘을 연습하는 것이 개발을 더 잘하게 만들어준다는 느낌을 받는다. 따라서 취업하고도 알고리즘을 푸는 걸 취미 삼아 하나씩 하는 것도 좋을 것 같다는 생각이 들었다.</p><h2 id="프로젝트"><a href="#프로젝트" class="headerlink" title="프로젝트"></a>프로젝트</h2><p>프로젝트는 취준 목적으로 했다기보다는 개발을 안 하는 삶이 조금 무료한 감이 있어서 시작했다. 프로젝트를 하는 사회인 동아리? 라고 해야 할지… 아무튼 그런 곳에서 프로젝트를 진행했다. 초반에 프로젝트 진행이 많이 루즈해졌다. 이유는 진짜 창업 아이템을 고르듯 아이템에 대해 조사도 하고 기능 명세도 문서화하고 기본적인 컴포넌트들에 대한 합의 과정이 진짜 길어서 그랬다. 사실 이런 단계를 모두 거치는 사이드 프로젝트는 해본 적이 없지만, PO 역할을 해주시는 분이 요런 저런 걸 해보고 싶어 하시는 것 같기도 하고 나름 재밌어서 쭉 같이 진행했던 것 같다. 루즈한 출발 자체는 아쉽지만, 그 사이 과정에서 배운 점들이 많이 있어서 그래도 이 부분은 긍정적이었다.</p><p>개발에서는 아쉬운 점이 있었다. 개발 스택을 정하는 과정에서 같이 개발하는 팀원에게 많은 부분을 양보해드렸다. 팀원분도 취준 중이신데 목표하시던 회사 스택을 사용해보고 싶다고 하셔서 최근까지 더 이상 잡고 있지 않던 타입스크립트와 NestJS를 사용했고 MySQL을 사용했다. 사실 개발 스택은 별로 신경 쓰지 않기 때문에 상관은 없었지만 배울 수 있는 포인트가 줄었다는 점이 사이드 프로젝트의 매력을 조금 반감되게 했다.</p><blockquote><p>심지어 서버 코드에 거의 기여한 바가 없으시다. 스켈레톤을 작성하는 것 외 서비스 로직이 머지된 적이 없었다. 이 부분은 좀 많이 아쉬웠다.</p></blockquote><p>그러나 진짜 문제는… 사이드 프로젝트가 더 이상 진행되지 않는다는 것이었다. 물론 사이드 프로젝트는 그야말로 사이드니까 원래 하던 일이 있다면 우선순위가 뒤로 밀리는 경우가 허다하다. 그래도 뭔가 우리 팀이 흐지부지 프로젝트를 정지한 이유를 생각해봤는데 다음과 같은 이유가 있었던 것 같다.</p><ul><li><p><strong>주기적인 회의를 안 함</strong>: 주기적인 회의를 해도 했던 작업이 많이 없으니 회의 시간이 짧고 그걸 위해 약속을 취소해야 하는 등 부담이 좀 있다는 이유로 주기적 회의를 없앴다. 사실 이게 가장 큰 실패 원인이 아닐까 싶은데, 회의 주기가 뭔가 개발 기능을 마무리 짓는 주기로 동작했기 때문에 이 부분이 없어지면서 더 안 하게 된 것 같다. 그리고 애초에 이 정도의 강제성조차 안 가지고 사이드 프로젝트를 진행할 수가 없다.</p></li><li><p><strong>작업에 정해진 시간이 없음</strong>: 언제까지는 해요! 라는 작업 시간이 없어서 무기한으로 미뤄진다. 정말 미친 듯이 바쁜 사람은 애초에 사이드를 할 생각을 안 한다는 가정하에, 일상 업무에 일반적인 시간 소비를 하는 사람들 기준으로 일주일 내내 일정 시간을 할애하도록 스케줄링하는 것이 불가능하지 않다. 강제적으로 3시간! 이런 식으로 정할 수 있는데, 각자 정한 이 시간을 기준으로 어떤 작업은 언제까지 마무리되어야 한다는 약속이 필요했던 것 같다.</p></li></ul><p>원래 사이드 프로젝트 완성하기란 정말 어렵다는 것을 알고 있다. 그렇지만 이번 프로젝트는 진짜 사이드 팀 프로젝트에 대해 굉장한 회의를 느끼게 했다. 그냥 혼자 하는 것보다 못한 경험을 했다고 느꼈다. 앞으로 사이드 프로젝트는 진짜 친해서 강제성을 좀 더 부여할 수 있거나, 사이드 프로젝트에 진~심인 디자이너 + 프론트 개발자와 하거나 혼자 하거나 해야겠다고 생각했다.</p><h1 id="인턴"><a href="#인턴" class="headerlink" title="인턴"></a>인턴</h1><p><img src="/images/2022-04-17-20220417/feature.svg?style=centerme" alt="그건 버그가 아니랍니다"></p><p>길다면 길고 짧다면 짧은 듯한 취준 시간을 보내고 평소에 정말 가서 일해보고 싶던 기업의 플랫폼 개발 인턴으로 들어가게 됐다. 회사에서 크게 두 가지를 했던 것 같은데, 하나는 인턴 과제와 같은 서비스를 개발하고 이를 배포하는 과정이었고, 다른 하나는 팀에서 사용하고 있는 기술을 학습하는 과정이었다. 두 가지 모두 본인에게 큰 의미가 있었고 개발자로서는 굉장한 퀀텀 점프를 했던 경험이었다.</p><h2 id="기술-학습에-대해"><a href="#기술-학습에-대해" class="headerlink" title="기술 학습에 대해"></a>기술 학습에 대해</h2><p>회사에서 사용하고 있던 기술들을 내가 잘 알고 있지는 않았다. gRPC, Go를 공통으로 사용하고 있던 조직이었기 때문에 위 기술들을 학습하고, 전반적으로 팀이 사용하고 있던 NoSQL, RDB에 대해 학습했다. 이 학습의 가장 큰 포인트는 “<strong>깊숙한 이해</strong>“ 였다. 단순히 특징을 검색해서 나오는 얘기들 말고, 예를 들어서 “Go는 동시성 프로그래밍에 특화된 언어 구조를 가지고 있습니다.”라는 문구는 쉽게 찾아볼 수 있다. 그렇다면 “왜 특화되었다고 표현되어있지?”라는 질문이 나온다. 어느 겉핥는 학습을 해보면 그 질문에 대한 답변은 “<code>go</code>, <code>channel</code> 키워드와 여러 <code>sync</code> 패키지 등으로 개발자들이 동시성을 구성하면서 고민해야 하는 여러 부분을 해결해주고 있기 때문이다”라는 것을 알 수 있다. 그렇다면 그 고민이 구체적으로 무엇이고 어떻게 해결해주고 있는 것일지 구현체 레벨까지의 궁금증(코드 레벨까지는 아니고, 보다 추상적인 레벨에서)을 갖게 된다. 완전히 어떠한 특징에 대해 깊게 이해한 다음, 그렇다면 우리는 이 기술을 어떻게 활용할 수 있을까? 어떤 옵션들이 우리 상황에 더 잘 맞는지, 그리고 그 이유는 무엇일지? 를 고민하는 순서로 여러 기술들을 학습했던 것 같다.</p><p><img src="/images/2022-04-17-20220417/step.png?style=centerme" alt="기술 학습 단계"></p><p>사실 과거에 상당히 많은 부분이 경험을 통해 얻을 수 있는 영역이라고 생각하던 부분이 있었다. 어느 정도 학습하고 나면, “여기부터는 경험을 통해 알 수 있는 영역”이라고 생각하는 부분들을 마주한다. 물론 그 부분이 없다는 것은 아닌데, 이 과정을 거치면서 상당 부분은 이런 깊숙한 이해를 통해 많이 해결할 수 있다고 생각하게 되었다.</p><hr><p>위에서는 조금 비중 있게 쓰진 않았지만, 사실 “깊숙한 이해”의 근본적인 목표는 “우리는 어떻게 사용할지”이다. 그래서 우리는 “어떻게 쓸 수 있을까?”를 조금 더 중요하게 본다. 식사를 기다리면서 시니어분에게 “대규모 서비스를 구성해본 경험이 없어서 ‘어떻게 쓸 수 있을까?’에 대한 정보는 떠올리기 어려운 것 같다”라고 말씀드린 적 있는데, 시니어분이 “기술적으로 까다로운 특정 상황에서 경험으로 어떤 기술을 사용하려는 사람은 사실 오히려 더 소수이다. 어떻게 쓰지?를 알기 위해서 깊숙한 이해가 요구되는 것”이라고 말씀하셨다. 깊숙한 이해가 기술을 대하는 핵심이지만, 그것이 핵심인 이유는 근본적으로 어떻게 쓸지를 보다 잘 알기 위해서이다.</p><p>잘 정리해서 쓴지 모르겠지만, 아무튼 이 공부 과정을 통해서 기술을 바라보고 대하는 태도, 학습 방법, 문제를 해결하기 위해 지나가야 하는 기술적 탐구 과정에 대한 에티튜드가 바람직한 방향으로 박힌 것 같아, 인턴이 끝나고 나서도 참 기분이 좋았다.</p><blockquote><p>회사에서 학습했던 기술들은 조금 더 포괄적이거나 깊게 다시 학습해 정리하고 있다.</p></blockquote><h2 id="프로젝트에-대해"><a href="#프로젝트에-대해" class="headerlink" title="프로젝트에 대해"></a>프로젝트에 대해</h2><p>회사에서 했던 프로젝트는 <a href="https://medium.com/daangn/%EC%98%88%EC%B8%A1-%EA%B0%80%EB%8A%A5%ED%95%9C-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%84%9C%EB%B9%84%EC%8A%A4-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-a33e2f3cef88">이 링크</a>에서 구체적으로 확인할 수 있다. 과정은 위 링크에서 잘 정리되어있기 때문에 위 과정으로 뭘 배웠나에 대해서 간단하게 정리해보려고 한다.</p><p>일단 위 프로젝트에서 경험한 핵심은 “예측 가능한 애플리케이션”이다. 예측 가능하다는 것은 내가 만든 서비스가 얼마만큼의 성능을 낼 수 있는 앱인지를 말한다. 서비스에 어떤 부분에 노출이 되는지 또는 어떤 서비스 뒤에서 돌아가는 플랫폼 서비스인지, 그래서 얼마만큼의 TPS가 나올지를 알 수 있다면 약간의 버퍼를 두고 그만큼을 해결할 수 있는 TPS가 뽑히도록 앱을 설계하거나, 그것이 현실적으로 불가능하다면 지금 만든 앱이 몇 개의 서버로 부하를 분산해야 하는지를 아는 것이 예측 가능한 애플리케이션이라고 생각한다.</p><p>일단 위에서 말한 것처럼 어느 정도 규모가 있는 애플리케이션에서는 이런 작업이 필수적이기 때문에 서비스를 개발하는 일련의 과정을 학습했다는 것 자체를 배웠다. 그리고 최대한의 성능을 위해서 애플리케이션의 성능 테스트를 진행하고 병목 지점을 찾아서 고쳐서 다시 배포하는 과정에서 숫자적인 감각이 조금 생겼던 것 같다. 예를 들어서 어떤 서비스인지, 하드웨어 성능이 어떤지에 차이가 있지만 I/O 작업이 추가될 때와 아닐 때 어느 정도의 성능이 나오는 게 일반적인지라든지, 어떤 수치를 보고 어디서 생기는 병목인지 예측하는 감이 생겼던 것 같다. 일시적이지 않으려면 뭐 추가적인 경험을 해봐야 할 것 같은데, 일단은 이러한 경험을 한차례 했다.</p><h1 id="졸업"><a href="#졸업" class="headerlink" title="졸업"></a>졸업</h1><p>학교를 참 열심히 다녔는데, 학교 수업을 열심히 들었다기 보다는 해보고 싶었던 건 거의다 한 것 같다.</p><p><img src="/images/2022-04-17-20220417/achieve.png?style=centerme" alt="교환 학생, 4.5 아쉽다"></p><p>사실 학교 그 자체에 대해서는 좀 회의적이기도 하고 쓸 말도 없다. 졸업 당일에는 아쉬운 감정이 생길 줄 알았는데 그런 거 없고 그냥 행복하게 졸업했다. 지금 약 2, 3개월 지나고 나니까 실감이 나는듯하다. 그러나 여전히 아쉽지는 않다.</p><p>졸업식에는 다행히 친구 몇 명과 같이 사진 찍고 즐겁게 졸업식을 보낼 수 있었다. 굿.</p><h1 id="회고-모임"><a href="#회고-모임" class="headerlink" title="회고 모임"></a>회고 모임</h1><p>2021년 초 “왕각코”라는 왕십리에서 각자 코딩 모임을 했다. 친한 동생 한 명하고 같이 모여서 각자 코딩하거나, 책을 읽거나 그냥 만나서 할 거 하는 모임이었다. 둘이서 하니까 모임이라고 부르기 뭐하긴 했는데, 꾸준히 이 모임에 누군가를 초대해왔었다. 공통으로 알고 있는 여러 명을 초대했는데, 그중 한 분이 정기적으로 이 모임에 나오게 되었고 이 모임의 아이덴티티를 재설정했다.</p><p>재설정된 아이덴티티는 회고 모임이었고, 이름도 “우린 남이니까”라는 이름으로 바꾸었다. 우린 남이니까라는 말은 파카라는 방송인이 과거에 자주 하던 소리였는데, 모두 파카 방송을 재밌게 보는 사람들이기도 하고, 회고 후 피드백이나 조언을 가감 없이 전달할 수 있는 사람들이라는 의미를 붙여서 이름을 정했다.</p><p>이 회고 모임은 지금은 4명이 되었고 꽤 유쾌한 회고 모임이 되었다. 회고 모임에는 아주 각자 영역에서 열심히 살고 계시는 분들이 함께하고 있는데, 조금씩 좋아하는 것이나 생각하는 방향이 차이가 있으면서도 남들의 의견을 폭넓게 수용하고 자신들의 것으로 만드시는 모습을 보면 본인도 아주 삶의 동기부여가 된다. 또 일주일마다 무엇을 했는지 어떤 것이 아쉬웠고 어떤 것이 좋았는지, 다음 주는 어떤 것을 할지를 계획하는 것들이 인생을 막사는 것으로부터 어느 정도 방지턱 역할을 해준다.</p><blockquote><p>막 사는 것을 막을 수는 없다. 그건 행복하다. 그리고 지금만 누릴 수 있는 것 같다. 그런데 그렇게 살고 난 주에 회고를 읽으면 자괴감도 들고 다른 분들이 훌륭하게 일주일을 마무리 지은 것을 보면서 반성하게 되는 효과가 있다.</p></blockquote><p>말이 잘 통하고, 자신의 가치관에 대해 굳이 남을 동의하게 만들려는 분들이 아닌 사람들과 이런 회고 활동을 하는 것은 정말 추천할만하다. 최근 좀 아쉬운 점이 생겼는데, 세 분이 모두 같은 회사에 다니게 되었다는 점이다. 아직 그에 대한 피부에 와닿는 단점은 없지만, 그 전보다 다양한 얘기들을 듣기 힘들고 회사 욕을 하기도 어렵다는 점(<del>예상</del>)이 아쉽다. 그래도 원래 하던 기능은 온전히 잘하고 있어서 피부로 와닿지는 않는듯하다.</p><hr><p>회고 전에는 뭔가 반성할 점이 많은 일 년이구나 싶었는데, 꽤 알찼던 것 같기도 하고? 이번 해에 개발자로서 한 단계 점프한 것 같다는 생각도 들었다. 벌써 상반기가 거의 다 지나가고 졸업 이후 첫 회사도 결정하는 단계가 되었고 고민 중이다. 다음 페이즈가 열리고 있다는 생각도 들고 커리어 골과 마일스톤 사이에 간극에 대한 고민도 많아진다. 이 글은 뇌에서 거의 바로 꺼내 쓴 글이라 두서가 없을 것 같은데 퇴고 과정 없이 올렸다. 회고는 참 어려운 것</p>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/logs/">logs</category>
      
      
      <category domain="https://changhoi.kim/tags/retrospect/">retrospect</category>
      
      <category domain="https://changhoi.kim/tags/log/">log</category>
      
      
      <comments>https://changhoi.kim/posts/logs/20220417/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>DynamoDB Internals (1) - Dynamo</title>
      <link>https://changhoi.kim/posts/database/dynamodb-internals-1/</link>
      <guid>https://changhoi.kim/posts/database/dynamodb-internals-1/</guid>
      <pubDate>Fri, 15 Apr 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;아마존은 지구 규모 스케일 서비스를 운영하면서 자신들의 요구와 가장 잘 들어맞는 범용적인 분산 스토리지 시스템을 만들어냈는데 이 시스템이 바로 Dynamo이다. 시스템을 만들고 운영한 경험을 논문으로 발표했고, 이 논문은 분산 스토리지 시스템 생태계에 큰 영향을 주었다. 이 논문에 영향을 받아 오픈소스에서는 Cassandra가 개발되었고 AWS 서비스의 SimpleDB, DynamoDB를 만드는 기초가 되었다. DynamoDB의 구조가 완전히 Dynamo와 같지는 않지만, 뿌리가 되는 Dynamo 시스템에 대해 먼저 알아보자.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>아마존은 지구 규모 스케일 서비스를 운영하면서 자신들의 요구와 가장 잘 들어맞는 범용적인 분산 스토리지 시스템을 만들어냈는데 이 시스템이 바로 Dynamo이다. 시스템을 만들고 운영한 경험을 논문으로 발표했고, 이 논문은 분산 스토리지 시스템 생태계에 큰 영향을 주었다. 이 논문에 영향을 받아 오픈소스에서는 Cassandra가 개발되었고 AWS 서비스의 SimpleDB, DynamoDB를 만드는 기초가 되었다. DynamoDB의 구조가 완전히 Dynamo와 같지는 않지만, 뿌리가 되는 Dynamo 시스템에 대해 먼저 알아보자.</p><span id="more"></span><h1 id="RDB가-적절하지-않았던-이유"><a href="#RDB가-적절하지-않았던-이유" class="headerlink" title="RDB가 적절하지 않았던 이유"></a>RDB가 적절하지 않았던 이유</h1><p><img src="/images/2022-04-16-dynamodb-internals-1/dynamo-title.png?style=centerme" alt="Dynamo 논문"></p><p>Dynamo는 아주 가용성 높은 키 값 스토어이다. 애초에 이러한 시스템을 구성하게 된 이유가 뭘까? 아마존은 Oracle이 제공하는 엔터프라이즈 데이터베이스 스케일을 넘어선 지구 단위의 글로벌 서비스로 성장했다. 이런 스케일을 감당하기 위해 아마존은 직접 DB를 설계하고 관리하기로 결정했다. 이를 위해 아마존은 그동안의 데이터베이스 사용 패턴에 대해 조사했고 다음과 같은 특징들을 확인할 수 있었다.</p><ul><li>스케일아웃 처리를 위한 <code>JOIN</code> 사용 제거 (<code>JOIN</code>을 사용하지 않음)</li><li>인덱스를 통한 단일한 데이터 검색이 대부분</li><li>복수의 데이터를 가져오는 패턴도 있었지만, 이 경우 보통 하나의 테이블에서만 데이터를 가져옴</li></ul><p>이런 특징들은 Key-Value 형태로 매칭되는 쿼리 조건으로 충분히 해결할 수 있고, RDB의 아주 강력한 쿼리들을 사용할 필요가 없었다. 즉, 규모있는 데이터 처리를 위해 RDB가 요구하는 컴퓨팅 리소스를 준비할 필요가 없다. 따라서 아마존에서는 RDB 사용이 데이터베이스 접근 패턴에 적합하지 않다고 판단했다.</p><hr><p>아마존에서 필요한 데이터베이스는 일반적인 RDB와 다르게 다음과 같은 특징을 가져야 한다</p><ul><li><p><strong>간단한 쿼리 모델</strong>: 프라이머리 키를 통해 데이터를 정의하고 읽어올 수 있는 간단한 쿼리 모델이 필요하고, 관계형 스키마라든지, 복잡한 테이블 연결은 불필요하다.</p></li><li><p><strong>느슨한 ACID</strong>: 트랜잭션의 ACID, 특히 일관성을 보장하는 것은 데이터 가용성 측면에서 좋지 않다. 약한 일관성을 가지고 동작하는 애플리케이션에 적합한 데이터베이스여야 한다.</p></li><li><p><strong>효율성</strong>: 아마존 플랫폼의 엄격한 지연율 제한을 여러 서비스 도메인에서 충족할 수 있어야 한다. 아마존 플랫폼은 일반적으로 500TPS 기준으로 99.9% 백분위가 300ms 안에 처리되어야 한다는 지연율 기준이 있다. 서비스마다 읽기와 쓰기 비율이 다르기 때문에 데이터베이스의 설정을 통해 어떻게 분산 환경의 읽기 쓰기를 수행할지 결정할 수 있어야 한다.</p></li></ul><blockquote><p>효율성은 조금 모호한 단어같이 보일 수 있는데, 설정값을 통해 범용적으로 인프라에 도입할 수 있다는 측면에서의 효율성을 뜻하는 것 같다.</p></blockquote><h1 id="시스템-디자인-고민"><a href="#시스템-디자인-고민" class="headerlink" title="시스템 디자인 고민"></a>시스템 디자인 고민</h1><p>위와 같은 목표를 달성하기 위해 필요한 몇 가지 고민이 있었다. 이 고민을 해결한다면 시스템 디자인의 목표를 달성할 수 있다.</p><hr><p>전통적인 RDB의 데이터 복제 알고리즘은 강력한 일관성을 위해 동기적으로 데이터를 복제한다. 이 수준의 일관성을 얻기 위해서는 특정 시나리오에서 데이터 가용성을 포기해야 한다. 즉, 높은 수준의 일관성은 정확한 답을 공유하지 못하는 불확실한 상황일 때 차라리 데이터를 사용 불가능하게 만들어버린다. 분산 시스템에서 아주 유명한 이론인 <a href="https://en.wikipedia.org/wiki/CAP_theorem">CAD 이론</a>에서 말하듯 일관성, 가용성, 그리고 네트워크 파티션 내구성 세 가지를 모두 충족시킬 수 없다. 네트워크 파티션 상황은 반드시 발생하게 되어있고, 데이터 일관성을 유지하기 위해서는 가용성을 포기해야 한다.</p><p><img src="/images/2022-04-16-dynamodb-internals-1/cad-theorem.png?style=centerme" alt="CAD 이론, 가운데는 유니콘임"></p><blockquote><p>강력한 일관성을 유지하는 데이터 복제는 “전통적”이라고 표현했지만, 이 논문이 쓰이기 전의 상황인듯 싶다. 정확한 히스토리는 잘 모르지만, 최근 RDB에서 레플리카를 운영하는 방법이 꼭 완전한 일관성을 요구하지는 않았던 것 같다.</p></blockquote><h2 id="핵심-고민"><a href="#핵심-고민" class="headerlink" title="핵심 고민"></a>핵심 고민</h2><p>Dynamo는 네트워크 장애가 무조건 발생한다는 가정 아래 가용성을 최대로 높이도록 디자인되었다. 이를 위해 데이터가 레플리카에 동기적으로 전파되도록 처리하지 않고, 비동기적으로 전파되도록 했다. 구체적으로 어떻게 전파되고, 어떤 상황에서 성공으로 판단하는지 등은 이후 후술한다. 아무튼 이러한 비동기 전파 상황에서는 데이터의 충돌 문제가 발생할 수 있다. 하나의 데이터를 수정한 값이 모종의 이유로 두 가지 이상의 버전으로 분기되는 것을 데이터 충돌 상황이라고 표현한다.</p><p><code>A</code> 노드에 <code>a</code> → <code>a&#39;</code>가 되도록 수정했는데 비동기 전파로 인해 다른 노드에 전파가 되기 전에 성공 응답을 보내고 <code>A</code> 노드에 네트워크 파티션이 발생했다고 가정해보자. 그다음 같은 데이터 <code>a</code>를 갖고 있던 <code>B</code> 노드에 <code>a</code> → <code>a&#39;&#39;</code>로 수정을 가했다면 시스템은 두 가지 버전의 <code>a</code> 데이터를 갖게 되는 것이다.</p><p><img src="/images/2022-04-16-dynamodb-internals-1/versioning.png?style=centerme" alt="예시 상황"></p><p>이 상황을 해결하는 방법은 다음 두 가지 방향의 문제를 해결하는 것이다.</p><ul><li>언제 해결할 것이냐? (쓰기 시점 or 읽기 시점)</li><li>누가 해결할 것이냐? (클라이언트 or 데이터베이스)</li></ul><p>전통적으로는 쓰기 시점에 이 문제를 해결하며 읽기 작업의 복잡도를 단순하게 유지한다. 이런 시스템에서는 주어진 타임아웃 시간 내에 모든(혹은 특정 정족수) 데이터 저장소에 닿지 못하면 쓰기가 실패할 수 있다. Dynamo는 “<strong>항상 쓰기 가능한</strong>“ 데이터 스토어를 목표로 한다. 아마존의 많은 서비스에서 고객의 업데이트 작업을 거절하는 경우 고객 경험을 해치는 결과를 가져온다. 예를 들어서 쇼핑 카트는 반드시 소비자가 담거나 지운 아이템을 네트워크 파티션이 발생하더라도 반영할 수 있어야 한다. 따라서 쓰기 작업의 가용성을 위해 Dynamo는 읽기 작업에 이 충돌 해결 역할을 맡겼다.</p><blockquote><p>쓰기 작업에서 이 문제를 해결한다면 버저닝이 발생하지 않도록 회피하는 형태로 문제를 해결한다고 볼 수 있고, 읽기 시점에서 해결한다면 문제 발견 후 복구하는 과정이 있다고 볼 수 있다.</p></blockquote><p>그다음 “누가 해결할 것인지” 선택해야 한다. 데이터베이스에서 일관적으로 처리하도록 하는 방법은 굉장히 제한적이다. 예를 들어서 마지막 업데이트가 발생한 시점을 기준으로 데이터를 덮어씌우는 방법처럼 아주 간단하고 단순한 방법으로만 문제를 해결할 수 있다. 반대로 애플리케이션에서 이를 해결하도록 두면, 데이터가 어떻게 비즈니스 로직과 연결되는지 이해하고 있기 때문에 더 적절한 방법을 선택할 수 있다. 어떻게 버저닝 문제를 해결하는지 구체적인 내용은 후술한다.</p><h2 id="기타-고려사항"><a href="#기타-고려사항" class="headerlink" title="기타 고려사항"></a>기타 고려사항</h2><p>위 가장 큰 두 가지 설계 고민 외에 다음과 같은 고민을 하며 시스템을 설계했다.</p><ul><li><p><strong>증분 확장성 (Incremental Scalability)</strong>: 데이터 스토리지 노드를 추가 또는 삭제할 때 데이터베이스 운영 및 시스템에 최소한의 영향만 주면서 이를 수행해야 한다.</p></li><li><p><strong>대칭성</strong>: 모든 스토리지 노드가 동일한 역할 수행해야 한다. 이유는 특수한 역할을 하는 노드를 지정하기 시작하면 프로비저닝 시스템의 복잡도가 증가하기 때문이다.</p></li><li><p><strong>탈중앙성</strong>: 중앙에서 컨트롤하는 시스템보다 P2P를 통한 분산된 컨트롤이 더 선호되는 방향으로 시스템을 설계한다. 이에 대해서는 구체적인 이유보다는 과거에 중앙 시스템의 문제로 인한 운영 중단 사태가 발생한 적이 있기 때문에 이를 피하기 위해서 이러한 고민을 했다고 한다.</p></li><li><p><strong>이질성 (Heterogeneity)</strong>: 시스템에서 동작하는 노드들이 불균일하다는 특성을 이용할 수 있는 시스템이어야 한다. 예를 들어 작업 분배가 각 노드의 Capacity에 비례해 분배될 수 있는 시스템이어야 한다. 이를 통해 보다 효율적으로 작업 분배가 이뤄질 수 있다.</p></li></ul><blockquote><p>시스템 목표와 그 목표를 위한 고민이 잘 매칭되는지 확인해보자. 간단한 쿼리 모델은 Key-Value 스토리지라는 점, 느슨한 ACID는 비동기적 데이터 전파를 통해 가용성을 높인다는 점(그리고 데이터 충돌을 해결하기 위한 핵심 고민 두 가지), 효율성의 경우 여러 설정값으로 위 고민을 해결하도록 했다. 이 여러 설정값에 대해서는 나중에 더 자세히 다룬다.</p></blockquote><hr><h1 id="시스템-아키텍처"><a href="#시스템-아키텍처" class="headerlink" title="시스템 아키텍처"></a>시스템 아키텍처</h1><p>위 고민을 어떻게 해결했는지 구체적으로 살펴보자. Dynamo는 독자적인 기술의 탄생이 아니고 그 전부터 논의되어온 분산 시스템을 구성하기 위한 기술들의 집합이다. 요약하자면 다음 방법들을 사용하고 있다.</p><table><thead><tr><th align="center">문제</th><th align="center">해결책</th><th align="center">해결 목표</th></tr></thead><tbody><tr><td align="center">파티셔닝 (노드 추가 or 제거)</td><td align="center">Consistency Hashing</td><td align="center">증분 확장성을 보장할 수 있음</td></tr><tr><td align="center">쓰기 HA 구성</td><td align="center">vector clock 개념과 클라이언트에서 데이터 충돌 해결</td><td align="center">쓰기 가용성이 증가</td></tr><tr><td align="center">일시적 실패</td><td align="center">쿼럼 (Quorum)과 Hinted Handoff</td><td align="center">범용적인 시스템을 위한 일시적인 실패와 복구 처리 방법</td></tr><tr><td align="center">영구적 실패</td><td align="center">Merkle trees</td><td align="center">데이터 동기화를 위한 데이터 전송량을 최소화</td></tr><tr><td align="center">멤버십, 실패 탐지</td><td align="center">가십 기반 멤버십 프로토콜</td><td align="center">노드 기능의 동일성을 유지하면서 탈중앙화 시스템을 유지할 수 있는 시스템</td></tr></tbody></table><p>글에서는 고민을 해결하기 위해 핵심적이라고 생각되는 파티셔닝문제, 쓰기 HA, 일시적 실패에 대해 다룰 예정이다.</p><h2 id="파티셔닝"><a href="#파티셔닝" class="headerlink" title="파티셔닝"></a>파티셔닝</h2><p>데이터 또는 트랜잭션이 증가함에 따라 스토리지 노드가 감당해야 하는 트랜잭션이 점점 늘어나면 이를 처리하기 위한 스토리지 노드가 추가로 붙어야 한다. 즉, 동적인 파티셔닝을 위한 방법이 필요하다. Dynamo에서는 이를 위해 <strong><a href="https://ko.wikipedia.org/wiki/%EC%9D%BC%EA%B4%80%EB%90%9C_%ED%95%B4%EC%8B%B1">Consistent Hashing</a></strong> 방법을 사용하고 있다.</p><p>Consistent Hashing은 해시 함수의 결과 범위가 고정된 원형 공간(Ring) 안에서 다뤄진다. 링 형태라는 것은 가장 큰 해시값의 마지막이 가장 작은 해시값으로 연결된다는 것을 의미한다. 해당 시스템 안에서 각 스토리지 노드는 랜덤 값이 할당되고, 이 랜덤 값의 해시값을 가지고 링 위에 위치 시키는 방법이다. 스토리지 노드 안에 들어갈 데이터 역시 키를 해싱한 값을 기준으로 링 위에 배치된다. 이때 데이터의 위치에서 시계 방향으로 돌았을 때 처음 만나게 되는 스토리지 노드에 실제 데이터가 저장되게 된다.</p><p><img src="/images/2022-04-16-dynamodb-internals-1/consistent-hashing.png?style=centerme" alt="데이터는 기본적으로 B에 담긴다"></p><p>일반적인 방법으로 데이터의 키를 해싱한 값으로 샤딩을 진행한 경우, 노드가 추가되거나 삭제될 때마다 데이터를 다시 해싱해야 하는 큰 비용이 있다. Consistent Hashing은 데이터를 균일하게 분산하면서도 노드가 추가되어도 이런 재해싱 과정 필요 없이 이웃한 노드에만 영향을 주는 방식으로 스토리지 노드를 추가한다.</p><p>동적인 스케일링을 위해 아주 적합한 방법이지만, 스토리지 노드의 이질성을 고려하지 않는다. 위에서 언급했던 “<strong>이질성</strong>“을 고려한 시스템을 위해 Dynamo는 하나의 물리적인 노드가 여러 개의 가상 노드(Virtual Node)와 매칭되며 가상 노드들이 링 위에 올라가도록 설계되었다. 각 가상 노드는 실제 물리 노드와 연결되고 가상 노드의 개수는 물리적 노드의 실제 성능에 맞게 조절된다.</p><p>즉, 성능이 좋은 스토리지 노드는 많은 가상 노드와 연결되어 링 위의 비교적 많은 영역을 담당한다. 반대의 경우 적은 수의 가상 노드와 연결되게 된다.</p><blockquote><p>랜덤하게 배치된다는 점 역시 분산이 고르지 못하다는 단점이 있다. 운영하면서 몇 가지 버전을 거친 이후 링을 고르게 나눠 노드를 배치하는 방법으로 이 문제를 해결할 수 있었다고 한다. 이 글에서는 해당 내용에 대해 설명하고 있지 않다. 궁금하다면 이 <a href="https://www.waitingforcode.com/general-big-data/dynamo-paper-consistent-hashing/read">링크</a>에서 설명을 더 읽어보자.</p></blockquote><h2 id="HA-High-Availability"><a href="#HA-High-Availability" class="headerlink" title="HA(High Availability)"></a>HA(High Availability)</h2><p>HA를 위해서는 복제 시스템이 필요하다. 즉, 데이터를 본래 저장해야 하는 스토리지 노드 외에 다른 스토리지 노드에도 저장할 수 있어야 한다. Dynamo는 몇 개의 호스트에 데이터를 복제할 것인지 설정 파라미터로 결정할 수 있도록 만들었다.</p><blockquote><p>몇 개의 호스트에 복제하는지 결정하는 파라미터는 이 글에서 <code>N</code>으로 표기한다.</p></blockquote><p><img src="/images/2022-04-16-dynamodb-internals-1/dynamo-consistent-hashing.png?style=centerme" alt="N = 3일 때, 데이터는 B, C, D 노드에 담긴다"></p><p>위 이미지에서 키 <code>K</code>를 가진 데이터는 <code>(A, B]</code> 사이에 위치하게 되고, <code>B</code> 노드에 기본적으로 저장된다. 그다음 데이터가 복제되어야 하는 노드는 <code>N - 1</code> 만큼 시계 방향으로 돌며 만나는 노드이다. <code>N = 3</code> 이라면, <code>B</code> 외 <code>C</code>, <code>D</code>도 이 데이터를 저장하는 대상이 된다.</p><p>이렇게 특정 데이터에 대해 저장할 책임이 있는 노드 리스트를 <strong>preference list</strong>라고 부른다. preference list 안에 가상 노드로 인해 물리 노드가 중복되어 들어가지 않도록 같은 물리 노드를 가리키는 가상 노드를 스킵하면서 리스트를 채운다.</p><hr><p>데이터가 여러 노드에 전파되는 것은 비동기적으로 (아직 어떻게 비동기적으로 동작하는지 설명하지 않았다. 후술할 예정) 발생한다. 이러한 이유로 Dynamo는 결과적 일관성(Eventual Consistency) 특성을 갖게 된다. 결과적 일관성은 일시적으로 데이터가 일관적이지 않을 수 있지만 결국 같은 데이터를 보장한다는 뜻이다. 예를 들어 <code>Put</code>을 호출해 데이터를 쓰는 작업을 할 때, 필요한 모든 노드에 데이터가 복제되는 것을 기다렸다가 응답을 보내주지 않는다. 아직 몇 개의 노드는 데이터를 쓰기 전이지만 <code>Put</code>에 대한 성공 응답을 보낸다. 만약 이런 상황에서 연속적으로 <code>Get</code> 요청을 보내면 어떤 노드의 데이터를 읽느냐에 따라 최신 버전의 데이터를 가져오지 못할 수도 있다는 것을 뜻한다. 위에서 살짝 예시를 들었는데, 쓰기 상황에서 이렇게 최신 데이터가 아닌 오브젝트를 기반으로 업데이트를 진행하게 되면 데이터 버저닝(분기, 데이터 충돌)이 발생한다.</p><p>앞서 언급한 것처럼 분기된 데이터를 통합하기 위해서 두 가지 결정이 필요하다. 언제 통합할 것인지? 누가 통합할 것인지? 그리고 Dynamo에서는 읽기 시점에 클라이언트에서 해결한다고 설명한다.</p><p>데이터 버저닝과 이를 해결하는 방법을 설명하기 전에 먼저 간단하게 Dynamo의 시스템 인터페이스를 확인해보자. 데이터에 접근하기 위한 <code>Get</code>과 업데이트를 위한 <code>Put</code>이 있다. 각각은 다음과 같이 호출된다.</p><ul><li><code>get(key)</code>: 스토리지 시스템에서 키와 연결된 오브젝트 복제본을 찾아 컨텍스트가 담긴 단일 오브젝트 또는 컨텍스트가 담긴 오브젝트 리스트를 반환한다.</li><li><code>put(key, context, object)</code>: 오브젝트 복제본이 연관된 키에 의존해서 어디에 위치해야 하는지 결정하고, <code>object</code>를 디스크에 쓴다.</li></ul><p><code>get</code>의 결과를 “<strong>컨텍스트가 담긴 오브젝트</strong>“라고 표현하고 있다. 컨텍스트는 <strong>데이터의 버전 정보</strong>를 포함한 메타데이터를 의미한다. 복수가 될 수 있다는 것은 하나의 데이터에 대해 여러 갈래로 나눠진 데이터 버전이 있는 경우 해당 버전들을 모두 가져오기 때문이다. <code>put</code>의 인자에서 <code>context</code>를 통해 수정 대상인 오브젝트 컨텍스트를 전달하고 기존에 나뉘어있던 버전들을 마지막 <code>put</code>을 기준으로 통합하게 한다.</p><blockquote><p>Dynamo의 쓰기 과정은 읽기 이후 쓰기를 수행하는 식으로 클라이언트에서 사용해야 하는 구조인 것으로 보인다.</p></blockquote><p>Dynamo의 오브젝트 버전 관리는 <code>vector clock</code>을 사용한다. 이는 어떤 노드에 저장되어 있는지, 몇 번째 데이터 수정인지를 담고 있는지, 이렇게 두 가지를 갖는 튜플 리스트이다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector clock = [(Node, Counter)...]</span><br></pre></td></tr></table></figure><p>컨텍스트 안의 <code>vector clock</code>을 비교해서 인과적인 순서(앞선 버전인지, 동시에 나눠진 버전인지)를 밝힐 수 있다. 많은 경우 새 버전이 과거 버전을 포함하고 있기 때문에 시스템 안에서 정규 버전(나눠진 두 버전을 조정한 새로운 버전)을 결정할 수 있다. 이렇게 시스템에서 버전을 조정하는 과정을 “<strong>syntactic reconciliation</strong>“이라고 한다. 그러나 동시 업데이트에 의한 분기는 클라이언트에 의해 조정이 된다. 위에서 언급했던 것처럼 <code>get(key)</code>를 통해 복수의 오브젝트 버전을 받으면 클라이언트에서 적절한 로직을 통해 이를 합치고 업데이트해 줘야 한다. 이렇게 클라이언트에 의해서 조정하는 것은 “<strong>semantic reconciliation</strong>“이라고 한다.</p><blockquote><p>따라서 정확하게는 Dynamo는 데이터베이스에 의한 조정과 클라이언트에 의한 조정, 두 가지 방법 모두 사용하고 있다고 볼 수 있다.</p></blockquote><h2 id="일시적-실패"><a href="#일시적-실패" class="headerlink" title="일시적 실패"></a>일시적 실패</h2><p>쓰기 동작 중 특정 노드의 장애로 인해 일시적인 실패가 발생할 수 있다. 이에 대한 처리를 <strong>Hinted Handoff</strong>라고 불리는 방식으로 해결하고 있다. 일단 이 설명을 하기 전에 먼저 “<strong>쓰기 실패 상황</strong>“ 또는 “<strong>읽기 실패 상황</strong>“을 정의해야 한다. 구체적으로 어떻게 비동기 복제를 하면서 응답을 전달해주는지 확인해보자.</p><h3 id="Sloppy-Quorum"><a href="#Sloppy-Quorum" class="headerlink" title="Sloppy Quorum"></a>Sloppy Quorum</h3><p>쿼럼(Quorum)은 “정족수”라는 뜻이다. 조금 단순하게 설명하자면 읽기의 최소 성공 수를 <code>R</code>, 쓰기의 최소 성공 수를 <code>W</code>라는 변수를 사용해 시스템에서 읽기와 쓰기의 실패 여부를 확인하는 방법이다. Dynamo 시스템에서 <code>Get</code>과 <code>Put</code> 요청은 어떤 스토리지 노드든 받을 수 있다. Read 또는 Write 요청을 처음 받은 노드를 “<strong>coordinator</strong>“라고 부른다. 일반적으로 coordinator는 preference list를 만들 때 첫 번째 노드이다.</p><blockquote><p>요청은 HTTP를 통해 전달되는데, 로드 밸런싱을 통해 앞단에서 요청을 관리한다면 coordinator는 맨 첫 번째 노드가 아닐 수도 있다. 로드 밸런서를 사용하지 않는 경우 Partition-Aware 클라이언트 라이브러리를 사용해 어떤 노드에 요청을 보내야 하는지 클라이언트에 의해 결정하도록 한다.</p></blockquote><p><img src="/images/2022-04-16-dynamodb-internals-1/quorum.png?style=centerme" alt="쓰기 성공 상태"></p><p>위 이미지처럼 복제해야 하는 노드 수만큼 preference list가 지정되고 coordinator는 이 리스트 안의 나머지 노드에 데이터를 전파한다. 그리고 정족수만큼의 정상 응답을 받으면 클라이언트에게 성공 응답을 보내준다. 예시에서는 <code>W = 2</code>로 설정되었기 때문에 위 이미지의 녹색 박스 노드에서 정상적으로 값을 저장했다면 이 요청은 성공한 요청이 된다.</p><p>이 방법은 “Strict Quorum” 시스템으로, 만약 복제되어야 하는 노드들 중에 최소 정족수만큼의 성공을 만들지 못하면 실패 처리 된다. 만약 preference list 안에 있는 <code>N</code>개의 노드 중 <code>N - W - 1</code>개만큼의 노드가 장애 상황이라면 쓰기 실패 상황이 발생한다. 그러나 아마존은 실패 처리를 극단으로 최소화하고 싶어 했다. 그래서 도입한 시스템이 “Sloppy Quorum”이다. 이름에서도 알 수 있듯 조금 느슨하게 쿼럼을 만족시키는 방식이다.</p><p>본래 preference list는 키를 해시한 다음 링 위에서 시계 방향으로 봤을 때 첫 번째로 만나는 노드를 포함해 상위 <code>N</code>개의 노드가 속하게 된다. 그런데 이 노드를 단순히 상위 <code>N</code>개가 아니라 “건강한 노드 상위 <code>N</code>개”로 만드는 것이다.</p><p><img src="/images/2022-04-16-dynamodb-internals-1/dynamo-consistent-hashing.png?style=centerme" alt="N = 3일 때, 원래 데이터는 B, C, D에 복제된다"></p><p>위 예시에서 설정 파라미터값이 <code>N = 3</code>, <code>W = 3</code>이고 만약 노드 <code>D</code>에 장애가 발생했다고 가정해보자. 그렇다면 preference list는 실제로 <code>B</code>, <code>C</code>, <code>E</code> 노드를 담고 있게 된다. 이런 방식에서 장점은 가용성을 높일 수 있다는 장점이 있지만, 문제는 약속과 다른 노드가 데이터를 저장할 수 있다. 레플리카의 범위는 노드 <code>D</code>까지인데, <code>E</code>에 데이터가 저장된 상황이다.</p><h3 id="Hinted-Handoff"><a href="#Hinted-Handoff" class="headerlink" title="Hinted Handoff"></a>Hinted Handoff</h3><p>이 문제를 해결하기 위해 <strong>Hinted Handoff</strong>라는 전략을 사용한다. <code>E</code>로 전달된 복제본 데이터는 메타 데이터 안에 원래 저장될 타겟 노드 정보를 포함하고 있다. 이 정보를 “힌트”라고 표현한 건데, 힌트가 박힌 복제본을 받으면 노드는 원래 저장소와 분리된 다른 로컬 임시 저장소에 해당 데이터를 저장한다. 본래 노드가 다시 복구되면 임시 저장소에 담긴 데이터를 보내주고 임시 저장소에서는 삭제한다.</p><hr><p>이러한 Sloppy Quorum과 Hinted Handoff를 가지고 가용성을 크게 높일 수 있게 된다. 만약 <code>W = 1</code>이라면, 모든 노드가 장애 상태여야 쓰기가 실패한다. 하지만 이 방법은 일시적인 장애 상황에서 처리를 위한 방법이고, 영구적인 실패 이후 데이터 동기화 과정을 위해서는 다른 방법이 필요하다. 간단히 설명하자면, 가지고 있는 데이터를 <a href="https://ko.wikipedia.org/wiki/%ED%95%B4%EC%8B%9C_%ED%8A%B8%EB%A6%AC">머클 트리</a>로 구성해 변경이 발생한 지점을 특정하고 변경된 부분만 데이터를 전송할 수 있게 해준다. 머클 트리로 두 노드의 데이터가 같은지 확인하는 케이스는 분산 시스템에서 자주 등장한다. 가장 유명해진 예시로는 블록체인이 있다. 이 <a href="https://medium.com/coinmonks/merkle-trees-concepts-and-use-cases-5da873702318">링크</a>에서 머클 트리에 대한 설명과 머클트리를 블록체인과 Dynamo에 적용한 유즈 케이스 설명을 확인할 수 있다.</p><h1 id="실제-운영"><a href="#실제-운영" class="headerlink" title="실제 운영"></a>실제 운영</h1><p>Dynamo는 몇 가지 서비스에서 다양한 설정값으로 사용되고 있다. 각 서비스는 데이터 버전을 합의하는 로직을 독립적으로 구성하고, 서비스의 특성에 따라서 쿼럼 파라미터인 <code>R</code>, <code>W</code>값을 설정한다. 일관성이 중요하다면 <code>W</code>값을 높게 설정하고, 읽기(쓰기) 성능 자체가 더 중요하다면 <code>R</code>(<code>W</code>)값을 낮춘다. Dynamo의 일반적인 (<code>N</code>, <code>R</code>, <code>W</code>)는 (3, 2, 2)로 구성되어있다.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf</a></li><li><a href="https://en.wikipedia.org/wiki/CAP_theorem">https://en.wikipedia.org/wiki/CAP_theorem</a></li><li><a href="https://ko.wikipedia.org/wiki/%EC%9D%BC%EA%B4%80%EB%90%9C_%ED%95%B4%EC%8B%B1">https://ko.wikipedia.org/wiki/%EC%9D%BC%EA%B4%80%EB%90%9C_%ED%95%B4%EC%8B%B1</a></li><li><a href="https://www.waitingforcode.com/general-big-data/dynamo-paper-consistent-hashing/read">https://www.waitingforcode.com/general-big-data/dynamo-paper-consistent-hashing/read</a></li><li><a href="https://www.allthingsdistributed.com/2017/10/a-decade-of-dynamo.html">https://www.allthingsdistributed.com/2017/10/a-decade-of-dynamo.html</a></li><li><a href="https://jimdowney.net/2012/03/05/be-careful-with-sloppy-quorums/">https://jimdowney.net/2012/03/05/be-careful-with-sloppy-quorums/</a></li><li><a href="https://medium.com/coinmonks/merkle-trees-concepts-and-use-cases-5da873702318">https://medium.com/coinmonks/merkle-trees-concepts-and-use-cases-5da873702318</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/database/">database</category>
      
      
      <category domain="https://changhoi.kim/tags/distributed-system/">distributed_system</category>
      
      <category domain="https://changhoi.kim/tags/dynamodb/">dynamodb</category>
      
      
      <comments>https://changhoi.kim/posts/database/dynamodb-internals-1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Learning Go 간단 리뷰</title>
      <link>https://changhoi.kim/posts/books/learning-go/</link>
      <guid>https://changhoi.kim/posts/books/learning-go/</guid>
      <pubDate>Mon, 28 Mar 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;이번년도에도 한빛 미디어의 &lt;strong&gt;나는 리뷰어다&lt;/strong&gt;에 선정되어 매달 책 한 권씩을 읽을 수 있게 됐다. 3월에는 Learning Go 책을 받아서 보게 되었다. 이 글은 해당 책에 대한 간단한 리뷰이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>이번년도에도 한빛 미디어의 <strong>나는 리뷰어다</strong>에 선정되어 매달 책 한 권씩을 읽을 수 있게 됐다. 3월에는 Learning Go 책을 받아서 보게 되었다. 이 글은 해당 책에 대한 간단한 리뷰이다.</p><span id="more"></span><p>일단 Go를 자주 사용하는 개발자로서 Go 책이 자주 보이고 있다는 점에서 굉장히 기분이 좋다. 학습을 해왔던 여러 리소스들과 비교하면서 책을 읽어봤다. 일단 책의 난도는 Go를 접한 적 없는 개발자를 위한 책이었다. 물론 개발자가 아니더고 새롭게 Go를 접하는 사람들 역시 이 책으로학습해도 좋을 것 같은 생각이 들었다. 원래 언어 학습을 위한 책들은 이 정도의 난도로 만들어지는 것 같은데 유독 Go 책은 기존에 개발을 하던 사람들 만을 대상으로 쓴 책 처럼 느껴지는 경우가 많았다. 예를 들어서 The Go Programming Language와 같은 책이 그랬다. 이 책은 내부 동작에 대한 구체적인 설명까지 하지는 않았다. 다만 아주 기초적인 CS 지식의 경우 추가 설명처럼 박스를 만들어서 해당 CS 배경 지식을 설명해준다. 예를 들어서 Map 자료구조를 이해하기 위한 Hash에 대한 기본적인 설명 등… 가장 장점으로 느껴졌던 부분은 꽤 실용적인 내용도 담고, 최신 버전의 정보들이 잘 반영되어 있다는 점이다. 초보자가 언어 학습을 위한 교재로 선택하면 좋을 것 같다고 생각했다.</p>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/books/">books</category>
      
      
      <category domain="https://changhoi.kim/tags/review/">review</category>
      
      
      <comments>https://changhoi.kim/posts/books/learning-go/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Go GC</title>
      <link>https://changhoi.kim/posts/go/go-gc/</link>
      <guid>https://changhoi.kim/posts/go/go-gc/</guid>
      <pubDate>Thu, 24 Mar 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;Go는 메모리 관리를 런타임에서 해주는 프로그래밍 언어이다. 메모리 관리라고 하면 일반적으로 힙 영역에 할당하는 메모리들 더이상 스택에서 접근할 수 없는 상태가 되면, 할당 해제하는 가비지 콜렉팅을 의미한다. 이번 글에서는 GC에 대한 전반적인 이야기와 함께, Go에서는 구체적으로 어떤지 알아보았다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>Go는 메모리 관리를 런타임에서 해주는 프로그래밍 언어이다. 메모리 관리라고 하면 일반적으로 힙 영역에 할당하는 메모리들 더이상 스택에서 접근할 수 없는 상태가 되면, 할당 해제하는 가비지 콜렉팅을 의미한다. 이번 글에서는 GC에 대한 전반적인 이야기와 함께, Go에서는 구체적으로 어떤지 알아보았다.</p><span id="more"></span><blockquote><p>💡 우선 글은 1.17 버전의 코드를 보면서 작성되었다.<br>💡 글에서 <code>GC</code>라는 말은 “가비지 콜렉터”를 의미하기도 하고 “가비지 콜렉터의 동작”을 의미하기도 한다. 동사로 사용되었으면 콜렉터의 동작, 명사면 콜렉터라고 이해하면 좋을 것 같다.</p></blockquote><h1 id="흔히-알려진-설명"><a href="#흔히-알려진-설명" class="headerlink" title="흔히 알려진 설명"></a>흔히 알려진 설명</h1><p>GC에 대한 아주 개략적인 Overview이다. 현대 많은 언어는 GC와 함께 메모리 관리를 도와주고 있다. 일반적으로 프로그램에서 동적 할당을 하게 되면 프로세스의 힙(Heap) 영역에 메모리를 할당하게 되어있다.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Person p = <span class="keyword">new</span> Person(); <span class="comment">// 힙 사용</span></span><br></pre></td></tr></table></figure><p>이때, 힙 영역에 할당된 메모리를 할당 해제 해줘야 하는데, 이 과정을 개발자가 직접 하는 경우가 있고, 언어의 런타임 레벨에서 자동으로 해주는 경우가 있다. 이때 자동으로 해주는 컴포넌트의 이름이 GC이다.</p><p>GC는 대략 다음과 같은 흐름을 갖는다.</p><ol><li>GC 수행 시간 동안 GC 스레드를 제외하고 모든 스레드 정지</li><li>GC는 참조할 수 없는 객체를 확인하고 메모리 할당 해제</li><li>GC가 끝난 후 정지된 애플리케이션 스레드를 다시 재개</li></ol><p>1번의 정지되는 순간을 <strong>STW</strong> (<code>Stop The World</code>)라고 부른다. 이때 STW가 발생하는 순간은 GC 수행의 전체 과정이 아닐 수 있다. 어떤 알고리즘을 사용하는지에 따라 어떤 구간에서 STW가 발생할지 달라진다. 아무튼 GC가 발전하는 과정은 이 STW 시간을 줄이는 과정이고 GC를 튜닝하는 이유도 대부분 STW를 줄이기 위함이다.</p><h1 id="알려진-방법들"><a href="#알려진-방법들" class="headerlink" title="알려진 방법들"></a>알려진 방법들</h1><p>GC의 핵심적인 동작을 수행하는 두 가지 알고리즘을 가져왔다. 첫 번째는 <strong>Mark &amp; Sweep</strong> 방식이고, 두 번째는 <strong>Reference Counting</strong>이다.</p><h2 id="Mark-amp-Sweep"><a href="#Mark-amp-Sweep" class="headerlink" title="Mark &amp; Sweep"></a>Mark &amp; Sweep</h2><p>이름이 아주 직관적인데, 말 그대로 지워야 하는 오브젝트를 마킹하고 청소하는 방법이다. 스택에서 힙을 참조하고 있는 루트 포인터를 찾아서 해당 루트 노드부터 체이닝 하면서 접근할 수 있는 오브젝트를 제거 대상에서 제외한다. 모두 순회하고 나서는 아직 제거 대상에 있는 오브젝트를 할당 해제하는 방식이다. Go와 JVM, JS에서 이 알고리즘을 사용한다.</p><p><img src="/images/2022-03-25-go-gc/marksweep.gif?style=centerme" alt="Mark &amp; Sweep"><br><small style="center">이미지 출처: <a href="https://deepu.tech/memory-management-in-programming/">링크</a></small></p><h2 id="Reference-Counting"><a href="#Reference-Counting" class="headerlink" title="Reference Counting"></a>Reference Counting</h2><p>모든 오브젝트들이 참조 횟수 카운터를 갖고, 카운터가 0이 되는 오브젝트를 GC가 지우는 방식이다. 이 방법은 Python, PHP에서 사용 중인데, 근본적으로 순환 참조하고 있는 오브젝트에 대한 GC가 이루어질 수 없다. 이를 처리하기 위한 추가적인 컴포넌트와 함께 동작해야 한다.</p><hr><p>여기 <a href="https://spin.atomicobject.com/2014/09/03/visualizing-garbage-collection-algorithms/">링크</a>에서 여러 GC들의 할당과 해제 모습을 시각화해서 보여주고 있다. 여기 작성된 알고리즘 외, 추가로 몇 가지가 더 설명되어 있으니 궁금하다면 위에서 간략하게 소개된 방법들에 대해 알아보면 좋을 것 같다.</p><h1 id="GC를-구성하는-것들"><a href="#GC를-구성하는-것들" class="headerlink" title="GC를 구성하는 것들"></a>GC를 구성하는 것들</h1><p>아! Go, JVM, JS는 Mark &amp; Sweep! 끄덕 끄덕, 하고 끝나면 좋겠지만 편한 프로그래밍의 뒷면은 그렇게 단순하지는 않다. 위에서 “<strong>알려진 방법들</strong>“로 소개한 방법들은 핵심적인 콜렉터의 동작 알고리즘에 관한 내용이고, GC를 구현한 언어에 따라 추가적인 기술이나 컴포넌트가 존재한다. Java의 GC가 굉장히 대표적이고 유명하다는 생각이 들어서, Go의 GC에 대한 구체적인 내용을 설명하기 전에 JVM에서 사용하고 있는 GC의 구성을 조금 더 살펴보고 이를 Go와 비교해보려고 한다.</p><h2 id="세대별-GC"><a href="#세대별-GC" class="headerlink" title="세대별 GC"></a>세대별 GC</h2><p>Generational GC라고 불리는 GC 방법이다. 세대별이라는 말은 힙 영역을 세대별로 나눠 관리한다는 것을 의미한다. “세대”는 오래 살아남은 객체와 그렇지 않은 객체를 구분 짓는 것을 의미한다. 이 GC는 다음과 같은 대전제를 바탕으로 설계되었다.</p><ol><li>대부분의 객체는 금방 접근 불가능 상태가 된다.</li><li>오래된 객체에서 새로운 객체를 참조하는 일은 드물게 발생한다.</li></ol><p>위 대전제의 이름은 <a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/generations.html">Weak Generational Hypothesis</a>라고 한다. 이 가설을 이용해 <code>Old</code> 객체를 담는 영역과 <code>Young</code> 영역의 객체를 담는 영역으로 힙을 나눈다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                    &lt;---- Tenured ----&gt;</span><br><span class="line">+----------+---+---+---------+---------+</span><br><span class="line">|   Eden   | S | S |         | Virtual |</span><br><span class="line">+----------+---+---+---------+---------+</span><br><span class="line">&lt;----- Young ------&gt;</span><br><span class="line"></span><br><span class="line">S: Survivor</span><br></pre></td></tr></table></figure><ul><li>Young 영역: 새롭게 생성된 객체가 위치한다. 가설대로 많은 객체가 이곳에서 새로 만들어졌다가 사라진다. 이곳에서 발생하는 GC는 <strong>Minor GC</strong>라고 불린다.</li><li>Old 영역: Young 영역에서 살아남은 객체가 여기 복사된다. Young 영역에 비해 크기가 크고, GC는 덜 자주 발생한다. 이곳에서 발생하는 GC는 <strong>Major GC</strong> 또는 <strong>Full GC</strong>라고 한다.</li></ul><p>이 방법을 통해 일반적인 상황에서는 Minor GC로 간단하게 GC를 수행하게 된다. 큰 힙 영역을 다 확인할 필요 없이 일부만 확인할 수 있으므로 GC 속도가 빠르다.</p><blockquote><p>💡 따라서 넓은 범위를 확인해야하는 Full GC가 자주 발생하는 상황은 문제가 있는 상황일 수 있다.</p></blockquote><p>만약 2번 전제 상황이 발생하였을 때 GC가 어떻게 Old 영역이 참조하고 있는 Young 영역의 객체를 할당 해제하지 않을 수 있을까? 이를 위해 Old 영역에서 Young 영역의 객체를 참조하고 있는지 기록하는 Card Table을 사용한다. 이 테이블은 512 바이트의 청크로, Old 영역을 모두 확인하지 않고도 이 부분을 확인함으로써 Young 영역의 객체가 지워지는 것을 방지할 수 있다.</p><h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><p>힙 영역에 메모리를 할당하고 해제하는 과정이 반복되면 단편화 문제가 발생할 수 있다. 짧게 단편화에 대해 설명하자면, 전체적인 메모리 양은 요청된 메모리를 할당하기에 충분한 양인데, 연속되지 않아서 할당할 수가 없는 상황을 <strong>외부 단편화</strong>라고 부른다. 메모리가 비효율적으로 사용되고 있는 상황이고, 이런 파편화된 메모리 상태에서는 메모리 할당을 위해 메모리 공간을 찾는 시간도 늘어난다.</p><blockquote><p>💡 <a href="https://en.wikipedia.org/wiki/Mark-compact_algorithm">Mark-Compact 방식</a>을 쉽게 찾아볼 수 있었는데, 위에서 간단히 설명한 Mark &amp; Sweep 방식에서 컴팩팅을 추가한 방식이다. 마킹 페이즈 이후 컴팩팅 페이즈가 존재해서 데이터들을 압축하고 이동한 오브젝트의 포인터를 업데이트 하는 과정을 거치게 된다.</p></blockquote><h1 id="Go의-GC"><a href="#Go의-GC" class="headerlink" title="Go의 GC"></a>Go의 GC</h1><p>이제 Go에서 어떻게 GC를 구성하고 있는지 확인해보자. <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.8:src/runtime/mgc.go">Go의 코드</a> 주석으로 설명된 바에 따르면 Go는 비세대별, 비압축, Concurrent Tri-color Mark &amp; Sweep이라고 한다.</p><ul><li>비세대별: 힙 영역을 세대별로 관리하지 않는다.</li><li>비압축: 힙 영역의 Compaction을 수행하지 않는다.</li><li>Concurrent Tri-color Mark &amp; Sweep: 마킹과 해제 과정이 STW 없이 애플리케이션과 동시에 동작하고, 삼색 마킹 알고리즘으로 구현되어 있다.</li></ul><h2 id="Collector"><a href="#Collector" class="headerlink" title="Collector"></a>Collector</h2><p>Go GC는 세 개의 페이즈를 수행한다. 이 페이즈들 중 두 개는 STW를 유발하고, 다른 한 페이즈는 애플리케이션의 CPU 처리량을 느리게 만든다. 세 개의 페이즈는 다음과 같다.</p><ul><li>Mark 준비 - STW</li><li>Marking - Concurrent</li><li>Mark 종료 - STW</li></ul><h3 id="Mark-준비-STW"><a href="#Mark-준비-STW" class="headerlink" title="Mark 준비 - STW"></a>Mark 준비 - STW</h3><p>GC가 시작되면서 가장 먼저 해야 할 일은 <strong>Write Barrier</strong>가 동작하도록(Enabled) 만드는 것이다. Go에서 Write Barrier는 동시적인 GC 마킹 과정에서도 힙 영역의 데이터 정합성을 유지해주는 장치이다. 위에서 살짝 써놨는데, 마킹 단계는 애플리케이션 고루틴과 GC 고루틴이 동시에 동작한다. 마킹을 하던 도중 애플리케이션 고루틴에서 힙 영역에 대한 변경 작업을 하게 되면 GC도 이를 인지하고 적절한 조치를 취해야 한다. 이것을 가능하게 해주는 것이 Write Barrier이다. 구체적으로 어떻게 해주는지는 이후 설명한다.</p><blockquote><p>💡 Write Barrier라는 용어나 컴포넌트가 Go GC의 특수한 개념은 아니다. 동시적인 힙 영역에 대한 접근을 하기에 앞서 필요한 전처리 작업을 해주는 장치 정도로 사용이 되는 것 같은데, Java에서는 Old 영역에서 Young 영역을 참조할 때 Card Table에 기록하는 역할을 Write Barrier가 한다.</p></blockquote><p>Write Barrier가 시작되려면 모든 애플리케이션의 고루틴들이 멈춰야 한다. 일반적으로 이 동작은 아주 빨라서 STW가 거의 발생하지 않는 것처럼 보인다.</p><h3 id="Marking-Concurrent"><a href="#Marking-Concurrent" class="headerlink" title="Marking - Concurrent"></a>Marking - Concurrent</h3><p>Write Barrier가 켜지고 나면 마킹이 시작된다. GC가 이 단계에서 처음 하는 일은 25% 정도의 CPU 처리량을 가져오는 것이다. 예를 들어 4개의 P가 있으면 그중 하나는 GC를 수행하기 위해 점유(dedicated)된다.</p><p><img src="/images/2022-03-25-go-gc/gc-dedicated.png?style=centerme" alt="Dedicated Goroutine"></p><blockquote><p>💡 위 이미지는 Go의 고루틴 스케줄링에 대해 알고 있으면 이해가 편한데, 만약 모른다면 사용 중인 스레드 중 하나가 점유된 이미지라고 이해하자. 그러나 엄밀히 말하면 틀린 소리기 때문에 시간이 된다면 Go GMP 구조에 대해 알아보자.</p></blockquote><p>그다음 진짜 마킹을 하게 된다. 일단 현재 존재하는 모든 애플리케이션 고루틴 스택을 확인하면서 힙을 참조하고 있는 포인터를 확인한다. 스택을 스캔하는 과정은 해당 고루틴을 멈추게 한다. 하지만 그 이후 힙 안에서 오브젝트들을 따라가는 과정은 애플리케이션 고루틴과 동시에 동작한다. 다만 25%가량의 CPU 처리량을 사용하지 못하기 때문에 그만큼의 성능 저하가 발생한다.</p><p>만약 할당 속도가 너무 빨라서 고루틴이 사용 중인 힙 메모리 한계에 도달 전에 마킹 작업이 완료되지 못한다면 어떻게 될까? 할당이 지속되어 해당 오브젝트를 마킹 하느라 마킹 작업이 끝나지 않는다면? 이 상황이면 고루틴의 할당 속도를 낮출 필요가 있다.</p><p>GC가 힙 할당 속도를 제어해야 하는 상황이 되면 애플리케이션 고루틴 중에서 마킹 작업을 도와줄 어시스트 고루틴을 선정한다. 이를 <strong>Mark Assist</strong>라고 부른다. 애플리케이션 고루틴이 Mark Assist 역할을 하는 시간은 힙 영역에 추가되는 데이터 양에 비례한다. Mark Assist가 선정되면 그만큼 애플리케이션의 할당 속도는 줄고, 마킹 작업 속도가 빨라지는 효과가 있다. 그러나 애플리케이션 로직을 수행하는 비율이 더 줄어드는 것이기 때문에 속도 저하의 원인이 되기도 한다.</p><hr><p>Tri-color Mark &amp; Sweep에 대해 자세히 알아보자. 아래 이미지가 알고리즘 방식이다.</p><p><img src="/images/2022-03-25-go-gc/tricolor.gif?style=centerme" alt="Tri-color Mark &amp; Sweep"><br><small>이미지 출처: <a href="https://programming.vip/docs/deep-understanding-of-go-garbage-recycling-mechanism.html">링크</a></small></p><ol><li>먼저 모든 오브젝트는 하얀색 집합에서 시작한다.</li><li>루트 오브젝트를 회색 마킹한다.</li><li>회색으로 마킹된 오브젝트를 순회하면서 참조하고 있는 오브젝트들을 회색으로 칠한다.</li><li>순회를 마친 회색 오브젝트는 검은색으로 마킹한다.</li><li>3, 4번 스탭을 회색 오브젝트가 없어질 때까지 반복한다.</li><li>여전히 흰색 집합에 있는 오브젝트를 할당 해제한다.</li></ol><p>위 과정은 STW 상태가 아니기 때문에 동시에 오브젝트 변경이 지속해서 발생한다. 위에서 언급한 것처럼 GC가 동작하는 도중에 애플리케이션 고루틴이 힙에 변경을 가하면 Write Barrier가 적절한 조치를 취한다. 예를 들어서 GC 도중 스택에서 새롭게 할당하는 오브젝트는 바로 검은색으로 마킹한다.</p><p>이미 존재하는 오브젝트 트리 구조에서 변경점이 생기면 Write Barrier에서는 변경이 생기기 전 <code>Original Pointer</code>와 변경이 생긴 <code>New Pointer</code>를 기록하고 두 포인터 모두 마킹 처리를 한다.</p><p><code>Original Pointer</code>에 마킹처리를 하는 이유는 포인터 값을 스택이나 레지스터에 복사해두는 경우, Write Barrier를 거치지 않기 때문이다. Write Barrier는 힙 영역을 대상으로 발생하는 변경 점에 대한 전처리 작업을 하는 것이기 때문에, 로컬 스택이나 레지스터에 복사가 발생했는지 알 수 없다.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">go</span>] b = obj</span><br><span class="line">[<span class="keyword">go</span>] oldx = <span class="literal">nil</span></span><br><span class="line">[gc] scan oldx...</span><br><span class="line">[<span class="keyword">go</span>] oldx = b.x <span class="comment">// b.x를 Write Barrier를 거치지 않고 로컬 변수 oldx에 복사한다.</span></span><br><span class="line">[<span class="keyword">go</span>] b.x = ptr <span class="comment">// Write Barrier는 원래 b.x 값 역시 체크한다.</span></span><br><span class="line">[gc] scan b...</span><br><span class="line"><span class="comment">//만약 Write Barrier가 원래 값을 마킹하지 않는다면 oldx가 스캔 되지 않는다.</span></span><br></pre></td></tr></table></figure><p>위와 같은 상황처럼, 스택에 복사된 상태로 사용할 때, 스캔하면서 할당 해제되는 상황을 막아준다.</p><p><code>New Pointer</code> 역시 마킹 처리하는 이유는 다른 고루틴에서 포인터의 위치를 바꿀 수 있기 때문이다.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">go</span>] a = ptr</span><br><span class="line">[<span class="keyword">go</span>] b = obj</span><br><span class="line">[gc] scan b...</span><br><span class="line">[<span class="keyword">go</span>] b.x = a <span class="comment">// Write Barrier는 새로운 b.x 값을 마킹하도록 한다.</span></span><br><span class="line">[<span class="keyword">go</span>] a = <span class="literal">nil</span></span><br><span class="line">[gc] scan a...</span><br><span class="line"><span class="comment">//만약 새로운 값을 마킹하지 않는다면, ptr 값은 스캔 되지 않는다.</span></span><br></pre></td></tr></table></figure><p>위 상황처럼 만약 Write Barrier가 없다면 이미 스캔을 진행한 오브젝트에 아직 스캔을 진행하지 않은 포인터가 붙고 기존의 포인터를 담던 변수에서 제거되면 해당 힙 오브젝트가 스캔 되지 않을 수 있다.</p><p>이런 이유로 Write Barrier가 <code>Original Pointer</code>, <code>New Pointer</code> 모두 마킹 작업을 수행하도록 만들어주고, 동시적인 상황에서도 안전하게 힙 마킹을 유지할 수 있다.</p><h3 id="Mark-종료-STW"><a href="#Mark-종료-STW" class="headerlink" title="Mark 종료 - STW"></a>Mark 종료 - STW</h3><p>마킹 작업이 끝나면 Write Barrier와 Mark Assist를 종료하고 다음 GC가 동작할 목표치를 계산하게 된다. 이 과정은 STW 없이 동작할 수 있는데, 구현 시 코드 복잡성이 과하게 증가하는 반면 그에 비해 얻는 이점이 너무 작아 STW 상태로 진행된다고 한다.</p><p>다음 GC 수행을 위한 목표치 계산 알고리즘을 <strong>Pacing Algorithm</strong>이라고 부른다. 알고리즘은 콜렉터가 실행 중인 애플리케이션의 힙 사이즈 정보와, 힙에 가해지는 강도(Stress)에 의해 정의된다. Go에서는 GC Percent 값을 Go 환경 변숫값으로 설정해 GC가 동작하는 속도를 조절할 수 있다. 이 환경 변수 이름은 <code>GOGC</code>인데, 기본값은 100이다. 이는 현재 정리된 이후 힙 메모리보다 100% 커지면 다시 GC가 동작한다는 것을 의미한다. 즉, 기본값으로는 대략 2배 사이즈가 될 때마다 GC가 동작한다.</p><h3 id="Sweep-과정"><a href="#Sweep-과정" class="headerlink" title="Sweep 과정?"></a>Sweep 과정?</h3><p>어떤 글에서는 Sweep 페이즈에 대해 따로 페이즈로 나눠서 설명하기도 하는데, 이는 GC 사이클과 조금 독립적으로 동작하기 때문에 GC의 페이즈로 설명하지 않았다. Sweep은 애플리케이션과 함께 동시적으로 동작하는데, 애플리케이션에서 힙 영역에 할당을 요청했을 때 필요한 경우 삭제 처리된 오브젝트를 게으르게 할당 해제한다. 즉, 할당 시점에 Sweep이 발생하고 GC 수행 시간과는 무관하다. 그리고 다음 GC가 수행되기 전까지 아직 청소되지 않은 메모리 영역이 있다면, 모두 클린업 처리해주면서 다음 GC가 시작된다.</p><h2 id="비압축-방식"><a href="#비압축-방식" class="headerlink" title="비압축 방식"></a>비압축 방식</h2><p>압축을 통해 단편화 문제를 해결할 수 있는데, Go는 이 방법을 사용하고 있지 않다. 그렇다면 이 문제는 어떻게 해결하고 있을까? 이 문제는 현대 메모리 할당 방식에서 많이 해결해주고 있다고 한다. 전통적으로 프로세스 안에서 힙을 공유해 메모리를 할당해주는 방식은 멀티 스레드 프로그래밍에서는 그다지 적합한 방식이 아니다. 힙에 접근해 할당하는 과정에 Lock이 필요하기 때문이다. Go는 Google에서 만든 <strong>TCMalloc</strong>이라는 메모리 할당 방식을 활용하고 있다.</p><blockquote><p>💡 “TCMalloc Like”라고 표현하던데, <a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html">TCMalloc</a> 방법을 사용했다고 이해해도 무방할 것 같다.</p></blockquote><h3 id="메모리-할당-방법-Overview"><a href="#메모리-할당-방법-Overview" class="headerlink" title="메모리 할당 방법 Overview"></a>메모리 할당 방법 Overview</h3><p>조금 개괄적으로 설명하자면, TCMalloc은 중앙 힙과 함께 스레드마다 로컬 스레드 캐시를 가지고 있고, 작은 할당은 로컬 스레드 캐시에서 해결한다. 필요에 따라 로컬 스레드 캐시에 새로운 메모리 영역을 할당해주거나, 중앙 힙에서 직접 큰 메모리 덩어리를 떼어 사용하기도 한다. 로컬 스레드 캐시로 인해 Lock이 필요 없는 할당이 빠르게 진행되기도 하고, 힙의 파편화된 영역을 최소화할 수 있는 원리로 작용하는 것 같다.</p><hr><p>아래 구체적인 내용은 몰라도 남은 내용들을 이해하는 데 문제가 없다. 궁금한 사람들은 보기로 하자.</p><h3 id="작은-메모리-할당"><a href="#작은-메모리-할당" class="headerlink" title="작은 메모리 할당"></a>작은 메모리 할당</h3><p>위에서 짧게 설명했지만, 작은 메모리를 할당하는 전략과 큰 메모리를 할당하는 전략이 다르다. 작은(32kb 이하) 할당을 할 때는 로컬 캐시인 <code>mcache</code>라고 불리는 메모리를 가져오려고 한다. 이 캐시는 32kb 짜리 청크 리스트인 <code>mspan</code> 리스트를 가지고 있다.</p><p><img src="/images/2022-03-25-go-gc/mcache.png?style=centerme" alt="mcache &amp; mspan"><br><small>이미지 출처: <a href="https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44">링크</a></small></p><p>고루틴 G를 처리하는 P에서 물고 있는 <code>mspan</code> 중 하나의 캐시를 사용해서 작은 범위의 할당을 한다. 이 과정은 힙 영역이 아니라서 Lock이 불필요하다. <code>mspan</code>은 32kb를 여러 사이즈로 나눈 여러 종류로 가지고 있다. 8bytes부터 32kb까지 클래스가 나눠진다.</p><p><img src="/images/2022-03-25-go-gc/mspan-class.png?style=centerme" alt="mspan 클래스"><br><small>이미지 출처: <a href="https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44">링크</a></small></p><p>그럼 만약 할당하려고 할 때 이 <code>mspan</code> 리스트에 충분한 슬롯이 없다면 어떻게 될까? Go는 중앙에 <code>mcentral</code>이라고 하는 메모리 공간을 관리한다. <code>mcentral</code>에는 두 가지 종류의 스판 리스트가 있다. 하나는 꽉 찬 스판과 다른 하나는 그렇지 않은 스판 리스트이다.</p><p><img src="/images/2022-03-25-go-gc/mcentral.png?style=centerme" alt="mcentral"><br><small>이미지 출처: <a href="https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44">링크</a></small></p><p><code>mcentral</code>에서는 스판 리스트가 양방향 연결 리스트로 되어있다. <code>mcache</code>에서 <code>mspan</code>이 꽉차게 되면 <code>mcentral</code>에서 빈 스판 리스트를 가져온다.</p><p><img src="/images/2022-03-25-go-gc/new-mspan.png?style=centerme" alt="새로운 mspan"><br><small>이미지 출처: <a href="https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44">링크</a></small></p><p>만약 <code>mcentral</code>에서 제공할 수 있는 리스트가 없으면 힙에서 새로 할당받는다.</p><p><img src="/images/2022-03-25-go-gc/new-mcentral.png?style=centerme" alt="새로운 mcentral 스판 리스트"><br><small>이미지 출처: <a href="https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44">링크</a></small></p><p>힙이 메모리가 더 필요한 경우 OS로부터 메모리를 가져온다. 이때 새롭게 할당하는 영역은 <code>arena</code>라고 불리는 커다란 메모리 덩어리이다. 64bits 아키텍처일 때 64MB를 할당받고, 32bits인 경우 4MB를 할당받는다.</p><h3 id="큰-메모리-할당"><a href="#큰-메모리-할당" class="headerlink" title="큰 메모리 할당"></a>큰 메모리 할당</h3><p>32kb보다 큰 메모리를 할당하게 되면 로컬 캐시를 사용하지 않는다. 할당되는 메모리 사이즈는 페이즈 사이즈로 올림 처리해 힙에 직접 할당한다.</p><hr><p>대략적인 전체 흐름 이미지는 다음과 같다.<br><img src="/images/2022-03-25-go-gc/memory-overview.png?style=centerme" alt="Overview"><br><small>이미지 출처: <a href="https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44">링크</a></small></p><h2 id="비세대별-GC"><a href="#비세대별-GC" class="headerlink" title="비세대별 GC"></a>비세대별 GC</h2><p>힙 메모리를 스캔하는 범위를 좁히는 방법으로 비세대별 GC에 관해 설명했었다. Go에서는 이 부분이 <a href="https://groups.google.com/g/golang-nuts/c/KJiyv2mV2pU/m/wdBUH1mHCAAJ">도입되면 충분히 장점이 있을 것이라고 하지만</a>, 현재는 도입된 상태가 아니라고 한다.</p><p>Go에서는 컴파일 최적화 과정인 Escape Analysis 단계에서 다른 언어와 다르게 실제 동적 할당하는 많은 부분을 스택에 할당하도록 한다. 세대별 알고리즘의 대전제인 “많은 오브젝트들은 수명이 짧다”에 해당하는 부분을 스택에 할당함으로써 GC의 대상이 아니게 만들어준다. 따라서 다른 언어에 비해 세대별 GC를 사용하는 것으로 생길 수 있는 장점이 비교적 작다.</p><hr><p>일단 여기까지 내용이 Go의 GC가 어떻게 동작하는지, 그리고 왜 이런지에 관한 내용이다. 이후는 GC를 컨트롤하려는 케이스를 예시로 가져왔다. 위 내용을 모두 포함하고 있어서, 잘 이해했다면 아래 내용이 재밌다.</p><h1 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h1><h2 id="GC-Tuning-옵션에-관한-이야기"><a href="#GC-Tuning-옵션에-관한-이야기" class="headerlink" title="GC Tuning 옵션에 관한 이야기"></a>GC Tuning 옵션에 관한 이야기</h2><p><a href="https://youtu.be/uyifh6F_7WM">dotGo 2019 컨퍼런스</a>에서 Go GC를 어떻게 쓸 수 있는지 설명한 얘기가 있다. Go는 GC 관련 설정을 할 수 있는 방법이 위에서 언급한 <code>GOGC</code> 환경 변숫값 하나뿐이다. 다음 두 가지 상황에서 <code>GOGC</code>가 어떻게 될지 설명하고 있다.</p><ul><li><p>상황 1: 안정적인 큰 데이터셋이 있다면?<br>예를 들어서 20GB가 고정된 사이즈의 데이터라고 해보자. <code>GOGC=100</code>이라면 다음 GC는 40GB가 될 때 발생한다. 메모리 낭비가 굉장히 심한 상황인데 <code>GOGC=50</code>으로 바꾸면 30GB에 동작하게 바뀐다.</p></li><li><p>상황 2: 고정된 데이터 사이즈가 없는 애플리케이션 (작은 힙을 가지고 시작)<br>10MB의 힙 사이즈를 들고 시작했다고 가정해보자. GC는 20MB에 발생할 것이고, 정리되고 나서도 금방 다음 GC 사이클이 돌아온다. 이런 경우 <code>GOGC</code> 사이즈를 조금 여유있게 잡아주면 GC가 덜 발생한다.</p></li></ul><hr><p>위 컨퍼런스의 내용을 대충 요약하면 고정 메모리 소비량이 많으면 메모리 효율성을 위해 <code>GOGC</code> 값을 줄이고, 그 반대 상황에서는 GC 사이클을 줄이기 위해 <code>GOGC</code> 값을 크게 만들자는 내용이다. 굉장히 단순한 방법.</p><h2 id="Twitch에서-Go-애플리케이션의-힙-사이즈를-수동으로-조절해-GC-OPS를-줄인-이야기"><a href="#Twitch에서-Go-애플리케이션의-힙-사이즈를-수동으로-조절해-GC-OPS를-줄인-이야기" class="headerlink" title="Twitch에서 Go 애플리케이션의 힙 사이즈를 수동으로 조절해 GC OPS를 줄인 이야기"></a>Twitch에서 Go 애플리케이션의 힙 사이즈를 수동으로 조절해 GC OPS를 줄인 이야기</h2><p>Twitch는 Visage라는 프론트앤드가 바라보고 있는 API Gateway 앱을 가지고 있다. 이 앱은 EC2 + LoadBalancer 위에서 돌고있는 Go 애플리케이션이다. AWS 컴포넌트로 기본적인 스케일링 처리가 가능하지만, 애플리케이션 자체적으로 CPU 처리량이 급격히 떨어지는 상황이 있었다고 한다. Twitch에서는 이를 “리프레시 스톰”이라고 불렀다. 인기 있는 방송인의 인터넷 상태가 안 좋아지는 경우 시청자들이 다 같이 새로고침을 연타하는 경우 생기는 문제이기 때문이다. 이 경우에는 평소보다 약 20배가 넘는 트래픽을 유발한다고 한다.</p><p>트위치는 Go 프로파일링 옵션을 프로덕션에서도 켜놔서 쉽게 프로파일링 결과를 얻을 수 있었는데, 다음과 같은 보고를 얻었다고 한다.</p><ul><li>안정적인 상태에서는 GC가 초당 8 - 10회 발생 (8 ~ 10 OPS)</li><li>30%의 CPU 사이클이 GC와 유관한 함수를 호출하기 위해 사용</li><li>리프래시 스톰 상황에서는 GC OPS 급증</li><li>평균적인 힙 사이즈는 450MiB</li></ul><blockquote><p>💡 프로파일링 옵션을 켜두는 것이 그렇게 오버헤드가 있지는 않다고 한다. Excution tracer는 오버헤드가 있을 수 있는데 시간당 몇 초 정도 수행할 정도로 수행 빈도가 별로 안된다고 한다.</p></blockquote><p>GC OPS를 줄이고 STW 시간을 줄일 목적으로 밸러스트(바닥짐, Ballast)를 수동으로 만들어줬다. 앱이 시작할 때 아주 큰 메모리 사이즈를 힙에 할당해버리는 방법이었다.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"> <span class="comment">// 10 GiB 할당 해버리기</span></span><br><span class="line"> ballast := <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">10</span>&lt;&lt;<span class="number">30</span>)</span><br><span class="line"> <span class="comment">// 앱 실행 진행</span></span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>기본 <code>GOGC</code>를 유지한 상태였기 때문에, 밸러스트를 만듦으로써 약 10GB의 할당이 더 발생해야 GC가 동작했다. 결과적으로는 GC OPS가 99% 감소했다.</p><p><img src="/images/2022-03-25-go-gc/twitch-gc-rate.png?style=centerme" alt="GC Rate"><br><small>이미지 출처: <a href="https://blog.twitch.tv/en/2019/04/10/go-memory-ballast-how-i-learnt-to-stop-worrying-and-love-the-heap/">링크</a></small></p><p>CPU 활용도 30%가량 내려갔다.</p><p><img src="/images/2022-03-25-go-gc/twitch-cpu-util.png?style=centerme" alt="CPU Utilization"><br><small>이미지 출처: <a href="https://blog.twitch.tv/en/2019/04/10/go-memory-ballast-how-i-learnt-to-stop-worrying-and-love-the-heap/">링크</a></small></p><p><code>GOGC</code>를 설정하지 않고 직접 밸러스트를 만든 이유는 다음과 같다.</p><ul><li>GC 발생 비율은 관계가 없고, 총 메모리 사용량이 더 중요한 상황</li><li>밸러스트와 같은 효과를 발생시키려면 아주 큰 <code>GOGC</code>가 필요한데, 그렇게 하면 힙에 유지되는 메모리의 크기 변경에 아주 민감해짐</li><li>라이브 메모리와 변화하는 비율을 추론하는 것 보다, 전체 메모리를 추론하는 것이 훨씬 쉬움</li></ul><p>그렇다면 소중한 10GiB 메모리가 그대로 소비되는 것은 아닐까? 실제 시스템 메모리는 OS에 의해 페이지 테이블을 통해 가상 주소가 지정되고 물리 메모리와 매핑된다. 위 밸러스트를 설정하는 코드가 실행되면 가상 메모리에 배열이 할당되고 실제 읽기 쓰기를 시도하면 페이지 폴트가 발생하면서 실제 메모리에 적재하는 과정이 발생한다. 따라서, 밸러스트가 물리 메모리를 차지하고 있지는 않다.</p><p>API 레이턴시 역시 많이 향상되었는데, Twitch는 처음에는 STW 자체가 줄어서라고 생각했지만, 실제로 STW가 줄어든 절대적인 시간 자체는 아주 짧았다. 실제로 성능 향상에 많은 영향을 줬던 것은 Mark Assist가 줄었기 때문이다. 위에서 언급했던 것처럼 Mark Assist가 동작하면 애플리케이션 입장에서는 CPU 처리량을 더 뺏기는 것이기 때문에 처리량이 줄어든다.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://deepu.tech/memory-management-in-programming/">https://deepu.tech/memory-management-in-programming/</a></li><li><a href="https://spin.atomicobject.com/2014/09/03/visualizing-garbage-collection-algorithms/">https://spin.atomicobject.com/2014/09/03/visualizing-garbage-collection-algorithms/</a></li><li><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/generations.html">https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/generations.html</a></li><li><a href="https://d2.naver.com/helloworld/1329">https://d2.naver.com/helloworld/1329</a></li><li><a href="https://en.wikipedia.org/wiki/Mark-compact_algorithm">https://en.wikipedia.org/wiki/Mark-compact_algorithm</a></li><li><a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.8:src/runtime/mgc.go">https://cs.opensource.google/go/go/+/refs/tags/go1.17.8:src/runtime/mgc.go</a></li><li><a href="https://www.ardanlabs.com/blog/2018/12/garbage-collection-in-go-part1-semantics.html">https://www.ardanlabs.com/blog/2018/12/garbage-collection-in-go-part1-semantics.html</a></li><li><a href="https://programming.vip/docs/deep-understanding-of-go-garbage-recycling-mechanism.html">https://programming.vip/docs/deep-understanding-of-go-garbage-recycling-mechanism.html</a></li><li><a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html">http://goog-perftools.sourceforge.net/doc/tcmalloc.html</a></li><li><a href="https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44">https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44</a></li><li><a href="https://groups.google.com/g/golang-nuts/c/KJiyv2mV2pU/m/wdBUH1mHCAAJ">https://groups.google.com/g/golang-nuts/c/KJiyv2mV2pU/m/wdBUH1mHCAAJ</a></li><li><a href="https://en.wikipedia.org/wiki/Escape_analysis">https://en.wikipedia.org/wiki/Escape_analysis</a></li><li><a href="https://youtu.be/uyifh6F_7WM">https://youtu.be/uyifh6F_7WM</a></li><li><a href="https://blog.twitch.tv/en/2019/04/10/go-memory-ballast-how-i-learnt-to-stop-worrying-and-love-the-heap/">https://blog.twitch.tv/en/2019/04/10/go-memory-ballast-how-i-learnt-to-stop-worrying-and-love-the-heap/</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/go/">go</category>
      
      
      <category domain="https://changhoi.kim/tags/gc/">gc</category>
      
      
      <comments>https://changhoi.kim/posts/go/go-gc/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>gRPC를 지탱하는 기술</title>
      <link>https://changhoi.kim/posts/backend/grpc-internals/</link>
      <guid>https://changhoi.kim/posts/backend/grpc-internals/</guid>
      <pubDate>Mon, 21 Feb 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;gRPC는 쉽게 말해서 HTTP/2.0 위에서 동작하는 RPC이다. 국내에서도 당근마켓, 뱅크샐러드, 데브시스터즈 같은 조직들이 gRPC를 활용하기 시작하면서 이미 많이 알려진 커뮤니케이션 방법이 되었다. 이번에 gRPC를 사용하게 되면서 어떤 기술들로 구성되어 있고, 어떤 대안들과 비교했을 때 어떤 장점이 생길 수 있는지 공부했던 내용을 정리했다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>gRPC는 쉽게 말해서 HTTP/2.0 위에서 동작하는 RPC이다. 국내에서도 당근마켓, 뱅크샐러드, 데브시스터즈 같은 조직들이 gRPC를 활용하기 시작하면서 이미 많이 알려진 커뮤니케이션 방법이 되었다. 이번에 gRPC를 사용하게 되면서 어떤 기술들로 구성되어 있고, 어떤 대안들과 비교했을 때 어떤 장점이 생길 수 있는지 공부했던 내용을 정리했다.</p><span id="more"></span><h2 id="gRPC의-특징"><a href="#gRPC의-특징" class="headerlink" title="gRPC의 특징"></a>gRPC의 특징</h2><p>유명한 오픈소스 기술들은 공식문서에 특징을 명확히 정리해서 보여준다. gRPC도 당연히 구글이 만든 잘된 프로젝트기 때문에 이러한 특징들이 간단명료하게 정리 되어있다.</p><blockquote><p>gRPC is a modern open source high performance Remote Procedure Call (RPC) framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication. It is also applicable in last mile of distributed computing to connect devices, mobile applications and browsers to backend services.</p></blockquote><p>정리하자면 다음과 같은 특징이 있다.</p><ul><li>gRPC는 <strong>High Performance</strong></li><li>여러 데이터 센터들 사이에 <strong>효율적인 연결</strong></li><li><strong>트레이싱, 헬스 체킹, 인증, 로드 밸런싱 포함</strong></li><li><strong>플랫폼 독립적</strong>으로 백엔드 서비스와 연결할 수 있음</li></ul><p>조금 더 구체적인 설명으로는 <strong>Protocol Buffer</strong>를 사용해서 Binary Serialization(직렬화)를 했고, <strong>HTTP/2.0</strong>을 사용해서 Bi-Directional 스트리밍이 가능하다는 내용과, 기타 크로스 플랫폼, 스텁을 생성해줘서 간단하게 개발할 수 있다는 내용 등이 나온다.</p><p>이런 특징들은 쉽게 말해서 “우리 기술을 사용하면 이런 장점이 있어”를 설명한 내용이다. 전반적인 벤치마크를 가지고 이런 특징을 내세우고 있겠지만, gRPC 같은 경우 생각해보면 대안은 대충 두 가지 갈래로 나눠질 수 있다. 첫 번째는 <strong>REST API</strong>를 대체하는 것이고, 두 번째는 Binary 인코딩을 하는 다른 구현체, 예를 들어 <a href="https://thrift.apache.org/">Thrift</a> 같은 것들이다.</p><p>사실 그런데 후자의 경우 보통 gRPC로 통일되고 있는 분위기이기도 하고, 보통 고민하고 있는 갈래가 보다 전통적인 방식의 HTTP/1.1 + JSON을 사용하는 REST API vs gRPC이기 때문에 이번 글 역시 REST API에 비해 어떤 장점을 설명할까에 집중해서 내부적인 부분들을 파헤쳐보려고 한다.</p><blockquote><p>일단 설명 전이지만, REST API는 gRPC와 비교 범주가 조금 다르긴 하다고 생각한다. gRPC는 아주 구체적인 구현체이고 REST API는 이론에 가까운 단어이기 때문이다. 그런데 일단 전통적인 방식과 비교하자는 의미이다. REST API가 JSON을 사용해야 한다는 것도 아니고 HTTP/1.1을 써야만 한다는 것도 아니다. 그냥 일반적인 상황을 얘기하는 것이다. “HTTP/1.1 프로토콜 위에서 JSON 바디를 보내는 방법”을 줄여 간단히 <strong>REST API</strong>라고 작성한 것으로 이해하자.</p></blockquote><hr><p>위 장점 중 트레이싱, 헬스 체킹 등 에코 시스템 관련된 장점과 크로스 플랫폼이라는 특징은 REST API를 타겟으로 한 소리는 아니라고 볼 수 있다. 따라서 gRPC가 어떻게 REST API에 비해 High Performance, 효율적인 연결을 이룰 수 있는지 위주로 풀어보자.</p><h2 id="CORE-1-HTTP-2-0"><a href="#CORE-1-HTTP-2-0" class="headerlink" title="CORE 1: HTTP/2.0"></a>CORE 1: HTTP/2.0</h2><p>gRPC는 HTTP/2.0 위에서 동작하는 RPC라고 가장 처음 설명했다. gRPC는 HTTP/2.0 프로토콜을 구현하는 것으로 다음과 같은 이점을 가지게 된다.</p><ul><li>컨넥션 수 감소</li><li>Long-live Connection</li><li>Bi-Directional Concept</li></ul><hr><h3 id="HTTP-2-0의-기술적-목표"><a href="#HTTP-2-0의-기술적-목표" class="headerlink" title="HTTP/2.0의 기술적 목표"></a>HTTP/2.0의 기술적 목표</h3><p>기존 HTTP/1.X에서는 다음 문제들이 있었다.</p><ul><li>Plain Text (ASCII) 프로토콜이기 때문에 Human-Readable 하므로 디버깅이 쉽지만, 아스키 코드 특성상 비슷한 다른 코드들이 여럿 존재한다. 예를 들어 다양한 White Space 종류들과 Termination을 의미하는 여러 코드, New Line을 의미하는 여러 코드 등 파싱 단계에서 생길 수 있는 문제가 있기도 하고 보안상 문제가 되기도 했다.</li><li>Plain Text라는 사실은 곧 불필요한 공간을 많이 사용하고 있다는 것을 의미하고, 이는 네트워크 친화적이지 않다는 것을 의미한다.</li><li>HOL(Head Of Line) Blocking 문제를 발생시킬 수 있다.</li><li>Parallel Connection을 통해 큰 오브젝트를 전달받을 때 비효율성을 해결하려고 했으나, 결국 컨넥션을 많이 사용해야 한다는 것을 의미한다. 서버의 구현 레벨에서 일반적으로 Connection은 스레드를 의미한다. 스레드는 메모리 등 컴퓨팅 자원을 소모하게 된다.</li></ul><p>위 문제들은 현재까지도 어느 정도 감안하며 사용하고 있을 정도로 크리티컬하다고 판단되지는 않는다. 그런데 구글 정도의 사이즈는 이런 문제를 해결했을 때 오는 효용 역시 엄청나기 때문인지, 새로운 프로토콜을 개발했다. 처음 만들어진 것은 <a href="https://ko.wikipedia.org/wiki/SPDY">SPDY</a>인데, 역사 얘기를 하지는 않을 것이고 결국 발전해서 HTTP/2.0이 되었다. HTTP/2.0의 디자인과 기술적 목표는 다음 같다.</p><ul><li>네트워크 리소스를 더 효율적으로 쓸 수 있고, 지연을 줄일 수 있어야 한다.</li><li>기존 HTTP/1.1을 대체하는 방식이 아니라 확장하는 방법이어야 한다.</li></ul><h3 id="Binary-Framing-Layer"><a href="#Binary-Framing-Layer" class="headerlink" title="Binary Framing Layer"></a>Binary Framing Layer</h3><p>HTTP/2.0의 성능 향상과 확장을 담당하는 레이어이다. 위에서 언급한 것처럼 HTTP/1.X의 확장적 개념으로 도입되기 위해서 기존 애플리케이션 레이어에 별도로 추가된 새로운 레이어이다. 이 레이어에서는 클라이언트와 서버 사이 HTTP 메시지가 HTTP/2.0 방식으로 캡슐화 된 것인지 확인하고 변환해준다.</p><p><img src="/images/2022-02-22-grpc-internals/http2-layer.png?style=centerme" alt="binary framing layer"><br><small>출처: <a href="https://www.oreilly.com/library/view/http2-a-new/9781492048763/">Oreilly</a></small></p><p>위 그림처럼 애플리케이션 레이어에서 바이너리 인코딩 및 디코딩을 담당한다. HTTP/1.X에서 Plain Text를 사용해 <code>\n</code>을 기준으로 작성하는 프로토콜이라면, HTTP/2.0에서는 프레임이라고 불리는 바이너리 포맷으로 전송된다. 따라서 HTTP/2.0을 사용하려면 클라이언트와 서버 모두 애플리케이션 레이어에 Binary Framing Layer를 지원하고 있어야 한다.</p><blockquote><p>이렇게 새로운 레이어 도입이 필수적이라는 측면에서 기존 인프라와 Incompatible 하기 때문에 HTTP/1.2가 될 수 없다.</p></blockquote><p>HTTP/1.1 버전의 헤더 (메소드, 상태 코드, URI 등)은 그대로 유지하기 때문에 애플리케이션 레벨에서는 변경점이 필요 없다. Binary Framing Layer를 양측에 도입하기만 하면 HTTP/2.0으로 동작할 수 있다는 뜻이다.</p><h3 id="Stream-Message-Frame"><a href="#Stream-Message-Frame" class="headerlink" title="Stream, Message, Frame"></a>Stream, Message, Frame</h3><p>HTTP/2.0은 바이너리로 인코딩된 프레임을 주고받는다. 커뮤니케이션에 사용되는 컴포넌트들은 아래와 같다.</p><ul><li>Frame(프레임): HTTP/2.0 커뮤니케이션의 가장 작은 유닛이다. 각 프레임은 하나의 프레임 헤더와 바디가 있는데, 헤더에는 자신이 속한 Stream의 식별자 정보와 우선순위 정보가 있다. 이 프레임들은 Message를 구성하는 일부이거나 전체이다.</li><li>Message(메시지): 온전한 메시지 시퀀스이다. 이 메시지는 논리적으로 HTTP/1.X 버전의 요청 또는 응답의 메시지와 같다.</li><li>Stream(스트림): 성립된 TCP 컨넥션 위에서 양방향 바이트 플로우를 보낼 수 있는 통로이다. 하나 이상의 메시지를 운반할 수 있다.</li></ul><p><img src="/images/2022-02-22-grpc-internals/http2-components.png?style=centerme" alt="Steam, Message, Frame"><br><small>출처: <a href="https://www.oreilly.com/library/view/http2-a-new/9781492048763/">Oreilly</a></small></p><p>모든 커뮤니케이션은 하나의 TCP 컨넥션 위에서 발생하고, 컨넥션은 양방향 스트림 몇 개든 동작시킬 수 있다. 각 스트림은 유니크한 식별자가 있고, 추가적으로 우선순위에 대한 정보가 있다. 그리고 해당 정보들은 메시지를 전달할 때 메시지를 구성하는 각 프레임 헤더에 담기게 된다.</p><blockquote><p>Google이 병렬 처리를 더 잘하도록 만드는 방법으로 기존 자원을 더 작게 나눠 관리하는 레이어를 추가해주는 방법을 많이 사용하는 것 같다는 생각을 했다. Go의 Goroutine도 Thread를 나눠 사용함으로써 더 가볍게 병렬로 동작하는 구현을 했다고 느꼈는데, 이 방법도 기존 컨넥션 활용을 더 작은 단위의 스트림이라는 단위로 나눠 사용하는 것이라고 느꼈다.</p></blockquote><blockquote><p>본인이 이해한 느낌은, 실제 구현 레벨에서는 컨넥션으로 전달되는 데이터는 Frame이다. 나머지는 논리적으로만 Binary Framing Layer에서 처리를 한다. 기존에 텍스트 메시지를 전달하듯, 메시지 순서와 상관 없이 메시지를 프레임으로 나눠 전송하는 형태이다. 그런데 도착해서는 프레임 헤더의 Stream 식별 정보로 데이터를 재조립할 수 있다.</p></blockquote><h3 id="gRPC가-HTTP-2-0을-활용한-방법"><a href="#gRPC가-HTTP-2-0을-활용한-방법" class="headerlink" title="gRPC가 HTTP/2.0을 활용한 방법"></a>gRPC가 HTTP/2.0을 활용한 방법</h3><p>gRPC는 HTTP/2.0을 구현하면서 확장적으로 사용하고 있다. gRPC에서 사용하고 있는 커뮤니케이션을 위한 컴포넌트는 다음과 같다.</p><ul><li>Channel(채널)</li><li>RPC</li><li>Message(메시지)</li></ul><p>위 HTTP/2.0처럼 각 컴포넌트들은 포함 관계를 가지고 있다. 채널은 여러 RPC를 가질 수 있고 RPC는 여러 메시지를 가질 수 있다.</p><p><img src="/images/2022-02-22-grpc-internals/grpc-concepts.png?style=centerme" alt="gRPC 컴포넌트들"></p><p>묘하게 연결되는 구석들이 느껴지긴 하는데 구체적으로 다음 그림처럼 표현할 수 있다.</p><p><img src="/images/2022-02-22-grpc-internals/grpc-related-to-http2.png?style=centerme" alt="gRPC on HTTP/2.0"></p><p>채널들은 gRPC에서 핵심적인 컨셉이다. HTTP/2.0에서 Stream 여러 개를 하나의 컨넥션 위에서 동작시킬 수 있었는데, gRPC의 채널은 컨넥션을 여러 개 활용해서 마치 하나의 전송 통로처럼 사용하도록 추상화하고 있다. 이 부분이 구체적으로 어떻게 구성되고 있는지는 후술하고 있다. 아무튼, 표면적으로는 RPC를 올리는 하나의 간단한 인터페이스를 제공하는 것 같지만 이면에는 여러 컴포넌트들이 여러 컨넥션을 묶어 Alive 상태를 유지한다. 즉, 채널은 하나의 엔드포인트와 연결해주는 가상의 컨넥션이다.</p><p>RPC는 이 컨넥션과 함께 본인이 해야 할 일을 수행한다. 해야 할 일이라고 하면 요청을 처리해 응답을 보내주는 역할을 하는 것인데, 커뮤니케이션 입장에서는 메시지를 주고받는 역할을 의미한다. RPC는 실제로 단순히 Stream 형태로 구현된다.</p><p>메시지는 HTTP/2.0의 메시지와 동일하고 RPC를 통해 전송된다. 조금 더 구체적으로는 프레임에 메시지를 “적재”하는 방법으로 동작한다.</p><blockquote><p>약간 프레임을 경제적으로 사용한다는 느낌인 것 같다. <code>layered</code> 한다고 표현을 하는데, 프레임이 하나 이상의 메시지를 담을 수도 있고, 만약 메시지가 HTTP/2.0 스펙상 기본 프레임 사이즈인 16KB보다 크면 두 개 이상의 프레임을 사용할 수도 있다는 내용이었다.</p></blockquote><p>정리하자면, Channel은 Connection(복수의 컨넥션을 추상화), RPC는 Stream, Message는 Message와 연결되는 개념이다.</p><h3 id="Resolver-amp-Load-Balancer"><a href="#Resolver-amp-Load-Balancer" class="headerlink" title="Resolver &amp; Load Balancer"></a>Resolver &amp; Load Balancer</h3><p>채널이 결국 여러 컨넥션을 활용하고 있는 가상의 컨넥션인데, 어떻게 컨넥션들을 관리하고 유지하고 있을까? 이를 위해서 여러 컴포넌트들이 사용되는데 핵심적으로 <code>name resolver</code>(resolver, 리졸버), <code>load balancer</code>(로드 벨런서)이다. 리졸버는 DNS 리졸버로부터 호스트 이름을 가지고 IP 주소를 질의한 다음 넘겨받은 IP 주소 리스트를 로드 벨런서에게 넘겨주는 역할을 한다.</p><p>로드 벨런서는 넘겨받은 주소들을 가지고 컨넥션들을 만들어 하나의 채널로 구성한다. 그리고 RPC가 채널에 들어오면 정해진 로드 벨런스 전략에 따라 RPC를 실제 컨넥션에 연결해준다. 일단 22년 2월 기준으로 기본은 Round Robin 방식인 것 같고 다른 방식으로는 <code>pick_first</code> 방식이 있다. 이 <a href="https://github.com/grpc/grpc-go/tree/master/examples/features/load_balancing">링크</a>에서 로드 벨런싱을 설정하는 예시를 볼 수 있다.</p><blockquote><p>Channel과 유관한 코드들은 다른 언어에서는 Channel이라는 키워드를 쓰고 있는 것 같은데, Go에서는 이미 채널이라는 개념이 언어 레벨에 있다 보니, <code>ClientConn</code>이라는 이름을 사용하고 있다. 동작 관련된 내용을 보면 클라이언트에서 찾아볼 수 있겠구나라고 생각할 수 있고, 예시 역시 <a href="https://github.com/grpc/grpc-go/blob/011544f72939c85397b0e24378280e6075061cb1/examples/features/load_balancing/client/main.go#L75-L79">클라이언트 코드</a>를 보면 확인할 수 있다.</p></blockquote><p><img src="/images/2022-02-22-grpc-internals/grpc-resolverAndLB.png?style=centerme" alt="Resolver &amp; Load balancer"></p><p>예를 들어서, DNS 리졸버로부터 호스트에 대한 13개의 IP 주소를 알려줬다면, 라운드 로빈 벨런서가 13개의 컨넥션을 만들고 RPC를 배분해준다.</p><h3 id="Connection-Management"><a href="#Connection-Management" class="headerlink" title="Connection Management"></a>Connection Management</h3><p>한 번 설정된 이후 gRPC는 리졸버와 로드 벨런서에 의해 정의된 대로 컨넥션 풀을 유지하게 된다. 그렇다면 컨넥션 실패를 경험하면 어떻게 될까? 일단 실패를 인지하는 단계가 있어야 하지만 구체적으로 어떻게 실패를 인지하는지는 나중에 얘기하고, 일단 실패를 발견하면 로드 벨런서는 현재 가지고 있는 주소 리스트를 기반으로 컨넥션을 새로 구성하려고 한다.</p><p>한편 리졸버는 호스트 이름의 주소 리스트를 새롭게 업데이트한다. 이유는 기본적으로 IP가 유동적인 개념이기도 하고, 특정 IP가 프록시 서버였다고 가정했을 때 이 서버에 문제가 생겨 내려간 상태라고 한다면 재시도를 할 필요 없기 때문이다. 이렇게 업데이트한 주소 목록을 다시 로드 벨런서에게 넘겨주면 로드 벨런서는 불필요한 컨넥션을 내리고, 필요한 컨넥션은 새롭게 만든다. 이런 방법으로 Long-live Connection을 안정적으로 유지되도록 한다.</p><h3 id="실패한-컨넥션-찾기"><a href="#실패한-컨넥션-찾기" class="headerlink" title="실패한 컨넥션 찾기"></a>실패한 컨넥션 찾기</h3><p>컨넥션 관리 사이클의 시작은 실패를 인지하는 것부터라고 했다. 실패한 컨넥션은 다음과 같은 케이스가 있다.</p><ul><li>Clean Failure: 실패에 대한 커뮤니케이션이 상호 진행됨</li><li>Less-clean Failure: 실패에 대한 커뮤니케이션이 진행되지 않음</li></ul><p>첫 번째 케이스는 엔드포인트에서 의도적으로 컨넥션을 끊었을 때 발생할 수 있다. Graceful Shutdown이 진행 중이라든지, 타임아웃이 발생한 경우 그럴 수 있다. 이런 경우 TCP 레이어에서 <code>FIN Handshake</code>가 발생할 것이고, gRPC는 즉각 실패를 인지할 수 있다.</p><p>두 번째 케이스는 엔드포인트가 의도치 않게 죽었거나, 클라이언트에게 알리지 않고 종료한 케이스이다. 이 경우 클라이언트는 TCP 컨넥션 연결 유지를 최대 10분 동안 하고 있는다. 10분 동안 컨넥션의 사용 가능 여부를 판단하는 것은 말이 안되니까, gRPC는 HTTP/2.0의 Ping Frame을 사용해 이런 케이스를 판단한다. 다이얼 옵션 중 <code>KeepAlive</code> 옵션이 켜진 경우 gRPC는 주기적으로 HTTP/2.0 Ping Frame을 전송하는데, 이 프레임들은 HTTP/2.0의 흐름 제어 플로우에서 바이패싱(무조건 통과)된다. 그리고 컨넥션이 살아있는 경우만 응답을 받게 되므로, 만약 핑의 응답을 못 받으면 gRPC는 이를 실패로 인지한다.</p><p>두 케이스 모두 실패로 인지된 이후는 위에서 설명한 대로 로드 벨런서의 재연결 시도가 시작된다.</p><blockquote><p><code>KeepAlive</code> 옵션은 지금 버전 기준으로 기본값이 True인 것으로 알고 있다. 위에서 언급한 기능 외 추가적으로 장점이 있는데, 프록시들에게 컨넥션의 라이브니스(Liveness)를 알려주는 용도로 많이 사용된다. 만약 서버와 클라이언트 사이 프록시 서비스가 사용되고 있을 때, 많은 프록시 서비스들이 일정 시간 동안 사용되지 않은 컨넥션을 불필요한 것으로 간주하고 닫아버린다. 예를 들어서 AWS ELB 서비스는 TCP 컨넥션이 1분간 사용되지 않으면 해당 컨넥션을 닫고, GCP의 경우 10분이면 닫는다고 한다. <code>KeepAlive</code> 옵션은 위에서 언급한 Ping을 보내는 방식으로 프록시 호스트에게 컨넥션이 사용 중임을 알리는 역할도 한다.</p></blockquote><h2 id="CORE-2-Protocol-Buffer"><a href="#CORE-2-Protocol-Buffer" class="headerlink" title="CORE 2: Protocol Buffer"></a>CORE 2: Protocol Buffer</h2><p>지금까지 gRPC가 어떻게 HTTP/2.0을 활용하는지 얘기해봤다. 이제는 gRPC가 바디 사이즈를 줄이기 위해 활용한 바이너리 인코딩 메커니즘인 Protocol Buffer에 대해 얘기해보려고 한다.</p><p>프로토콜 버퍼는 구조화된 데이터를 바이너리로 직렬화하기 위한 구글의 메커니즘이다. 어떻게 사용하지에 대한 내용은 이 글에서 담지 않았다. 기본적인 얘기를 하자면 <code>proto</code> 확장파일을 가진 IDL을 정의한 다음 필요에따라 각 언어로 컴파일함으로써 쉽게 직렬화·역직렬화를 할 수 있는 Stub을 생성해 사용하는 구조이다.</p><h3 id="메시지-구조"><a href="#메시지-구조" class="headerlink" title="메시지 구조"></a>메시지 구조</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">message Example &#123;</span><br><span class="line">  int32 id = 1;</span><br><span class="line">  string msg = 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>메시지 구조는 이렇게 생겼다. <code>int32 id = 1;</code>이라는 라인에서 <code>int32</code>에 해당하는 부분이 <strong>필드 타입</strong>, <code>id</code>에 해당하는 곳이 <strong>필드</strong>(<strong>필드 이름</strong>), <code>1</code>에 해당하는 부분을 <strong>필드 넘버</strong>라고 한다.</p><blockquote><p>어떤 글에서는 필드 넘버를 필드 아이디라고도 하고… 조금씩 표현이 다른 것 같다. 아무튼 이 글에서는 이렇게 표기하고 있다.</p></blockquote><p>필드 넘버는 유니크한 값이다. 실제 인코딩 디코딩 시점에서 Key 역할을 하기 때문이다. JSON 타입은 문자열로 구성된 타입을 키로 사용하지만 Protocol Buffer는 간단히 숫자로만 표현한다. <code>&#123;&quot;id&quot;: Value&#125;</code>를 <code>&#123;1: Value&#125;</code>로 변환하는 느낌으로 보면 된다. 디코딩하는 시점에서는 개발의 편리를 위해 설정된 필드 이름으로 매핑된다. 이렇게 전송 과정에서 불필요한 텍스트를 다 버려 일차적으로 압축되는 효과가 있다.</p><h3 id="인코딩"><a href="#인코딩" class="headerlink" title="인코딩"></a>인코딩</h3><p>프로토콜 버퍼 사이즈가 줄어들게 되는 이유로 가장 길게 설명하는 부분은 <code>Varints</code>이다. <code>Varints</code>라고 표현하는 이 인코딩 방법은 스칼라 정수형 값을 인코딩하는 방법이다. 이 방법은 정수를 하나 이상의 유동적인 바이트 수로 표현한다. 숫자가 더 작을 수록 더 적은 바이트만 사용하게 된다.</p><p>인코딩된 바이트의 첫 번째 비트는 <code>MSB</code>(<code>Most Significant Bit</code>)라고 한다. 이 비트는 현재 바이트가 마지막 바이트인지 알려주는 역할을 한다. 나머지 7비트는 숫자를 표현하기 위해 사용한다.</p><p>인코딩은 2진수의 작은 숫자 비트부터 시작해서 위로 7비트를 잘라 표현하는 리틀 엔디안 방식이다. 예를 들어 1을 인코딩하면 다음과 같다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0000 0001 -&gt; MSB = 1 &amp; 나머지 비트로 1 표현</span><br></pre></td></tr></table></figure><p>300을 표현해보자</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1010 1100 / 0000 0010</span><br></pre></td></tr></table></figure><p><code>1010 1100</code>과 <code>0000 0010</code> 두 개의 바이트로 표현된다. 먼저 앞의 바이트의 <code>MSB</code>가 1이기 때문에, 그 뒤 바이트 역시 같은 수를 표현하기 위해 사용되었다는 것을 의미한다. 그리고 그다음 바이트의 <code>MSB</code>가 0이니까 그다음 바이트에서 끝나는 수이다.</p><p>두 바이트의 뒤 7비트를 뒤집어서 합쳐주면 원래 숫자가 나온다. (앞의 7비트가 더 아랫자리 수니까 뒤집어서 합친다)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">000 0010 ++ 010 1100 = 0001 0010 1100 = 256 + 32 + 8 + 4 = 300</span><br></pre></td></tr></table></figure><blockquote><p>이 방법은 사실 신박한 프로토콜 버퍼의 인코딩 방법이 아니라 과거에서부터 사용되던 압축 방법이다. “대규모 시스템을 지탱하는 기술”이라는 책에서 이 방법을 <code>vbcode</code>라는 이름으로 소개하고 있다. 과제로도 있어서 <a href="https://github.com/changhoi/vbcode">구현</a>한 적이 있다.</p></blockquote><h3 id="필드-타입-amp-필드-넘버-인코딩"><a href="#필드-타입-amp-필드-넘버-인코딩" class="headerlink" title="필드 타입 &amp; 필드 넘버 인코딩"></a>필드 타입 &amp; 필드 넘버 인코딩</h3><p>위 방법은 메시지 타입이 <code>Varint</code> 타입인 경우 적용되는 방법이다. “메시지 타입”은 <code>Wire Type</code>이라고 문서에서 말한다.</p><p><img src="/images/2022-02-22-grpc-internals/wiretype.png?style=centerme" alt="Wire Type"></p><p>위 표처럼 Wire Type은 0부터 5까지 총 6개 정수형으로 구성되어있다. 이를 표현하는 건 3개의 비트만 있으면 되고, 필드 넘버도 위에서 설명했던 것처럼 정수형으로 인코딩되기 때문에 둘이 합쳐서 메시지의 맨 첫 번째로 나오게 된다.</p><p>즉, 데이터 스트림 시작의 첫 바이트는 <code>MSB</code>(1) + <code>Field Number</code>(4) + <code>Wire Type</code>(3)으로 구성되어있다.</p><blockquote><p>따라서 필드 넘버는 1 ~ 15까지의 숫자만 쓰는 것이 좋다. 그 이상 사용하게 되면 바이트를 추가로 써야 한다. 사실 1바이트 더 쓰는 게 뭐 그렇게 대수냐? 라고 생각할 수 있다. 그 말도 맞다고 생각하기 때문에 그냥 숫자 자체는 15이하로 쓰고 안되면 넘겨 쓰자는 정도로 이해하면 될 것 같다.</p></blockquote><hr><p>인코딩된 데이터를 받았는데 아래와 같이 생겼다고 가정해보자. 각 띄어쓰기로 구성된 부분이 바이트이고, 16진수로 표현된 숫자이다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">08 96 01</span><br></pre></td></tr></table></figure><p>위 데이터 중 맨 앞부분의 바이트는 필드 정보를 나타내고 있다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">08 = 0000 1000 -&gt; MSB = 0, MSB 제거</span><br><span class="line"></span><br><span class="line">000 1000 -&gt; 뒤 세 비트가 0임을 확인 -&gt; varint 타입. 타입에 맞게 이후 바이트들을 디코딩</span><br><span class="line"></span><br><span class="line">0001 -&gt; 남은 비트는 1을 표현 -&gt; 필드 넘버는 1</span><br></pre></td></tr></table></figure><p>따라서, 필드 넘버가 1이고 값은 <code>Varint</code> 타입인 값에 150 (<code>96 01</code>을 <code>Varint</code> 방식으로 디코딩하면 150)이 들어온 데이터라고 인식하게 된다.</p><h3 id="작은-음수-인코딩"><a href="#작은-음수-인코딩" class="headerlink" title="작은 음수 인코딩"></a>작은 음수 인코딩</h3><p>음수가 나올 가능성이 확실히 있는 경우, 2의 보수 표현법으로 바이너리를 채우는 <code>Varint</code> 방식을 그대로 적용하면 불필요하게 너무 많은 바이트를 쓰게 될 수 있다. 특히 작은 숫자일 수록 1로 큰 수 쪽이 채워지기 때문에 그렇다.</p><p>이런 경우 <code>sint</code>(<code>sint32</code>, <code>sint64</code>)로 필드 타입을 설정하는 것이 효율성 측면에서 더 좋다. Signed Integer 타입은 음수값을 지그재그 인코딩으로 먼저 변환한 다음 <code>Varint</code> 인코딩을 수행한다. 지그재그 인코딩은 다음 표처럼 음수를 양수 사이사이에 껴두어 치환한 테이블을 가지고 인코딩을 하는 방식이다.</p><p><img src="/images/2022-02-22-grpc-internals/zigzag.png?style=centerme" alt="지그재그 인코딩 테이블"></p><blockquote><p>기타 다른 인코딩 방식은 단순히 필요한 바이트 길이를 미리 전달해주고 뒷부분을 바이트로 변환해 집어 넣는 <code>length-delimited</code> 방식의 인코딩과, <code>double</code>, <code>float</code> 처럼 고정된 바이트를 사용하는 경우 그대로 바이너리 값을 넣어주는 등, 큰 압축 효과 없이 데이터를 전달한다.</p></blockquote><h2 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h2><p>지금까지 gRPC를 지탱하는 핵심 기술에 대해 알아봤다. 실제로 FAQ에는 <a href="https://grpc.io/docs/what-is-grpc/faq/#why-is-grpc-better-than-any-binary-blob-over-http2">“gRPC가 HTTP/2 위로 바이너리를 보내는 것보다 나은 게 있는가?”</a>라는 질문이 있다. 이 질문에 결국 gRPC가 하는 역할은 크게 보면 그걸 하고 있다고 답변한다. 물론 결국 답변은 +a가 있기 때문에 더 낫다는 답변이지만, 본질적으로 우리는 핵심 두 가지를 살펴본 것이다.</p><h3 id="어떻게-쓰는-것이-좋지"><a href="#어떻게-쓰는-것이-좋지" class="headerlink" title="어떻게 쓰는 것이 좋지?"></a>어떻게 쓰는 것이 좋지?</h3><p>그렇다면 gRPC는 앞으로 어떻게 써야 할까? 우선 HTTP/2.0이라는 특징과, 구체적으로 어떻게 구현해 사용하고 있는지를 알게 되었으니 Dial 옵션을 더 꼼꼼하게 알아볼 필요가 있다. 우리 상황에 맞게 더 잘 쓸 수 있는 방법이 있을지 확인해보고 프로젝트 환경에서 컨넥션을 효율적으로 사용할 수 있는 옵션이 무엇일지 찾아보고 적용해보면 좋을 것 같다.</p><p>그리고 Protocol Buffer를 사용하는 것 자체에서 주의해야 할 점 몇 가지가 있다. IDL에서 메시지에 새로운 필드를 추가하는 작업은 기본값 처리만 해두면 이전 시스템과 호환이 되기 때문에 비교적 자유롭게 추가할 수 있다. 그러나 삭제하는 작업은 고민해볼 필요가 있다. 삭제 자체는 문제 되지 않지만, 만약 삭제한 다음 해당 필드 넘버로 새로운 필드를 추가한다면, 과거 IDL을 사용하고 있던 시스템과 문제를 일으킨다. 따라서 값을 지울 때는 미래에도 이 값을 사용하지 않도록 키워드로 DEPRECATED 처리를 하든, <code>reserved</code> 키워드로 방어하든 조금 보수적으로 접근할 필요가 있다.</p><p>살짝 언급했지만, 프로토콜 버퍼에서 값이 없는 필드는 디코딩할 때 제로값(기본값)을 사용한다. 따라서 실제 값인지, 기본값인지 판단할 수 있는 로직이 필요하고 만약 그게 어렵다면 <code>WKT</code>의 Wrapper를 사용해 <code>null</code> (Go 에서는 <code>nil</code>) 타입이 제로값으로 들어가도록 한 번 감싸주는 것도 좋은 방법이 될 수 있다.</p><p>IDL을 관리해야한다는 이슈도 있다. 보통 프로토콜 버퍼를 사용하는 조직은 전사적인 IDL 관리를 진행하고 있다는 얘기를 많이 들었다. <a href="https://blog.banksalad.com/tech/production-ready-grpc-in-golang/">뱅크샐러드</a>글에서도 그 내용이 나온다. IDL 관리, 버저닝 등 미리 팀과 얘기해볼 것들이 많이 있다.</p><h3 id="REST-API는-대체되는가"><a href="#REST-API는-대체되는가" class="headerlink" title="REST API는 대체되는가?"></a>REST API는 대체되는가?</h3><p>결론 먼저 말하면 당연히 아니다. REST API에 비해 결론적으로 갖게 되는 장점은 다음과 같은 것들이 있을 수 있다. </p><ul><li>TCP 컨넥션 사용 효율성 증가</li><li>메시지 Header 압축으로 네트워크 사용 감소</li><li>Long-live Connection으로 Handshake Overhead 감소</li><li>페이로드 압축률 증가</li></ul><p>그러나 클라이언트와 서버 모두 gRPC가 애플리케이션 레이어 앞쪽에서 동작해야 하는 영역이 있기 때문에, 그 부분을 자유롭게 손볼 수 없다면 사용이 어렵다. 대표적으로 Web 클라이언트는 온전히 gRPC 스텁을 동작시키지 못하기 때문에 HTTP/1.1에서 동작하는 방식으로 다운그레이딩되어 사용된다. 위에서 말한 장점들 역시 온전히 가져가지 못할 것이고, 그렇다면 굳이 그 환경에서도 gRPC를 써야 할지 의문이다.</p><p>프로토콜 버퍼의 공식문서를 보면 프로토콜 버퍼는 큰 데이터를 다루기에는 부적합한 방법이라고 설명한다. 메시지가 메가바이트 단위라면 다른 대안을 찾을 것을 권고하고 있다. 아마 인코딩 디코딩의 CPU Bound가 문제가 되는 것인가 싶다. 예를 들어 이미지 파일의 경우 스트림을 통해 보내주는 케이스가 있을 수도 있는데, 그냥 저장하고 있는 CDN 링크를 요구사항에 맞게 보내주는 것이 한 방법이 될 수 있다.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://grpc.io/">https://grpc.io/</a></li><li><a href="https://grpc.io/blog/grpc-on-http2/">https://grpc.io/blog/grpc-on-http2/</a></li><li><a href="https://www.cncf.io/blog/2018/07/03/http-2-smarter-at-scale/">https://www.cncf.io/blog/2018/07/03/http-2-smarter-at-scale/</a></li><li><a href="https://www.oreilly.com/library/view/http-the-definitive/1565925092/ch04s04.html">https://www.oreilly.com/library/view/http-the-definitive/1565925092/ch04s04.html</a></li><li><a href="https://www.oreilly.com/library/view/http2-a-new/9781492048763/">https://www.oreilly.com/library/view/http2-a-new/9781492048763/</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/backend/">backend</category>
      
      
      <category domain="https://changhoi.kim/tags/grpc/">grpc</category>
      
      <category domain="https://changhoi.kim/tags/http2/">http2</category>
      
      <category domain="https://changhoi.kim/tags/protocolbuffer/">protocolbuffer</category>
      
      
      <comments>https://changhoi.kim/posts/backend/grpc-internals/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>SQL 쿡북 간단 리뷰</title>
      <link>https://changhoi.kim/posts/books/sql-cookbook/</link>
      <guid>https://changhoi.kim/posts/books/sql-cookbook/</guid>
      <pubDate>Sat, 19 Feb 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;올해도 한빛 미디어에서 &lt;strong&gt;나는 리뷰어다&lt;/strong&gt; 활동을 지속하게 되었다. 이번 달 책은 &lt;strong&gt;SQL 쿡북&lt;/strong&gt;을 받았고, 이 글은 이 책에 대한 간단한 리뷰이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>올해도 한빛 미디어에서 <strong>나는 리뷰어다</strong> 활동을 지속하게 되었다. 이번 달 책은 <strong>SQL 쿡북</strong>을 받았고, 이 글은 이 책에 대한 간단한 리뷰이다.</p><span id="more"></span><p>“쿡북” 이라는 이름의 책은 다들 레시피처럼 “어떤 상황에서 어떻게 할 수 있습니다.” 같은 내용을 소개해주는 구조를 띄고 있는 것 같다. 이번에 받은 책 역시 그런 형식이었다. SQL에서 특정 동작을 어떻게 할 수 있는지를 알려주는 레시피 책이었다. 이런 책은 사실 사전 지식이 있다면 모든 내용을 다 읽을 필요가 없다. 약간 사전처럼 필요한 경우 찾아보는 형식이어도 될 것 같다. 쿡북답게, 간결하게 필요한 정보를 전달해주고, 예시 테이블에서 수행했을 때의 결과까지 같이 보여주고 있어서 보기가 편했던 것 같다.</p><p>간결하다고는 했지만 쉬운 책은 아닌 것 같다. 예상 독자 역시 SQL을 이미 알고 있는 사람들을 대상으로 한다. 꽤나 복잡하고 디테일한 상황들까지 다루고 있어서 좋은 인사이트를 얻을 수 있었다.</p>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/books/">books</category>
      
      
      <category domain="https://changhoi.kim/tags/review/">review</category>
      
      <category domain="https://changhoi.kim/tags/sql/">sql</category>
      
      
      <comments>https://changhoi.kim/posts/books/sql-cookbook/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>RDB 스케일링</title>
      <link>https://changhoi.kim/posts/database/rdb-scaling/</link>
      <guid>https://changhoi.kim/posts/database/rdb-scaling/</guid>
      <pubDate>Tue, 08 Feb 2022 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;RDB는 흔히 말하길 스케일링 (스케일 아웃) 하기 까다로운 데이터베이스라고들 한다. NoSQL이 등장하며 내세웠던 차별점 역시 이러한 부분(확장성)이 포함되어있다. 하지만 RDB가 스케일 아웃이 불가능하다는 건 절대 아니다. 많은 거대한 서비스들이 RDB를 사용하고 있고, 이 서비스들은 많은 방법으로 스케일 아웃을 구현하고 있다. 이 방법에 대해서 정리한 글이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>RDB는 흔히 말하길 스케일링 (스케일 아웃) 하기 까다로운 데이터베이스라고들 한다. NoSQL이 등장하며 내세웠던 차별점 역시 이러한 부분(확장성)이 포함되어있다. 하지만 RDB가 스케일 아웃이 불가능하다는 건 절대 아니다. 많은 거대한 서비스들이 RDB를 사용하고 있고, 이 서비스들은 많은 방법으로 스케일 아웃을 구현하고 있다. 이 방법에 대해서 정리한 글이다.</p><span id="more"></span><blockquote><p>우선 글 내용에서 구체적인 부분들은 <code>InnoDB</code> 스토리지 엔진의 케이스를 다루고 있다. 핵심적인 원리에 대해서는 사실 모든 RDB에서 같다고 생각된다.</p></blockquote><h2 id="거대한-테이블의-문제점"><a href="#거대한-테이블의-문제점" class="headerlink" title="거대한 테이블의 문제점"></a>거대한 테이블의 문제점</h2><p>스케일 아웃이 필요한 근본적인 이유는 무엇일지 생각해보자. In-memory 데이터베이스가 아니라면 일반적으로 RDB는 정보의 영구적인 저장을 위해 디스크에 파일을 작성하게 된다. 서비스가 성장하면서 메모리 사이즈보다 데이터 용량이 커지면 OS 레벨에서 캐시해주는 범위를 초과하면서 Disk I/O가 급등하게 된다. 인덱스도 마찬가지이다. 인덱스 역시 파일로 관리되게 되는데, 이 인덱스 파일의 사이즈가 커지면 같은 이유로 Disk I/O가 많아지고 속도는 Memory 접근에 비해 백만 배까지 느려진다. CRUD를 할 때 직, 간접적으로 인덱스 파일을 사용하게 되는데, 모든 동작이 이렇게 느려진다.</p><h2 id="해결할-수-있는-원리"><a href="#해결할-수-있는-원리" class="headerlink" title="해결할 수 있는 원리"></a>해결할 수 있는 원리</h2><p>근본적으로 해결하기 위해서는 테이블의 사이즈를 줄여줘야 한다. 이 방법으로는 두 가지를 여기서 언급하는데, 첫 번째는 일반적으로 RDB에서 제공하는 파티셔닝과 엔지니어가 직접 테이블을 분리하는 샤딩에 대해 다룬다. 간단히 말해서 파티셔닝은 하나의 RDB 안에서 테이블 하나를 내부적으로 여러 테이블로 나눠주는 것이고, 샤딩은 여러 RDB 서버를 사용해 데이터를 분할하는 방식이다.</p><h2 id="파티셔닝-Partitioning"><a href="#파티셔닝-Partitioning" class="headerlink" title="파티셔닝 (Partitioning)"></a>파티셔닝 (Partitioning)</h2><p>파티셔닝은 논리적으로는 하나의 테이블인데, 내부에서는 물리적으로 여러 테이블로 나눠 관리하는 방법이다. RDB마다 다를 수 있지만 일반적으로는 <code>PARTITION</code> 키워드를 통해 테이블을 분할할 수 있다. 사용하는 데이터들의 인덱스를 여러 개로 분할해서 사용할 수 있게 된다. 따라서 이전에 발생한 문제를 해결할 수도 있고, 데이터를 목정성에 맞게 나눠 관리하다가 요구에 따라 간단하게 삭제할 수도 있다.</p><blockquote><p>흔히 이 파티셔닝을 “스케일 아웃”이라고 표현하지 않는다. 일종의 기술로 대량의 데이터를 특정 기준별로 데이터베이스에 부하가 적게 생기면서 삭제할 수 있도록 하는 목적이 더 크다. 그렇지만 근본적으로 큰 테이블을 여러 테이블로 나눠주는 과정이 포함되어있어서 큰 테이블에서 발생할 수 있는 문제를 해결해줄 수 있다.</p></blockquote><h3 id="파티션-키"><a href="#파티션-키" class="headerlink" title="파티션 키"></a>파티션 키</h3><p>파티션을 만들 때, 특정 데이터가 어디에 위치하게 될지를 결정하는 키를 파티션 키라고 한다. CRUD를 할 때, 이 키를 활용해(활용할 수 있는 상황이라면) 파티션을 선택한다. 그다음 명령 동작을 수행하는 구조이다. 한 단계를 거치지만 거대한 테이블을 모두 찾아보지 않아도 된다. 이렇게 불필요한 다른 서브 테이블을 배제하는 동작을 프루닝이라고 한다.</p><hr><p>조금 구체적인 얘기인데, 파티션 키를 선택할 때 제한사항이 존재한다. 유니크 키는 논리적인 테이블 안에서 유일해야 하는 값이기 때문에 파티션 키를 통해 해당 유니크 키가 어디에 있는지 결정할 수 있어야 한다. 따라서 <strong>파티션 키는 유니크 인덱스의 일부 또는 전체를 사용해 표현해야 한다.</strong></p><p>예를 들어서 유니크 키가 다음과 같이 설정되어있다고 생각해보자.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">PRIMARY</span> (fd1, fd2) <span class="comment">-- PRIMARY도 유니크 키</span></span><br></pre></td></tr></table></figure><p>파티션 키는 <code>fd1</code>을 사용하거나, <code>fd2</code>를 쓰거나, 둘 다 사용해야 한다. 그래야만 파티션 키가 유니크 값들이 무조건 같은 테이블에 있음을 확인해줄 수 있다.</p><h3 id="파티션에서-쿼리가-발생하는-과정"><a href="#파티션에서-쿼리가-발생하는-과정" class="headerlink" title="파티션에서 쿼리가 발생하는 과정"></a>파티션에서 쿼리가 발생하는 과정</h3><p><img src="/images/2022-02-09-rdb-scaling/partition-query.png?style=centerme"></p><p>우선 먼저 파티션을 구분할 수 있는 조건절이 사용되었는지 확인하고 <strong>파티션 프루닝</strong>을 시도한다. 위에서 살짝 언급했지만, 파티션 프루닝은 찾을 필요가 없는 파티션을 걸러 내는 과정이다. 그다음 일반적인 테이블을 스캔하는 과정이 발생한다.</p><blockquote><p>일반적인 테이블을 스캔하는 과정은 조건절에 인덱스가 포함된 경우 인덱스를 통해 쿼리를 하고, 그렇지 않으면 테이블 풀 스캔을 하는 과정을 말한다.</p></blockquote><p>따라서 쿼리를 하는 방법에서도 어떤 키를 기준으로 파티셔닝을 해야 할지 신중하게 결정해야 한다. 쿼리 패턴에 맞게 파티셔닝을 해야 파티셔닝을 한 효과를 최대화할 수 있다.</p><h3 id="파티션에서-업데이트가-발생하는-과정"><a href="#파티션에서-업데이트가-발생하는-과정" class="headerlink" title="파티션에서 업데이트가 발생하는 과정"></a>파티션에서 업데이트가 발생하는 과정</h3><p>업데이트라고 썼지만 실제로 파티셔닝이 된 데이터베이스에서는 읽기, 삭제, 삽입이 포함될 수 있는 과정이다. 업데이트 동작을 수행하기 위해서는 먼저 테이블에서 해당 데이터를 찾아야 한다. 이 과정에서 위에서 말한 쿼리 과정이 수행된다. 그다음 데이터를 수정하게 되는데, 만약 업데이트한 필드가 파티션 키와 상관없는 필드인 경우엔 값만 수정하고 끝난다. 그런데 만약 파티션 키를 수정하게 되면 해당 데이터를 재배치하는 과정이 필요하다. 즉, 데이터를 삭제 후 알맞은 파티션에 삽입하는 과정이 발생한다. 이런 동작을 하므로 파티션 키는 쉽게 변하지 않는 값으로 설정하는 것이 퍼포먼스 측면에서 좋다.</p><h3 id="파티션-프루닝"><a href="#파티션-프루닝" class="headerlink" title="파티션 프루닝"></a>파티션 프루닝</h3><p>지금까지 이 글을 따라오다 보면 파티션 프루닝을 몇 차례 만날 수 있다. 파티션 프루닝은 파티셔닝의 핵심이다. 이 작업은 <code>EXPLAIN</code> 명령으로 확인할 수 있다.</p><p><img src="/images/2022-02-09-rdb-scaling/explain-pruning.png?style=centerme"><br><small>해시 파티셔닝을 한 다음 쿼리를 <code>EXPLAIN</code>으로 확인한 모습. <code>p0</code> 파티션만 사용되고 나머지는 사용되지 않음</small></p><p>테이블을 분리해서 인덱스의 크기를 줄이는 것이 파티셔닝의 외적으로 드러나는 장점이지만, 사실 프루닝을 잘 할 수 있도록 쿼리를 하지 않으면 오히려 안 좋은 퍼포먼스를 발생시킨다. 따라서 무턱대고 파티션을 많이 만들어서 인덱스 사이즈를 줄이기보단 파티션 프루닝이 최적으로 발생하도록 만들고, 인덱스 서치를 한 번만 발생하도록 하는 것이 더 중요한 파티셔닝 전략이다.</p><h3 id="방법"><a href="#방법" class="headerlink" title="방법"></a>방법</h3><p>이 글에서는 파티셔닝 방법 4가지를 설명한다. 구체적인 내용에 대해서는 <code>MySQL</code>, 특히 <code>InnoDB</code> 스토리지 엔진을 기준으로 설명하고 있다.</p><h4 id="Range"><a href="#Range" class="headerlink" title="Range"></a>Range</h4><p><img src="/images/2022-02-09-rdb-scaling/partition01.png?style=centerme"></p><p>범위를 기반으로 데이터를 나누기 쉬운 경우 사용할 수 있는 방법이다. 로그 데이터를 예로 들어볼 수 있다. 데이터가 시간에 따라 쌓이기 때문에 필요에 따라 월 단위나 연 단위로 테이블을 나눌 수 있다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> example_logs (</span><br><span class="line"> ...</span><br><span class="line"> reg_date DATETIME <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line"> <span class="keyword">PRIMARY</span> KEY (id, reg_date)</span><br><span class="line">) <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span> (<span class="keyword">YEAR</span>(reg_date)) (</span><br><span class="line"> <span class="keyword">PARTITION</span> p2017 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2018</span>),</span><br><span class="line"> <span class="keyword">PARTITION</span> p2018 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2019</span>),</span><br><span class="line"> <span class="keyword">PARTITION</span> p2019 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2020</span>),</span><br><span class="line"> <span class="keyword">PARTITION</span> p2020 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2021</span>),</span><br><span class="line"> <span class="keyword">PARTITION</span> p9999 <span class="keyword">VALUES</span> LESS THAN MAXVALUE</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>위 SQL을 보면 파티션 키로 내부 함수가 사용된 것을 볼 수 있다. 모든 내장 함수가 가능한 것은 아니고, <code>InnoDB</code>인 경우에는 이 <a href="https://dev.mysql.com/doc/refman/5.7/en/partitioning-limitations-functions.html">링크</a>에 있는 내장함수들이 가능하다. 그리고 범위 마지막 부분은 <code>MAXVALUE</code> 키워드가 사용된 것을 확인할 수 있다. 위 SQL대로면 <code>p9999</code> 파티션에 2021년도 이후 로그가 쌓이고 있다고 보면 된다. 이 때 2021년도 이후 파티션을 구성하려고 하면 단순히 <code>ADD PARTITION</code> 키워드로는 동작하지 않는다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> example_logs <span class="keyword">ADD</span> <span class="keyword">PARTITION</span> (</span><br><span class="line">    <span class="keyword">PARTITION</span> p2021 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2022</span>)</span><br><span class="line">); <span class="comment">-- ERROR</span></span><br></pre></td></tr></table></figure><p>맨 처음 <code>CREATE TABLE</code>을 한 <code>SQL</code>에서 알 수 있듯, 파티션으로 나눠질 때 위에서부터 차례대로 파티션 위치를 판단해 나누는 것을 알 수 있는데, <code>ADD PARTITION</code>을 하게 되면 이미 만들어진 파티션들 뒤에 파티션을 추가하기 때문에 마지막에 <code>MAXVALUE</code>를 사용하지 않는 상황이 된다. 따라서 파티션에 범위를 추가하기 위해서는 <code>REORGANIZE</code>를 사용해야 한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> example_logs REORGANIZE <span class="keyword">PARTITION</span> p9999 <span class="keyword">INTO</span> (</span><br><span class="line">    <span class="keyword">PARTITION</span> p2021 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2022</span>),</span><br><span class="line">    <span class="keyword">PARTITION</span> p9999 <span class="keyword">VALUES</span> LESS THAN MAXVALUE</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>다만 <code>REORGANIZE</code> 작업은 기본적으로 그 전 파티션을 복사하는 작업이다. 따라서 데이터가 많은 경우 오래 걸릴 수도 있다. 이런 문제를 해결하기 위한 일반적인 패턴 중 하나로 <code>MAXVALUE</code> 키워드를 쓰지 않고, 미래에 사용될 범위의 파티션을 미리 만들어두는 방법이 있다. 이렇게 하면 <code>ADD PARTITION</code>을 통해 간단하게 범위를 늘릴 수 있다. 당연히 문제가 발생할 여지가 있다. 이 작업이 모종의 이유로 생략되거나 문제가 생겨 생성되지 못한 상태로 해당 테이블을 사용하게 되면 파티션에 들어가야 할 데이터의 <code>INSERT</code> 작업이 동작하지 않는다.</p><hr><p>이렇게 만들어진 파티션은 간단하게 드랍할 수 있다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> example_logs <span class="keyword">DROP</span> <span class="keyword">PARTITION</span> p2017;</span><br></pre></td></tr></table></figure><p>위 코드로 2017년 로그를 삭제할 수 있다. 조건절을 통해 삭제하는 것보다 데이터베이스에 생기는 부하도 적고 빠르게 데이터를 삭제할 수 있다.</p><h4 id="List"><a href="#List" class="headerlink" title="List"></a>List</h4><p>리스트 방식은 파티션 키가 어떤 케이스에 속하는지 직접 지정해주는 방법이다. <code>IN (...)</code> 안에 파티션으로 선택되는 리스트를 만들어주어야 한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> posts (</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    title <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">        ...</span><br><span class="line">    category_id <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">) <span class="keyword">PARTITION</span> <span class="keyword">BY</span> LIST(category_id) (</span><br><span class="line">    <span class="keyword">PARTITION</span> fleamarket <span class="keyword">VALUES</span> <span class="keyword">IN</span> (<span class="number">1</span>),</span><br><span class="line">    <span class="keyword">PARTITION</span> town <span class="keyword">VALUES</span> <span class="keyword">IN</span> (<span class="number">2</span>),</span><br><span class="line">    <span class="keyword">PARTITION</span> etc <span class="keyword">VALUES</span> <span class="keyword">IN</span> (<span class="number">3</span>, <span class="keyword">NULL</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>당연히 리스트 안의 값은 겹치면 안 되고, 만약 겹치게 되면 에러를 발생시킨다. 파티션 키의 값이 지정된 코드나 값일 때 사용할 수 있다. 위 예시에서는 포스트의 카테고리에 따라 테이블을 나눠 구성한 모습이다. 또한 키 값이 오름차순이나 내림차순의 의미가 없는 경우라면 <code>Range</code>를 사용할 수 없으므로 <code>List</code> 방법이 적합한지 생각해볼 수 있다.</p><p>위에서 파티션을 추가하는 방법처럼 <code>ADD</code> 키워드를 통해 파티션을 추가할 수 있고, <code>DROP PARTITION</code>을 통해 파티션을 지울 수 있다. 또 하나의 파티션을 분리 및 병합할 때는 <code>REORGANIZE PARTITION</code>을 사용할 수 있다.</p><blockquote><p><code>List</code>, <code>Range</code> 파티션의 경우 <a href="https://dev.mysql.com/doc/refman/8.0/en/partitioning-subpartitions.html"><code>Subpartition (Composite Partition)</code></a>을 구성할 수 있다.</p></blockquote><h4 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h4><p>해시 함수에 의해 파티션을 결정할 수 있다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> accounts (</span><br><span class="line">    ...</span><br><span class="line">) <span class="keyword">PARTITION</span> <span class="keyword">BY</span> HASH(id) PARTITIONS <span class="number">4</span> (</span><br><span class="line">    <span class="keyword">PARTITION</span> p0,</span><br><span class="line">    ...</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p><code>PARTITIONS 4</code>는 4개의 파티션에 의해 분할되는 것을 의미한다. 해시 작업이라고 하는 것은 쉽게 말해서 모듈러 연산하는 작업이다. 따라서 파티션 키로 사용되는 값은 정수값을 반환해줘야 한다. 파티션 이름을 지정하려면 위에서처럼 직접 이름을 정해줄 수도 있는데, 만약 정의하지 않으면 <code>p0</code>, <code>p1</code>, … 이런 식으로 지정된다.</p><p>데이터를 균일하게 파티션에 분배되어야 잘 파티셔닝 된 것이라 볼 수 있는데, 해시의 경우 아주 균일하게 파티션을 분배한 것이라 볼 수 있다. 자원을 효율적으로 사용할 수 있지만, 데이터 목적이나 유형을 고려해서 파티션을 나눈 것은 아니다. 따라서 모든 데이터에 대해 용도가 비슷하고 사용 빈도도 비슷한 큰 데이터를 파티셔닝 해야할 때 사용하기 좋다. 예를 들어서 계정 정보는 오래 전에 가입했든 최근에 가입했든 지속해서 사용하는 사람들의 정보가 계속해서 사용된다.</p><p>하지만 이 방법으로 파티션을 분할하면 파티션을 구성을 변경하는 과정의 비용이 많이 들거나 불가능하다. 예를 들어서 하나의 파티션을 더 넣는다는 것은 해시 함수를 바꿔주는 것과 같은 의미이다. 따라서 바뀐 해시 함수로 기존 데이터를 모두 재배열 해줘야 한다. 또한 해시로 나눠진 파티션을 삭제할 일도 사실상 없다. 해시 파티션을 했을 때, 각 파티션에 어떤 데이터가 있는지에 대한 의미가 없기 떄문이다. 따라서 특정 파티션을 삭제할 이유가 없고, 실제로 삭제한려고 한다 하더라도 <code>DROP PARTITION</code>은 에러를 발생시킨다. 그리고 병합하거나 분할하는 작업도 불가능하다. 이 과정은 그냥 파티션을 늘려주거나 줄여주는 작업을 해야 한다. 예상할 수 있겠지만 파티션을 늘이고 줄이는 작업은 아주 비싼 작업이다.</p><blockquote><p><code>COALESCE PARTITION 1</code>과 같은 방법으로 파티션을 줄여줄 수 있다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> example COALESCE PARTITIONS <span class="number">1</span>;</span><br></pre></td></tr></table></figure></blockquote><p>파티셔닝 이후의 유연성이 부족한 방법이기 때문에, 설계할 때 몇 개의 파티션이 적합할지 생각해보는 것이 중요하다. 하지만 해시로 사용하는 컬럼값이 조건절에 사용되면 아주 효율적으로 파티션 프루닝이 가능하다.</p><blockquote><p>유연성이 부족한 해시 파티션 문제를 해결하기 위해서 <a href="https://dev.mysql.com/doc/refman/8.0/en/partitioning-linear-hash.html"><code>Linear Hash</code></a>를 사용할 수 있다. 그러나 사용되는 특정한 알고리즘으로 인해 데이터의 분배가 덜 균등해질 수 있다.</p></blockquote><h4 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h4><p>키 파티션 방법은 해시와 거의 비슷한데 해시 함수의 모듈러를 위해 정수형 타입을 사용해야 했던 해시와는 다르게, 대부분의 타입을 파티션 키로 사용할 수 있다. 파티션 키를 <code>MD5</code>를 통해 해시값을 계산하고 그 값을 모듈러 연산해서 파티셔닝을 해주는 구조이다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> k1 (</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">    name <span class="type">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> KEY() <span class="comment">-- 괄호가 비어있으면, 프라이머리 키 모든 칼럼을 사용함</span></span><br><span class="line">PARTITIONS <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 프라이머리 키가 따로 없으면 유니크 키를 사용</span></span><br></pre></td></tr></table></figure><p>해시 파티션에 비해서 더 균등하게 나눠질 수 있다. 따라서 보다 효율적이고, 파티션 키로 사용되는 필드가 정수형이 아니어도 되기 때문에 <code>Hash</code> 방법이 사용될 수 없는 상황에서 고려해볼 수 있다.</p><h3 id="파티셔닝-정리"><a href="#파티셔닝-정리" class="headerlink" title="파티셔닝 정리"></a>파티셔닝 정리</h3><p>파티션 키와 파티셔닝 방법을 선택하는 기준은 데이터 접근 패턴, 어떤 유형의 데이터인지, 등 고려해볼 만한 상황이 많이 있다. 그리고 단순히 인덱스를 작게 만드는 것보다 효율적인 DML을 쓰기 위해 어떻게 설계하는 것이 좋을지도 고민해봐야 한다.</p><h2 id="샤딩-Sharding"><a href="#샤딩-Sharding" class="headerlink" title="샤딩 (Sharding)"></a>샤딩 (Sharding)</h2><p>단일 서버에서 효율적으로 테이블을 나눈다고 하더라도 물리적인 한계는 반드시 존재한다. 예를 들어서 데이터베이스의 디스크 크기를 늘리기 어렵다든지, 늘릴 수 있더라도 근본적인 문제 해결 방법이 아니라든지(Network 부하, 꾸준하고 급격하게 증가하는 데이터들, 서버 자체의 부하), 이러한 이유로 결국 서버를 물리적으로 여러 대를 사용해서 해결해야 한다. 이렇게 수평적인 방식으로 파티셔닝을 하는 것을 샤딩이라고 한다.</p><blockquote><p>위에서 언급한 것처럼 파티셔닝은 스케일 아웃이라고 보기 어렵다. 스케일 아웃은 결국 “수평적 확장”을 의미한다. 수평적 파티셔닝 방법이 일반적인 데이터베이스의 스케일링 방법이다. 그런데 “수평적 방식의 파티셔닝”이라는 말처럼 방법 측면에서 파티셔닝의 방법과 유사하다.</p></blockquote><hr><p>샤딩이라고 하는 것은 RDB의 기본적인 기능은 아니다. 즉, 개발자의 엔지니어링이 요구되는 부분이다. 어떤 데이터가 어떤 노드에 들어가 있는지 판단하는 것을 개발자가 엔지니어링을 통해 라우팅 처리 해줘야 한다. 이렇게 데이터를 저장하거나 가져올 때 적절한 노드를 찾아주는 흐름을 <strong>샤딩 로직</strong> 이라고 하는데, 이 로직은 애플리케이션 사이드에 존재할 수도 있고 스토리지 시스템의 미들웨어로 존재할 수도 있다. 애플리케이션 사이드에 이 로직이 있는 것을 <strong>Application-level 샤딩</strong>이라는 이름으로 보통 불린다. 이는 애플리케이션의 로직에서 라우팅 처리를 해준다는 것을 의미한다. ORM에서 이를 설정한다든지, 직접 데이터값에 따라 어떤 데이터베이스와 연결할지 선택하는 흐름 등을 예로 들 수 있다. 반대로 스토리지 시스템 미들웨어는 <strong>솔루션</strong>, <strong>샤딩 플랫폼</strong>, <strong>프록시</strong> 등 여러 이름으로 불리고 있다. 이 방법을 사용하면 어떤 미들웨어인지에 따라 다를 수 있지만, 일반적으로 애플리케이션에서는 데이터베이스의 라우팅 처리에 신경쓰지 않고 마치 하나의 데이터베이스와 상호작용하는 것처럼 동작하게 된다.</p><hr><p>샤딩을 하게되면 그 전처럼 RDB를 사용하지 못 할 수 있다. 여러 RDB의 특징들에 제약이 생긴다는 것을 의미한다. 대표적으로 다음과 같은 문제들이 있다.</p><ul><li>물리적으로 다른 노드의 데이터베이스와 <code>JOIN</code> 연산을 수행할 수 없는 문제</li><li>Auto Increment가 샤드별로 달라지는 문제</li><li>하나의 트랜잭션이 두 개 이상의 샤드에 접근할 수 없는 문제</li></ul><p>이런 문제가 발생할 수 있으므로 샤딩을 설계하는 과정에서 이 문제들을 고려해서 샤딩을 진행해야 한다.</p><h3 id="샤드-키"><a href="#샤드-키" class="headerlink" title="샤드 키"></a>샤드 키</h3><p>파티셔닝에서도 각 파티션이 어떤 데이터를 가져갈지 결정할 파티션 키가 있었던 것처럼, 분할된 노드(분리된 데이터베이스 서버)는 각각이 가져갈 데이터를 결정해야 한다. 이 기준을 샤드 키라고 부른다. 위에서 파티션 키가 변하지 않는 값으로 설정하는 것이 좋다고 했던 것과 같은 이유로 샤드 키는 변경되지 않는 값을 기준으로 설정해야 한다.</p><h3 id="방법-1"><a href="#방법-1" class="headerlink" title="방법"></a>방법</h3><p>샤드 키를 어떻게 설계했는지에 따라 어떻게 라우팅할지도 달라진다. 여러 방법이 있지만 여러 곳에서 소개되고 있는 두 가지 방법을 가져왔다.</p><h4 id="Range-Based-Sharding"><a href="#Range-Based-Sharding" class="headerlink" title="Range Based Sharding"></a>Range Based Sharding</h4><p><img src="/images/2022-02-09-rdb-scaling/range-sharding.png?style=centerme"><br><small>출처: <a href="https://techblog.woowahan.com/2687/">우아한 형제들 기술 블로그</a></small></p><p>특정 키의 범위에 따라 샤드에 배분해주는 방법이다. 이름에서 알 수 있듯, 위 파티셔닝 방법 중 <code>Range</code> 방식과 유사하다. 특징은 샤드를 추가하는 과정이 비교적 간단하고 라우팅도 간단하다. 다만 데이터 접근 패턴이나 범위별 데이터양을 고려한 방법은 아니기 때문에 컴퓨팅 자원을 불균형하게 소비하는 케이스가 발생할 수도 있다.</p><h4 id="Modulus-Key-Hash-Based-Sharding"><a href="#Modulus-Key-Hash-Based-Sharding" class="headerlink" title="Modulus (Key, Hash Based) Sharding"></a>Modulus (Key, Hash Based) Sharding</h4><p><img src="/images/2022-02-09-rdb-scaling/modular-sharding.png?style=centerme"><br><small>출처: <a href="https://techblog.woowahan.com/2687/">우아한 형제들 기술 블로그</a></small></p><p>특정 키를 모듈러 연산으로 특정하는 방식이다. 이 방법의 다른 이름에서 알 수 있듯, 위에서 파티셔닝 방법 중 <code>Hash</code> 방식과 유사하다는 점을 알 수 있다. 특징도 <code>Hash</code> 방식의 특징과 유사하다. 데이터가 샤드에 균일하게 분산된다는 장점이 있지만, 샤드를 추가할 때 데이터를 재배열해야 하는 비용이 있다는 단점이 있다.</p><hr><h3 id="케이스-스터디"><a href="#케이스-스터디" class="headerlink" title="케이스 스터디"></a>케이스 스터디</h3><p>샤딩같은 경우는 아무래도 RDB의 자체적인 기능이 아니라서 케이스를 찾아보면 굉장히 다양한 방법으로 샤딩을 진행한 것을 볼 수 있다. 예시로 세 가지 케이스를 확인해보자.</p><h4 id="Notion-샤딩"><a href="#Notion-샤딩" class="headerlink" title="Notion 샤딩"></a>Notion 샤딩</h4><p>노션은 애플리케이션 레벨의 샤딩을 결정했다. <code>Vitess</code>, <code>Citus</code>와 같은 미들웨어 서비스를 알아보긴 했는데, 그 솔루션들의 동작이 불투명하다고 판단했고, 본인들 데이터를 직접 컨트롤하길 원했기 때문에 이러한 선택을 했다고 한다. 그 결정 이후에는 어떻게 데이터를 나눌지 결정하는 과정이 있었다.</p><ol><li>어떤 데이터를 샤드해야 할까? → 노션의 블록과 FK로 연관된 모든 데이터를 같이 묶어 하나의 샤드에 포함될 수 있도록 함으로써 데이터 부정확성 문제를 방지</li><li>어떻게 데이터를 나눠야 할까? → 워크스페이스의 ID를 기준으로 샤딩 함으로써 한 워크스페이스의 데이터들이 같은 데이터베이스 안에 들어갈 수 있도록 분할</li></ol><p>더 자세한 내용은 <a href="https://www.notion.so/blog/sharding-postgres-at-notion">이 링크</a>에서 확인할 수 있다.</p><h4 id="LINE"><a href="#LINE" class="headerlink" title="LINE"></a>LINE</h4><p>LINE Manga 서비스의 <a href="https://engineering.linecorp.com/ko/blog/line-manga-server-side/">서버 엔지니어링 스토리</a>를 보면 애플리케이션 샤딩을 한 것으로 추측된다. 몇 단계를 거쳐 샤딩을 진행했는데, 4단계에서 코드를 수정해서 샤딩을 적용한다는 얘기가 나온다. 라인 망가의 경우에는 RDB 부하 문제를 초기엔 스케일 업으로 대응했으나, 근본적인 해결책이 아니라고 판단하여 샤딩을 진행했다고 한다. 검토 과정은 생략되었는데, 새로운 컬럼을 구성하고 <code>Range Based Sharding</code>을 진행했다고 한다.</p><h4 id="NHN"><a href="#NHN" class="headerlink" title="NHN"></a>NHN</h4><p>NHN의 경우 게임 서버 얘기였는데, 여러 서버로 샤딩을 한 상태에서 애플리케이션 레벨의 샤딩을 했을 때 컨넥션과 관련한 문제가 생길 수 있었다고 한다. 애플리케이션 서버가 200대, DB에 컨넥션이 서버당 300개씩 각자 거는 상황이면, 하나의 DB마다 최대 6만 개의 컨넥션이 생기게 된다. 이 문제를 해결하기 위해 미들웨어를 두고 프록시를 사용하고 있다고 한다. 여기서 사용된 미들웨어는 <code>ProxySQL</code>이고, 이 솔루션을 사용하게 되면 애플리케이션 레벨에서는 하나의 데이터베이스와 통신하는 것과 같이 구성할 수 있었다고 한다. 동시 접속의 개념이 있는 게임 서버에서 컨넥션을 Demultiplexing 하는 과정에 대해 더 자세히 알아보고 싶다면 <a href="https://www.youtube.com/watch?v=8Eb_n7JA1yA&ab_channel=NHNCloud">이 영상</a>을 보자.</p><h2 id="마치며"><a href="#마치며" class="headerlink" title="마치며"></a>마치며</h2><p>사실 애플리케이션의 사용자가 증가하면서 부하를 견디는 설계를 할 때 애플리케이션이 데이터베이스와 접근할 때뿐만 아니라 고려해야 할 사항이 많이 있다. 데이터베이스의 부하를 분산하는 방법으로 미들웨어를 사용한 샤딩을 결정했다면, 이 미들웨어가 애플리케이션으로부터 오는 부하를 강하게 견디는지도 확인해봐야 한다. 이런 전반적인 이야기는 <code>Database HA</code> (<code>High Availability</code>)라는 키워드로 몇 가지 더 알아봐야 한다. 그리고 Replication과 관련된 얘기도 이 글에서는 빠져있는데, 데이터베이스를 복제해 읽기 전용 슬레이브 레플리카를 만들거나, 데이터 분석용, 백업용, 등 여러 이유로 사용할 수도 있다.</p>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/database/">database</category>
      
      
      <category domain="https://changhoi.kim/tags/cs/">cs</category>
      
      <category domain="https://changhoi.kim/tags/rdb/">rdb</category>
      
      
      <comments>https://changhoi.kim/posts/database/rdb-scaling/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>모던 자바스크립트 핵심 가이드 간단 리뷰</title>
      <link>https://changhoi.kim/posts/books/complete-guide-to-modern-javascript-book-review/</link>
      <guid>https://changhoi.kim/posts/books/complete-guide-to-modern-javascript-book-review/</guid>
      <pubDate>Sat, 18 Dec 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;이번년도에도 한빛 미디어의 나는 리뷰어다에 선정되어 매달 책 한 권씩을 읽을 수 있게 됐다. 12월달 미션으로 나온 책 중에 하나인 모던 자바스크립트 핵심 가이드를 받게 됐고, 이번 달에 읽어보게 됐다. 이 글은 이 책에 대한 간단한 리뷰이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>이번년도에도 한빛 미디어의 나는 리뷰어다에 선정되어 매달 책 한 권씩을 읽을 수 있게 됐다. 12월달 미션으로 나온 책 중에 하나인 모던 자바스크립트 핵심 가이드를 받게 됐고, 이번 달에 읽어보게 됐다. 이 글은 이 책에 대한 간단한 리뷰이다.</p><span id="more"></span><p>이 책은 자바스크립트의 핵심 기술에 대한 명확한 설명과, 그에 대한 쉬운 예시로 문법의 이해를 돕고, 기술의 이해도를 확인 할 수 있는 문제들로 구성되어있다. 필자는 이 문제 풀이 부분이 특히 가장 마음에 들었다. 문제를 풀어봄으로써 스스로 어디까지 이해 했는가 확인 하고, 부족한 부분들을 알게 해주기 때문이다.<br>필자는 이 책이 자바스크립트를 처음 접하는 사람들은 물론이고 어느정도 지식을 가지고 있는 사람들에게도 추천 하고싶다. 그 이유는 앞서 말한 구성이 잘 짜여있고, 책의 부족한 설명은 중간에 스스로 학습할 수 있게 링크를 알려주는 방식으로 보완하여 입문자가 아니더라도 충분히 읽을만 하다고 생각했기 때문이다. 또한 문법의 다양한 쓰임을 알려주기 때문에 이미 알고 있다 하더라도 다시 한 번 기본 지식을 단단히 다지는데 좋을 것 같다고 생각했다.</p>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/books/">books</category>
      
      
      <category domain="https://changhoi.kim/tags/review/">review</category>
      
      
      <comments>https://changhoi.kim/posts/books/complete-guide-to-modern-javascript-book-review/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Go에서 range의 모든 것</title>
      <link>https://changhoi.kim/posts/go/about-go-range/</link>
      <guid>https://changhoi.kim/posts/go/about-go-range/</guid>
      <pubDate>Sun, 17 Oct 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;Go 언어의 내장 함수들은 많지 않지만, 각각이 일당백 역할을 한다. &lt;code&gt;make&lt;/code&gt;, &lt;code&gt;new&lt;/code&gt;, &lt;code&gt;range&lt;/code&gt;는 Go 프로그램을 작성할 때 넓은 범위에서 사용되는 내장 함수이다. 이번 포스팅에서는 &lt;code&gt;range&lt;/code&gt; 활용에 대해서 정리해두었다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>Go 언어의 내장 함수들은 많지 않지만, 각각이 일당백 역할을 한다. <code>make</code>, <code>new</code>, <code>range</code>는 Go 프로그램을 작성할 때 넓은 범위에서 사용되는 내장 함수이다. 이번 포스팅에서는 <code>range</code> 활용에 대해서 정리해두었다.</p><span id="more"></span><p><code>range</code>는 <code>for</code>와 함께 사용된다. <code>range</code>의 뒷 부분으로 배열, 슬라이스, 맵, 또는 채널(특히, 값을 받는 역할을 하는)이 들어올 수 있다. 이터레이션 값들 (<code>iteration values</code>라고 표현함)이 있는 경우 그 값을 할당해주고 반복문의 블록으로 진입하게 된다.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, val := <span class="keyword">range</span> intSlice &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 가장 많이 사용되는 슬라이스 순환</span></span><br></pre></td></tr></table></figure><p><code>range</code> 문의 오른쪽 영역을 <code>range expression</code>이라고 하는데, 이 영역에는 다음 표현들이 들어올 수 있다.</p><ul><li>배열, 배열 포인터</li><li>슬라이스</li><li>문자열</li><li>맵</li><li>채널 (받기 동작을 할 수 있어야 한다.)</li></ul><p><code>range</code> 왼쪽의 <code>=</code> 또는 <code>:=</code> 기준으로 그 다음 왼쪽 영역은 이터레이션 변수(<code>iteration variables</code>)라고 하는데, <code>range expression</code>이 채널인 경우는 최대 1개의 이터레이션 변수가 가능하고, 나머지는 최대 2개까지 가능하다.</p><blockquote><p>0개 부터 2개까지 사용이 가능하다, 1개만 사용하면, 첫 번째 이터레이션 값이 할당된다.</p></blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> [<span class="string">`iteration variables`</span>] := <span class="keyword">range</span> <span class="string">`range expression`</span></span><br><span class="line"><span class="comment">// `range`는 `range expression`에 맞게 `iteration values`를 반복 생성</span></span><br><span class="line"><span class="comment">// `iteration variables`에 할당한다.</span></span><br></pre></td></tr></table></figure><p><code>range expression</code>를 <code>x</code>라고 했을 때, <code>x</code>는 루프가 시작할 때 딱 한 번 평가된다. 하나의 예외가 있는데, 최대 하나의 이터레이션 변수가 있는 상황에서 <code>len(x)</code> 값이 상수인 경우 <code>range expression</code>은 평가 되지 않는다.</p><blockquote><p><code>len(x)</code>가 상수인 경우라는 뜻은, <code>x</code>가 상수 문자열이거나, 배열이거나 배열 포인터 이면서, 그 배열에 받는 쪽 채널이나 함수 호출등이 없는 경우에 해당한다. 자세한 내용은 이 <a href="https://golang.org/ref/spec#Length_and_capacity">링크</a>에 나온다.</p></blockquote><blockquote><p><code>range expression</code>을 평가한다는 것은, 어떤 표현식인지를 판단하는 과정이다. 공부하면서 든 생각인데, 슬라이스 중간에 값을 추가하는 동작을 하더라도 이터레이션 횟수가 변하지 않는데, 이유가 표현식을 첫 루프 시작할 때만 평가하기 때문이 아닐까 싶다.</p></blockquote><hr><p>왼쪽에 이터레이션 변수가 있다면, 각 값에 대해 이터레이션 값이 생성된다.</p><table><thead><tr><th align="center">Range Expression</th><th align="center">1st value</th><th align="center">2nd value</th></tr></thead><tbody><tr><td align="center">배열, 슬라이스, 배열 포인터</td><td align="center">인덱스</td><td align="center">값</td></tr><tr><td align="center">문자열</td><td align="center">인덱스</td><td align="center">룬</td></tr><tr><td align="center">맵</td><td align="center">키</td><td align="center">값</td></tr><tr><td align="center">채널</td><td align="center">요소</td><td align="center">-</td></tr></tbody></table><ol><li>배열, 슬라이스, 배열 포인터인 <code>a</code>가 <code>range expression</code>으로 사용된 경우: 첫 번째 값으로는 인덱스(<code>i</code>) 값이 0부터 오름차순으로 생성된다. 만약 이터레이션 변수가 하나만 제공된 경우, 0부터 <code>len(a) - 1</code> 까지의 값을 생성하게 된다. 두 번째 값으로는 <code>a[i]</code> 값을 생성한다. <code>nil</code> 슬라이스는 이터레이션 횟수가 0이다.</li><li>문자열의 경우, 바이트 인덱스 0부터 시작해서 유니코드 절을 반복한다. 연속 반복할 때 인덱스 값은 문자열에서 UTF-8 인코딩 된 코드 포인트의 첫 번째 바이트 인덱스가 되고, 두 번째 값은 해당 코드 포인트의 값이 된다. 반복 과정 중 잘못된 UTF-8 시퀀스를 만나면, 두 번째 값이 <code>0xFFFD</code>가 되고, 다음 반복에서는 바이트 단위로 진행되게 된다.</li><li><code>map[K]V</code> 타입의 맵 <code>m</code>의 경우, 첫 번째 값은 <code>K</code> 타입인 키 <code>k</code>이다. 두 번째 값은 <code>V</code> 타입인 값 <code>m[k]</code>이다. 반복 순서는 보장되지 않는다. 반복 도중에 도달하지 않은 엔트리가 제거된다면, 이터레이션 값이 생성되지 않는다. 만약 맵의 값이 반복 중 생성되는 경우엔 이터레이션 값을 만들 수도 있고 생략될 수도 있다. 만들어져 있던 엔트리들과 반복마다 다를 수 있다. 만약 맵이 <code>nil</code>인 경우 이터레이션 횟수는 0이다.</li><li>채널의 경우, 이터레이션 값은 채널이 닫히기 까지 받은 연속된 값이다. 만약 채널이 <code>nil</code>이라면, <code>range expression</code>이 영원히 블락되어버린다.</li></ol><hr><p>아래는 문자열의 경우 예시이다.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, r := <span class="keyword">range</span> <span class="string">&quot;→👍👎🌮🗂HelloWorld!안녕세상아!😊🚀🔥📝.&quot;</span> &#123;</span><br><span class="line">  fmt.Print(i, <span class="string">&quot; &quot;</span>)</span><br><span class="line">  fmt.Println(<span class="keyword">string</span>(r))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, r := <span class="keyword">range</span> <span class="string">&quot;string, just string&quot;</span> &#123;</span><br><span class="line">  fmt.Print(i, <span class="string">&quot; &quot;</span>)</span><br><span class="line">  fmt.Println(<span class="keyword">string</span>(r))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>아래 문자열을 보면, 룬을 잘라 넣고 이동한 바이트 만큼 인덱스가 이동하는 것을 확인할 수 있다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">0 →</span><br><span class="line">3 👍</span><br><span class="line">7 👎</span><br><span class="line">11 🌮</span><br><span class="line">15 🗂</span><br><span class="line">19 H</span><br><span class="line">20 e</span><br><span class="line">21 l</span><br><span class="line">22 l</span><br><span class="line">23 o</span><br><span class="line">24 W</span><br><span class="line">25 o</span><br><span class="line">26 r</span><br><span class="line">27 l</span><br><span class="line">28 d</span><br><span class="line">29 !</span><br><span class="line">30 안</span><br><span class="line">33 녕</span><br><span class="line">36 세</span><br><span class="line">39 상</span><br><span class="line">42 아</span><br><span class="line">45 !</span><br><span class="line">46 😊</span><br><span class="line">50 🚀</span><br><span class="line">54 🔥</span><br><span class="line">58 📝</span><br><span class="line">62 .</span><br><span class="line">0 s</span><br><span class="line">1 t</span><br><span class="line">2 r</span><br><span class="line">3 i</span><br><span class="line">4 n</span><br><span class="line">5 g</span><br><span class="line">6 ,</span><br><span class="line">7  </span><br><span class="line">8 j</span><br><span class="line">9 u</span><br><span class="line">10 s</span><br><span class="line">11 t</span><br><span class="line">12  </span><br><span class="line">13 s</span><br><span class="line">14 t</span><br><span class="line">15 r</span><br><span class="line">16 i</span><br><span class="line">17 n</span><br><span class="line">18 g</span><br></pre></td></tr></table></figure><p>다음은 맵에서 값을 추가하는 경우이다.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">m := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>)</span><br><span class="line">m[<span class="string">&quot;key&quot;</span>] = <span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> k, v := <span class="keyword">range</span> m &#123;</span><br><span class="line">  m[k+<span class="string">&quot;next&quot;</span>] = v + <span class="number">1</span></span><br><span class="line">  fmt.Println(m)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>아래 결과를 보면, 임의로 추가된 엔트리가 출력되기도 하고, 안되기도 한다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ go run main. go</span><br><span class="line">map[key:10 keynext:11]</span><br><span class="line"></span><br><span class="line">$ go run main.go</span><br><span class="line">map[key:10 keynext:11]</span><br><span class="line">map[key:10 keynext:11 keynextnext:12]</span><br><span class="line"></span><br><span class="line">$ go run main.go</span><br><span class="line">map[key:10 keynext:11]</span><br><span class="line">map[key:10 keynext:11 keynextnext:12]</span><br><span class="line">map[key:10 keynext:11 keynextnext:12 keynextnextnext:13]</span><br><span class="line">map[key:10 keynext:11 keynextnext:12 keynextnextnext:13 keynextnextnextnext:14]</span><br><span class="line">map[key:10 keynext:11 keynextnext:12 keynextnextnext:13 keynextnextnextnext:14 keynextnextnextnextnext:15]</span><br><span class="line">map[key:10 keynext:11 keynextnext:12 keynextnextnext:13 keynextnextnextnext:14 keynextnextnextnextnext:15 keynextnextnextnextnextnext:16]</span><br><span class="line">map[key:10 keynext:11 keynextnext:12 keynextnextnext:13 keynextnextnextnext:14 keynextnextnextnextnext:15 keynextnextnextnextnextnext:16 keynextnextnextnextnextnextnext:17]</span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://golang.org/ref/spec#For_statements">https://golang.org/ref/spec#For_statements</a></li><li><a href="https://golang.org/ref/spec#Length_and_capacity">https://golang.org/ref/spec#Length_and_capacity</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/go/">go</category>
      
      
      <category domain="https://changhoi.kim/tags/programming/">programming</category>
      
      
      <comments>https://changhoi.kim/posts/go/about-go-range/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>NAT에 대하여</title>
      <link>https://changhoi.kim/posts/network/about-nat/</link>
      <guid>https://changhoi.kim/posts/network/about-nat/</guid>
      <pubDate>Wed, 06 Oct 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;NAT은 클라우드 환경에서 인프라를 구성하다 보면 쉽게 보이는 단어들이다. 사설망을 유지하면서 외부 인터넷과 단방향으로 연결하려면 어떻게 할지?와 같은 상황에서 NAT 인스턴스를 통해 외부와 연결하는 방법이 있다. NAT이 어떻게 동작하는 건지 간단하게 정리했다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>NAT은 클라우드 환경에서 인프라를 구성하다 보면 쉽게 보이는 단어들이다. 사설망을 유지하면서 외부 인터넷과 단방향으로 연결하려면 어떻게 할지?와 같은 상황에서 NAT 인스턴스를 통해 외부와 연결하는 방법이 있다. NAT이 어떻게 동작하는 건지 간단하게 정리했다.</p><span id="more"></span><h2 id="동작-방식"><a href="#동작-방식" class="headerlink" title="동작 방식"></a>동작 방식</h2><p>일단 네트워크를 활용해야 하는 장비는 모두 IP가 필요하다. 그런데, 모든 장비에게 각각의 IP를 부여하면, 하나의 작은 오피스에도 넓은 범위의 IP 주소 범위를 할당해야 한다. 이런 문제를 해결하는 방법이 네트워크 주소 변환(NAT, Network Address Translation)이다.</p><p>NAT 역할을 하는 라우터는 실제로 외부에서 보기엔 라우터처럼 보이지 않고, 하나의 IP 주소를 갖는 장비로서 동작한다.</p><p><img src="/images/2021-10-07-about-nat/nat.jpg"></p><p>위 이미지를 보면, NAT 안쪽으로는 192.168.1.0/24 에 해당하는 서브넷을 사용하고 있다. 이 주소는 <strong>사설망</strong>이라고 하고, 전세계적으로 사용되는 사설망 IP 대역이 있다.</p><ul><li>10.0.0.0/8 (10.0.0.0 ~ 10.255.255.255)</li><li>172.16.0.0/12 (172.16.0.0 ~ 172.31.255.255)</li><li>192.168.0.0/16 (192.168.0.0 ~ 192.168.255.255)</li></ul><p>위 주소는 수많은 네트워크들이 동일하게 부여받기 때문에, NAT을 넘어서 외부에서는 사용할 수가 없다.</p><blockquote><p>NAT 안쪽을 LAN 밖을 WAN 방향이라고 표현할 수 있다.</p></blockquote><p>192.168.1.2 PC에서 173.194.67.102 호스트로 요청을 보내기 위해서는 192.168.1.1을 할당받은 NAT 인터페이스로 들어가서 NAT이 ISP의 DHCP를 통해 부여받은 IP를 사용해 요청을 보내게 된다.</p><blockquote><p>각 PC가 사설망의 IP 주소를 얻는 과정도 NAT의 [[DHCP]] 서버를 통해 얻게 된다.</p></blockquote><p>구체적인 예시를 생각해보자. 192.168.1.2 PC는 173.194.67.102:80 으로 요청을 보내고 있다. 출발지 PC는 요청에 임의의 포트 번호를 달아 보내게 된다. 여기서는 3345를 할당했다고 가정해보자. 192.168.1.2:3345 형태로 LAN에 데이터그램을 보내면, NAT은 이 데이터그램을 받아, NAT 출발 IP 주소를 NAT의 WAN쪽에 있는 인터페이스의 IP로 바꾸고, 포트번호도 NAT에서 할당 할 수 있는 새로운 출발지 번호로 다시 변경한다. 즉, 192.168.1.2:3345를 67.210.97.1:5505로 바꾼다는 뜻이다. 이 때, 변환된 정보를 저장하기 위해 NAT 변환 테이블(NAT Translation Table)을 사용한다. 이런 TCP 요청을 보내면, 다음과 같은 엔트리가 추가된다.</p><table><thead><tr><th>Protocol</th><th>LAN</th><th>WAN</th></tr></thead><tbody><tr><td>TCP</td><td>192.168.1.2:3345</td><td>67.210.97.1:5505</td></tr></tbody></table><p>서버는 다시 67.210.971:5505에게 응답을 보내게 되고, NAT는 NAT 변환 테이블을 사용해서 다시 원래 IP와 포트번호로 바꿔 LAN 네트워크로 보낸다.</p><blockquote><p>NAT의 포트 번호와 LAN의 장비를 연결해 테이블 엔트리를 작성하기 때문에, 결국 포트 숫자 만큼 동시접속을 허용한다. 2^16, 약 6만개의 동시접속을 허용하는 것이다.</p></blockquote><blockquote><p>위 방식은 NAT 종류 중 PAT(Port Address Translation) 방식에 해당한다.</p></blockquote><h2 id="사용-이유"><a href="#사용-이유" class="headerlink" title="사용 이유"></a>사용 이유</h2><ol><li>IP 주소 절약: 처음 언급한 것처럼, 하나의 공인 IP를 가지고 여러 사설망을 운영함으로써 IP 소비를 줄일 수 있다.</li><li>보안: NAT의 특성상, 요청을 보낸 측의 IP를 숨기는 효과가 있다. 라우터 안쪽의 최종 목적지를 외부에서는 알 수 없다. 따라서, 내부에서 외부로의 요청은 가능하지만, 외부에서 내부로 요청은 불가능하다.</li></ol><blockquote><p>단, NAT에서 포트포워딩을 통해 특정 포트에 대해서 내부로 라우팅을 처리한다면 가능하다.</p></blockquote>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/network/">network</category>
      
      
      <category domain="https://changhoi.kim/tags/cs/">cs</category>
      
      <category domain="https://changhoi.kim/tags/network-layer/">network_layer</category>
      
      
      <comments>https://changhoi.kim/posts/network/about-nat/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>DHCP에 대하여</title>
      <link>https://changhoi.kim/posts/network/about-dhcp/</link>
      <guid>https://changhoi.kim/posts/network/about-dhcp/</guid>
      <pubDate>Wed, 22 Sep 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;h2 id=&quot;DHCP란&quot;&gt;&lt;a href=&quot;#DHCP란&quot; class=&quot;headerlink&quot; title=&quot;DHCP란&quot;&gt;&lt;/a&gt;DHCP란&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;DHCP&lt;/strong&gt;(&lt;strong&gt;Dynamic Host Configuration Protocol&lt;/strong&gt;)은 호스트 IP에 주소를 동적으로 자동 할당하는 방식이다. 호스트에게 IP를 할당하는 작업은 수동으로도 할 수 있지만, 일반적으로 DHCP을 사용한다. 관리자는 수동으로 IP를 설정하지 않고, 특정 호스트가 들어왔을 때 이 호스트가 특정 IP를 받도록 하거나, 임시 IP 주소를 받도록 DHCP를 설정해두면 된다. 아래 이미지는 공유기 설정에 있는 DHCP 설정 화면이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="DHCP란"><a href="#DHCP란" class="headerlink" title="DHCP란"></a>DHCP란</h2><p><strong>DHCP</strong>(<strong>Dynamic Host Configuration Protocol</strong>)은 호스트 IP에 주소를 동적으로 자동 할당하는 방식이다. 호스트에게 IP를 할당하는 작업은 수동으로도 할 수 있지만, 일반적으로 DHCP을 사용한다. 관리자는 수동으로 IP를 설정하지 않고, 특정 호스트가 들어왔을 때 이 호스트가 특정 IP를 받도록 하거나, 임시 IP 주소를 받도록 DHCP를 설정해두면 된다. 아래 이미지는 공유기 설정에 있는 DHCP 설정 화면이다.</p><span id="more"></span><p><img src="/images/2021-09-23-about-dhcp/01.png" alt="공유기 설정의 DHCP"></p><blockquote><p>호스트에게 동적으로 IP를 할당해주는 것 말고도, 서브넷 마스크 첫 번째 홉 라우터 (Default Gateway)의 IP 주소나, 로컬 DNS 서버 주소를 얻게 해준다.</p></blockquote><p>이 기능은 호스트가 빈번하게 들어왔다 나갔다 하는 환경에 아주 유용하다. 예를 들어 도서관과 같은 곳에서 사람들이 IP를 얻기 위해 매번 네트워크 관리자를 찾아갈 필요가 없다.</p><hr><p>DHCP는 클라이언트/서버 구조의 프로토콜이다. 여기서 클라이언트는 네트워크 설정을 위한 정보를 얻기 위해 도착한 새로운 호스트이다. 서브넷에는 일반적으로 하나의 DHCP 서버를 갖는다. 만약 없다면, 해당 네트워크에서 사용할 DHCP 서버 주소를 알려줄 DHCP 연결 에이전트(일반적으로 라우터)가 필요하다.</p><p><img src="/images/2021-09-23-about-dhcp/02.png" alt="DHCP가 포함된 서브넷 구조"></p><p><code>223.1.2.0/24</code> 서브넷에 연결된 DHCP 서버가 있고 나머지 두 서브넷에는 없기 때문에, 라우터가 DHCP 연결 에이전트 역할을 한다.</p><h2 id="DHCP-동작"><a href="#DHCP-동작" class="headerlink" title="DHCP 동작"></a>DHCP 동작</h2><p>새로 들어온 클라이언트는 4단계 과정을 거쳐 IP를 할당받는다.</p><h3 id="1-DHCP-서버-발견-DHCP-server-discovery"><a href="#1-DHCP-서버-발견-DHCP-server-discovery" class="headerlink" title="1. DHCP 서버 발견 (DHCP server discovery)"></a>1. DHCP 서버 발견 (DHCP server discovery)</h3><p>새롭게 도착한 호스트는 상호 동작될 DHCP를 찾아야 한다. 이 과정은 <strong>DHCP 발견 메시지</strong>(<strong>DHCP discover message</strong>)를 통해 수행된다. 클라이언트는 서버의 67번 포트로 UDP 패킷을 보낸다. 현재 호스트는 자신이 접속될 네트워크 주소도 모르고 DHCP 서버의 주소도 모른다. 이런 상황이기 때문에 DHCP 발견 메시지를 포함하는 IP 데이터그램으로 UDP 패킷을 캡슐화 하는데, 이 메시지 내의 목적지 IP 주소는 브로드캐스팅 IP 주소인 <code>255.255.255.255</code>를 사용한다. 출발지 주소는 <code>0.0.0.0</code>으로 설정한다. 이 데이터그램은 링크 계층에 의해 서브넷 안에서 연결된 모든 노드로 브로드캐스팅 된다.</p><h3 id="2-DHCP-서버-제공-DHCP-server-offer"><a href="#2-DHCP-서버-제공-DHCP-server-offer" class="headerlink" title="2. DHCP 서버 제공 (DHCP server offer)"></a>2. DHCP 서버 제공 (DHCP server offer)</h3><p>DHCP 발견 메시지를 받은 서버는 <strong>DHCP 제공 메시지</strong>를 보내 응답한다. 이 때에도 다시 IP 브로드캐스팅 주소 <code>255.255.255.255</code>를 사용해 서브넷의 모든 노드로 보낸다. 제공 메시지에는 다음 정보들이 포함되어있다.</p><ul><li>수신된 메시지의 트랜잭션 ID</li><li>클라이언트에게 제공된 IP 주소</li><li>네트워크 마스크</li><li>IP 주소 임대 기간 (IP 주소가 유효한 시간)</li></ul><h3 id="3-DHCP-요청-DHCP-request"><a href="#3-DHCP-요청-DHCP-request" class="headerlink" title="3. DHCP 요청 (DHCP request)"></a>3. DHCP 요청 (DHCP request)</h3><p>서브넷에는 도달할 수 있는 DHCP 서버가 복수일 수 있으므로, 클라이언트는여러 응답 중 하나를 선택해 파라미터 설정을 통해 DHCP 요청 메시지를 만들어 응답한다.</p><h3 id="4-DHCP-ACK"><a href="#4-DHCP-ACK" class="headerlink" title="4. DHCP ACK"></a>4. DHCP ACK</h3><p>서버는 DHCP 요청 메시지에 대해 요청된 파라미터를 확인하는 DHCP ACK 메시지로 응답한다.</p><p><img src="/images/2021-09-23-about-dhcp/03.png" alt="DHCP Handshake"></p><hr><p>클라이언트가 ACK를 받으면 상호 동작은 종료되고 IP 주소를 임대 기간 동안 사용할 수 있다. </p>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/network/">network</category>
      
      
      <category domain="https://changhoi.kim/tags/cs/">cs</category>
      
      <category domain="https://changhoi.kim/tags/network-layer/">network_layer</category>
      
      
      <comments>https://changhoi.kim/posts/network/about-dhcp/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>처음 시작하는 마이크로서비스 간단 리뷰</title>
      <link>https://changhoi.kim/posts/books/microservices-up-and-running-review/</link>
      <guid>https://changhoi.kim/posts/books/microservices-up-and-running-review/</guid>
      <pubDate>Tue, 21 Sep 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;이번년도에도 한빛 미디어의 &lt;strong&gt;나는 리뷰어다&lt;/strong&gt;에 선정되어 매달 책 한 권씩을 읽을 수 있게 됐다. 9월달 미션으로 나온 책 중에 하나인 &lt;strong&gt;처음 시작하는 마이크로서비스&lt;/strong&gt;를 받게 됐고, 이번 달에 읽어보게 됐다. 이 글은 이 책에 대한 간단한 리뷰이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>이번년도에도 한빛 미디어의 <strong>나는 리뷰어다</strong>에 선정되어 매달 책 한 권씩을 읽을 수 있게 됐다. 9월달 미션으로 나온 책 중에 하나인 <strong>처음 시작하는 마이크로서비스</strong>를 받게 됐고, 이번 달에 읽어보게 됐다. 이 글은 이 책에 대한 간단한 리뷰이다.</p><span id="more"></span><p>기술적인 내용을 기대한다면, 사실 이 책은 추천도서로 오를 수 없다. 이 책은 마이크로서비스를 도입하고자 하는 팀에게 기술 외적인 부분에서부터 팀 구성과 팀의 규칙, 그리고 경계를 설정하는 등 비 개발적인 영역에서 고민해야 하는 점들부터 시작한다. 그러나 간단하게나마 기술에 대한 구체적인 이야기도 나오기 때문에, Up &amp; Running이라는 말이 정말 딱 어울린다. 어떻게 팀을 구성할 수 있는지, 어떤 팀이 있고 어떤 역할을 하는지에 대한 일반적인 이야기가 궁금한 사람들에게 정말 필요한 도서이다. 필자도 마이크로서비스에 대해 아는 바가 없었기 때문에 이런 이야기들이 반가웠다.<br>이 책이 마이크로서비스를 접해본 적 없는 초보자에게 만큼은 아주 좋은 책이라고 생각했는데, 책 전반적인 내용에서 CI/CD를 다루는 내용과, IaC에 대한 내용, 그리고 결과적으로 핸즈온 성격으로 항공편 관련 애플리케이션을 마이크로서비스로 구성해볼 수 있도록 책을 구성했다. 마이크로서비스는 꽤 거대한 영역이라는 생각이 많이 드는데, 그 영역을 공부하는 물꼬를 틀 수 있는 좋은 책이라고 생각했다.</p>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/books/">books</category>
      
      
      <category domain="https://changhoi.kim/tags/review/">review</category>
      
      
      <comments>https://changhoi.kim/posts/books/microservices-up-and-running-review/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>메모리 할당과 매핑</title>
      <link>https://changhoi.kim/posts/os/memory-allocation-and-mapping/</link>
      <guid>https://changhoi.kim/posts/os/memory-allocation-and-mapping/</guid>
      <pubDate>Wed, 08 Sep 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;우리는 코드를 짤 때, 실제 메모리 위치를 알고 코드를 쓰지 않는다. &lt;code&gt;count := 10&lt;/code&gt; 이라는 코드를 쓰면, &lt;code&gt;count&lt;/code&gt;라는 변수가 메모리 어디에 위치하는지를 알고 짜는 것은 아니다. 프로그램을 동작시키려면 메모리에 올려야 하는데, 이 과정에서 발생하는 우리가 짠 코드가 실제 메모리에는 어떻게 올라가고, 어떻게 주소를 찾아가는지에 대한 이야기이다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>우리는 코드를 짤 때, 실제 메모리 위치를 알고 코드를 쓰지 않는다. <code>count := 10</code> 이라는 코드를 쓰면, <code>count</code>라는 변수가 메모리 어디에 위치하는지를 알고 짜는 것은 아니다. 프로그램을 동작시키려면 메모리에 올려야 하는데, 이 과정에서 발생하는 우리가 짠 코드가 실제 메모리에는 어떻게 올라가고, 어떻게 주소를 찾아가는지에 대한 이야기이다.</p><span id="more"></span><h1 id="Continuous-Memory-Allocation"><a href="#Continuous-Memory-Allocation" class="headerlink" title="Continuous Memory Allocation"></a>Continuous Memory Allocation</h1><p>연속 메모리 할당 방식은 초기 버전의 메모리 할당 방식에 해당한다. 가장 쉬운 방법으로는 고정된 크기로 메모리를 나눠 프로세스에게 할당해주는 방식이 있고, 효율적인 메모리 분배를 위해 파티션을 프로세스 크기에 따라 나누는 방법이 있다.</p><h2 id="Fixed-Partition-FPM-고정-분할"><a href="#Fixed-Partition-FPM-고정-분할" class="headerlink" title="Fixed Partition (FPM, 고정 분할)"></a>Fixed Partition (FPM, 고정 분할)</h2><p>이름대로, 고정된 크기로 메모리를 나누는 방식이다. 각 분할마다 한 프로세스를 가지게 되며, 이때 분할의 개수를 <strong>다중 프로그래밍 정도</strong>(Multiprogarmming Degree)라고 한다. 한 분할이 비게 되면 프로세스가 입력 큐(<code>input queue</code>)에서 선택되어 빈 분할로 들어오게 된다. 이 방식은 내부 단편화와 외부 단편화 모두 발생할 수 있다.</p><h2 id="Variable-Partition-VPM-가변-분할"><a href="#Variable-Partition-VPM-가변-분할" class="headerlink" title="Variable Partition (VPM, 가변 분할)"></a>Variable Partition (VPM, 가변 분할)</h2><p>가변 분할 방식에서는 어떤 부분이 사용되었는지를 파악하는 테이블을 사용해야 한다. 초기에는 하나의 큰 사용 가능한 블록, <strong>hole</strong>이 있는 상태라고 한다. 프로세스가 <code>input queue</code>에 들어오면 프로세스가 사용할 메모리를 확인하고, 남은 공간이 있다면 필요한 메모리만큼 할당해준다. 이 방식에서는 내부 단편화가 발생할 수 없지만, 여러 프로세스에 메모리를 할당하고 빼주는 과정을 거치다 보면 외부 단편화 문제는 발생할 수 있다. 예를 들어, 다음 시나리오를 생각해보자.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">매모리 공간 55MB</span><br><span class="line"></span><br><span class="line">1. P1 적재 -&gt; 20MB</span><br><span class="line">2. P2 적재 -&gt; 10MB</span><br><span class="line">3. P3 적재 -&gt; 10MB</span><br><span class="line">3. P4 적재 -&gt; 10MB</span><br><span class="line">4. P1, P3, P4 종료</span><br><span class="line">5. P5 적재 -&gt; 30MB</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>위 시나리오에서 초기 상태, 메모리 사용 상태를 파악하는 <strong>파티션 테이블</strong>은 다음과 같다.  </p><img src="/images/2021-09-09-memory-allocation-and-mapping/01.png?style=centerme" width="500" height="200"><p><code>P4</code>까지 적재된 후의 상태는 다음과 같다.  </p><img src="/images/2021-09-09-memory-allocation-and-mapping/02.png?style=centerme" width="500" height="200">    <p>이제 <code>P1</code>, <code>P3</code>, <code>P4</code>가 종료 되고 나면 Partition 1, 3, 4는 빈 공간이 되고, 3, 4번 파티션이 합쳐진다.  </p><blockquote><p>이렇게 빈 영역을 하나의 파티션으로 합치는 것을 <code>Coalescing holes</code>(공간 통합)라고 한다.</p></blockquote><img src="/images/2021-09-09-memory-allocation-and-mapping/03.png?style=centerme" width="500" height="200"><p>현재 남은 공간은 총 45MB이지만, 이는 연속되지 않았기 때문에 <code>P5</code>를 적재할 수 없는 상태이다. 즉, 외부 단편화가 발생하는 상황인 것이다.</p><hr><h2 id="메모리-배치-전략"><a href="#메모리-배치-전략" class="headerlink" title="메모리 배치 전략"></a>메모리 배치 전략</h2><p>위와 같은 예시 상태에서, <code>P5</code>가 10MB라고 가정해보자. 현재 남은 파티션은 1, 3이고 두 파티션 모두 적재할 수 있는 크기이다. 그렇다면 어디에 배치할 수 있을까? 이것을 결정하는 문제의 해결책은 대표적으로 <strong>최초 적합</strong>(<strong>First-fit</strong>), <strong>최적 적합</strong>(<strong>Best-fit</strong>), <strong>최악 적합</strong>(<strong>Worst-fit</strong>)이 있다.</p><h3 id="최초-적합-First-fit"><a href="#최초-적합-First-fit" class="headerlink" title="최초 적합 (First-fit)"></a>최초 적합 (First-fit)</h3><p>메모리 가용 파티션 중 첫 번째로 사용 가능한 공간을 할당해준다. 검색 시작은 집합의 시작에서부터 하거나, 지난 번에 검색이 끝났던 위치부터 시작할 수 있다.</p><blockquote><p>지난 번에 검색이 끝났던 위치부터 시작하는 경우를 <strong>Next-fit</strong>으로 구분하기도 한다. 이 방식을 사용하면 메모리가 한 쪽만 지나치게 사용되는 문제를 해결할 수 있다.</p></blockquote><h3 id="최적-적합-Best-fit"><a href="#최적-적합-Best-fit" class="headerlink" title="최적 적합 (Best-fit)"></a>최적 적합 (Best-fit)</h3><p>사용 가능한 공간들 중에서 가장 작은 것을 선택한다. 리스트가 크기 순서로 되어있지는 않으므로 모든 리스트를 탐색해야 하는 오버해드가 존재한다. 이 방식은 아주 작은 파티션을 만들어낸다.</p><h3 id="최악-적합-Worst-fit"><a href="#최악-적합-Worst-fit" class="headerlink" title="최악 적합 (Worst-fit)"></a>최악 적합 (Worst-fit)</h3><p>가장 큰 가용 공간을 선택한다. 마찬가지로 리스트가 크기 순서로 정렬되어있지 않다면 모두 탐색해야 한다. 이 방식은 남게 되는 공간이 비교적 클 확률이 높다.</p><blockquote><p>이 세 가지 방식 중 어떤 것이 더 낫다는 이론적으로 확정할 수는 없지만 모의 실험을 해봤을 때, 시간과 메모리 이용 효율 측면에서 최악 적합이 가장 안 좋았고, 최초 적합과 최적 적합이 공간 효율성은 비슷했지만 속도 면에서 최초 적합이 더 빠르게 나타났다고 한다.</p></blockquote><hr><h1 id="Non-Continuous-Memory-Allocation"><a href="#Non-Continuous-Memory-Allocation" class="headerlink" title="Non-Continuous Memory Allocation"></a>Non-Continuous Memory Allocation</h1><p>어떻게 하면 외부 단편화 문제를 완화할 수 있을까? 가변 분할 방식에서 외부 단편화는 프로세스가 메모리에 적재 되었다가, 빠지는 과정을 반복하면서, 불연속적인 공간이 남는 것으로 인해 발생했다. 그렇다면, 이런 불연속한 부분을 사용 중인 영역을 밀어 올려 없애는 걸 생각해볼 수 있을 것 같다. 이 방식을 <code>Storage Compaction</code>(메모리 압축)이라고 한다. 프로세스 처리에 필요한 적재 공간을 확보해야 할 때 사용할 수 있다. 예를 들어서, 위 테이블을 재배치 하면 다음과 같이 변경된다.  </p><p><img src="/images/2021-09-09-memory-allocation-and-mapping/04.png?style=centerme"></p><p>그러나 이 방식은, 프로세스를 모두 중지 해야 하고, 많은 시스템 자원을 소비하는 방식이다.<br>이 문제를 해결하는 다른 접근 방식은 한 프로세스의 논리 주소 공간을 여러 비연속적인 공간으로 나눠 필요한 크기의 공간을 사용할 수 있을때 메모리에 할당해주는 방식이다. 이를 <code>Non-Continuous Memory Allocation</code>이라고 한다. 정확하게는, 사용자 프로그램을 여러개의 블록으로 분할하고, <code>swap-device</code>에 모두 두고, 실행시 필요한 블록만 메인 메모리에 적재하는 방식이다. 이를 구현한 방식이 페이징(<code>Paging</code>)과 세그먼테이션(<code>Segmentation</code>)이다. 두 방식은 결합되어 사용될 수도 있다</p><h2 id="Address-Mapping"><a href="#Address-Mapping" class="headerlink" title="Address Mapping"></a>Address Mapping</h2><p>Address Mapping은, 연속 할당 방식에서는, 상대 주소를 물리 주소로 “재배치”하는 작업을 뜻했다. 불연속 메모리 할당 방식에서는 <code>Virtual Address</code> (가상 주소) 개념이 등장한다. 이는 연속 메모리 할당 방식의 “상대 주소”와 같다고 볼 수 있다. <code>Real Address</code>는 물리 주소와 같은 소리이고, 실제 메모리 주소를 뜻한다. 불연속 메모리 할당 방식의 메모리 매핑은 가상 주소를 실제 주소로 바꿔주는 과정이다.  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[User process의 Virtual Address] -&gt; (Address Mapping) -&gt;[Real Address]</span><br></pre></td></tr></table></figure><blockquote><p>논리적, 가상적의 뉘앙스의 메모리는 프로그램이 가지고 있는 연속을 가정한 가상의 주소 형태라고 볼 수 있다. 대체적으로, <strong>시작점을 찾을 수 있는 단서</strong>와 <strong>시작점으로부터 얼마나 많이 떨어져 있는가</strong>와 같은 튜플로 구성된다. 물리적, 실제의 뉘앙스의 메모리는 메인 메모리의 위치이다.  </p></blockquote><h3 id="Block-Mapping"><a href="#Block-Mapping" class="headerlink" title="Block Mapping"></a>Block Mapping</h3><p>사용자 프로그램을 블록 단위로 분할하고 관리하는 시스템에서의 매핑 방식이다. 가상 주소를 <strong>블록 숫자</strong>와 얼마나 <strong>시작점에서 떨어져있는지</strong>에 대한 정보를 가지고 표현한다.  </p><p>즉, <code>V = (b, d)</code>로 표현하는데, <code>b</code>는 <code>block number</code>를 뜻하고, <code>d</code>는 <code>displacement</code>를 의미한다.  </p><blockquote><p><code>displacement</code>는 쉽게 말해 <code>offset</code>이다. <code>block number</code>로부터 블록의 실제 메모리 주소를 가지고, 해당 Instruction이 시작점으로부터 얼마나 떨어진 명령인지 알려주는 역할을 한다.  </p></blockquote><p>Address Mapping 정보는  <code>Block Map Table</code>(<code>BMT</code>)에서 관리된다. 프로세스마다 하나의 <code>BMT</code>를 커널 공간에 가지고 있다. <code>BMT</code>가 관리하는 정보는 대략 다음과 같다.  </p><p><img src="/images/2021-09-09-memory-allocation-and-mapping/05.png?style=centerme"></p><blockquote><p><code>residence bit</code>는 해당 블록이 메모리에 올라간 상태인지를 나타내주는 비트이다.  </p></blockquote><p><code>V = (b, d)</code>로 표현되면, 먼저 <code>BMT</code>에서 <code>b</code>에 해당하는 열을 찾는다. 해당 열에서는 블록이 메모리에 적재된 상태인지 아닌지 확인 후, 적재된 상태라면 <code>Real Address</code>를 받아와서 <code>d</code>와 함께 명령어 주소를 찾는다. 적재되지 않은 상태라면 해당 블록을 메모리에 올리고 <code>BMT</code>를 업데이트 하고 <code>Real Address</code>를 받아와 명령어 주소를 계산한다.<br>사용자 프로그램을 여러 개의 블록으로 분할하고, <code>swap-device</code>에 모두 두고, 실행 시 필요한 블록만 메인 메모리에 적재하는 방식이다.  </p><blockquote><p>이 방식은 구체적인 구현이라기 보단, <code>Non-continuous Memory Allocation</code>에서 주로 사용하는 메모리 매핑 방법이다. 이후, 구체적으로 페이징 방식이나, 세그먼테이션 방식에서 어떻게 주소를 찾아주는지 나온다.</p></blockquote><hr><h2 id="Paging-System"><a href="#Paging-System" class="headerlink" title="Paging System"></a>Paging System</h2><p>프로그램을 같은 크기의 블록으로 분할하는 방식이다. 나누어진 블록을 <code>Page</code>(페이지)라고 부르고, 메모리의 분할 영역을 <code>Page Frame</code>(페이지 프레임)이라고 부른다. 페이지와 페이지 프레임은 같은 크기이다. 프로세스는 분할된 페이지로 나눠져 예비 저장 장치 또는 파일 시스템에 놓여진다. 나눠진 페이지 중 사용되는 페이지를 메모리에 올리는 방식이다.  </p><blockquote><p>교과서와 다르게, 강의에서는 예비 저장 장치, 파일 시스템은 <code>Secondary Storage</code> / <code>Swap Device</code>로 지칭되었는데 같은 의미로 봐도 될 것 같다.  </p></blockquote><p>우선 가장 큰 특징은 논리적 분할이 아니라 크기에 따른 분할이다. 이러한 특징으로 인해, 이후 세그먼테이션에서 확인할 수 있겠지만, 페이지 공유나 보호 과정이 복잡하다. 그러나 단순한 설계 방식으로 효율적으로 관리할 수 있다. 또한 외부 단편화는 발생할 수 없지만, 내부 단편화는 발생할 수 있다.  </p><blockquote><p>OSX의 기본 페이지 사이즈는 4096Bytes인 것 같다. <code>vm_stat</code> 명령어로 터미널에서 현재 가상 메모리 상태를 확인할 수 있다. 나타내는 구체적인 정보는 <a href="https://www.oreilly.com/library/view/mac-os-x/0596003560/ch08s01s05.html">이 링크</a>에서 확인할 수 있다.</p></blockquote><p><img src="/images/2021-09-09-memory-allocation-and-mapping/vmstat.png?style=centerme" alt="vm_stat 명령어 결과"></p><h3 id="Address-Mapping-1"><a href="#Address-Mapping-1" class="headerlink" title="Address Mapping"></a>Address Mapping</h3><p>위의 블록 매핑 방식과 유사하다. 블록이라는 이름 대신 페이지를 사용하는 것이라고 볼 수 있다. 가상 주소를 다음과 같이 표현할 수 있다.   </p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">V = (p, d)</span><br><span class="line">p: page number</span><br><span class="line">d: displacement</span><br></pre></td></tr></table></figure><p>위 정보와 함께, 물리 주소를 찾기 위해 페이지 <code>PMT</code>(<code>Page Map Table</code>)를 사용한다. 페이지 테이블은 대략 다음과 같이 생겼다.  </p><p><img src="/images/2021-09-09-memory-allocation-and-mapping/06.png?style=centerme"></p><p>페이지 맵 테이블은 커널 안에(메모리 안에) 있다. 다음과 같은 프로세스를 따른다고 볼 수 있다.  </p><ol><li>프로세스의 PMT가 저장된 주소 <code>b</code>에 접근</li><li>PMT에서 page p의 엔트리를 찾는다. (<code>b + p * entrySize</code>)</li><li>찾아진 entry의 <code>residence bit</code> 검사<ol><li><code>residence bit == 0</code>인 경우, <code>page fault</code>라고 부른다.<pre><code> swap device에서 해당 page를 메모리에 적재하고 PMT를 갱신 후 3-2 수행 이 과정은 컨텍스트 스위칭이 발생하고, 오버해드가 크다.</code></pre></li><li><code>residence bit == 1</code>인 경우, 해당 entry에서 <code>page frame number</code> p’를 확인</li></ol></li><li>p’의 가상 주소의 <code>d</code>를 사용해 실제 주소 <code>r</code>을 만든다. (<code>r = p&#39; * pageSize + d</code>)</li></ol><hr><p>지금까지 소개한 방법은 <code>Directed Mapping</code>이라는 이름으로 불린다. 커널 위의 매핑 테이블을 메모리에서 찾아오는 방식인데, 이 방식에서는 한 가지 문제점이 있다. 실제 주소를 얻기까지 메모리 접근을 두 번 해야한다는 것이다. 첫 번째는 <code>PMT</code>에 접근하기 위해서, 두 번째는 실제 메모리에 접근하기 위해서. 이 문제를 해결하기 위해서 <code>Associative Mapping</code>이라는 방법을 사용하는데, 간단히 말해서 <code>TLB</code>를 사용하는 방식이다.  </p><p><code>TLB</code>(Translation Look-aside Buffer)라는 특수한 캐시 하드웨어를 사용해, 이곳에 <code>PMT</code>를 적재하는 방식이다. <code>TLB</code>는 <code>page number</code>를 받으면, 페이지 테이블을 병렬적으로 탐색해 굉장히 빠르게 <code>page frame number</code>를 가져올 수 있다. 다만, <code>TLB</code>는 아주 비싸기 때문에, 작은 크기이다. 따라서, 큰 <code>PMT</code>를 다루기는 어렵다. 따라서, 일반적으로 <code>PMT</code>와 <code>TLB</code>를 함꼐 사용한다. <code>PMT</code>는 그대로 메모리 공간에 올려두고, <code>PMT</code> 일부만 <code>TLB</code>에 올리는 방식이다.  </p><p><img src="/images/2021-09-09-memory-allocation-and-mapping/07.png?style=centerme"></p><p>만약 찾고자 하는 Page가 <code>TLB</code>에 없다면, <code>PMT</code>에서 가져와야 한다. 이때, 이미 <code>TLB</code>가 모두 차있다면, 대체해야 하는데 이 정책 중 일반적인 것이 최근에 가장 적게 사용된 엔트리를 빼는 것이다. 이는 메모리 지역성과 유관하다.  </p><h2 id="Segmentation"><a href="#Segmentation" class="headerlink" title="Segmentation"></a>Segmentation</h2><p>페이징 시스템은 논리적 단위가 아닌, 크기에 따라 프로세스를 나누기 때문에, 페이징을 공유하고 보호하는 것에서 어려움이 있다. 세그멘테이션 시스템은 프로세스를 논리적 블록으로분할한다. 즉, 프로그래머가 생각하는 모양대로 메모리를 분할해 적재해준다. 따라서, 블록의 크기는 서로 다를 수 있고 페이징 시스템에서 처럼 메모리를 미리 분할할 수도 없다.  </p><p>이 방식은 내부 단편화가 발생할 일이 없지만, 외부 단편화는 발생할 수 있다. 또한 세그멘트를 공유하거나 보호하는 작업을 하기 쉽지만, Address Mapping이나, 메모리 관리에서 오버헤드가 비교적 크다.  </p><h3 id="Address-Mapping-2"><a href="#Address-Mapping-2" class="headerlink" title="Address Mapping"></a>Address Mapping</h3><p>Non-continuous Allocation 방식의 Address Mapping의  방식과 마찬가지로, 가상 주소를 다음과 같이 표현한다.  </p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">V = (s, d)</span><br><span class="line">s: segment-number</span><br><span class="line">d: displacement (offset)</span><br></pre></td></tr></table></figure><p>페이징 시스템에서 사용한 것처럼 <code>SMT</code>(Segment Map Table)라는 매핑 테이블을 사용한다. 매커니즘도 <code>PMT</code>와 유사하다. <code>PMT</code>와 비교하자면, <code>segment length</code>와 <code>protection bits</code>가 추가되어있다.  </p><p><img src="/images/2021-09-09-memory-allocation-and-mapping/08.png?style=centerme"></p><p>위와 같은 형태라고 볼 수 있는데, 추가된 두 필드는 다음과 같은 역할을 한다.  </p><ul><li><code>segment length</code>: 세그먼트의 크기를 기록한다. 실제 주소를 찾을때, 세그먼트 사이즈를 초과해 접근하지 않도록 만들어준다.</li><li><code>protection bits</code>: 세그먼트(예를 들어 함수나 데이터)에 대한 프로세스의 권한을 적는다.</li></ul><blockquote><p>읽기: R / 쓰기: W / 실행: X / 추가: A 비트가 있다고 한다. 위에서는 추가된 두 필드라고는 하지만, 실제로 페이징 시스템에도 <code>protection bits</code>는 있는 것으로 설명한다.</p></blockquote><hr><p>매핑을 할때는 다이렉트 매핑 과정을 거친다.  </p><ol><li><code>V = (s, d)</code>와 함께 <code>SMT</code>가 저장된 주소 <code>b</code>에 접근해 필요한 entry를 계산해낸다. (<code>b + s * entrySize*</code>)</li><li><code>SMT</code>의 entry에 대해 다음 단계를 순차적으로 수행한다.<ol><li><code>residence bit</code>가 0인 경우 (<strong>segment fault</strong>), <code>swap-device</code>로부터 해당 segment를 메모리에 적재하고, <code>SMT</code>를 갱신한다.</li><li><code>d</code>가 <code>segment length</code>의 길이보다 크다면, <strong>segment overflow exception</strong> 처리 모듈을 호출한다.</li><li><code>protection bits</code>를 확인해, 허가 되지 않은 연산인 경우 <strong>segment protection exception</strong> 처리 모듈을 호출한다.</li></ol></li><li>실제 주소 <code>r</code>을 찾아 명령어를 처리한다.</li></ol><blockquote><p>Paging System에서 처럼 TLB를 사용해서 메모리에 두 번 접근하는 오버헤드를 줄일 수 있다.  </p></blockquote><h3 id="Memory-Manangement"><a href="#Memory-Manangement" class="headerlink" title="Memory Manangement"></a>Memory Manangement</h3><p><code>VPM</code>과 유사하게, 세그먼트를 적재할 때, 그 크기에 맞춰 동적으로 메모리를 분할한 후 적재한다. 이를 관리하는 <strong>파티션 테이블</strong>이 요구된다. 아래 구성과 같이 파티션 테이블을 관리한다.  </p><p><img src="/images/2021-09-09-memory-allocation-and-mapping/09.png?style=centerme"></p><hr><h2 id="Hybrid-System"><a href="#Hybrid-System" class="headerlink" title="Hybrid System"></a>Hybrid System</h2><p>페이징 시스템과 세그멘테이션 시스템의 장점을 결합한 시스템이다. 프로그램을 다음과 같이 분할한다.  </p><ol><li>논리 단위의 Segment로 분할</li><li>각 Segment를 고정된 크기의 Page들로 분할</li></ol><p>메모리에 적재할 때는 페이지 단위로 적재하게 된다.</p><h3 id="Address-Mapping-3"><a href="#Address-Mapping-3" class="headerlink" title="Address Mapping"></a>Address Mapping</h3><p>가상 주소는 다음과 같은 형태로 주워진다.</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">V = (s, p, d)</span><br><span class="line">s: segment number</span><br><span class="line">p: page number</span><br><span class="line">d: offset</span><br></pre></td></tr></table></figure><p>매핑을 위해 <code>SMT</code>와 <code>PMT</code>를 모두 사용해야 한다. 각 <strong>프로세스마다</strong> 하나의 <code>SMT</code>가 존재하고, 하나의 <strong>세그먼트마다</strong> 하나의 <code>PMT</code>를 갖는 구조이다. <code>SMT</code> 테이블은 마지막에 실제 주소 대신, <code>PMT</code>의 베이스 주소를 알려준다. 아래는 하이브리드 시스템에서의 <code>SMT</code>이다.  </p><p><img src="/images/2021-09-09-memory-allocation-and-mapping/10.png?style=centerme"></p><p>이전 <code>SMT</code>테이블과 다른 모습은, 첫 번째로 <code>resident bit</code>가 없다는 점이다. 실제 메모리에 올라가는 것은 Page이기 때문에 <code>residence bit</code>는 불필요하다. 두 번째는, 위에서 언급한 것처럼 실제 주소를 매핑하고 있지 않고, 해당 세그먼트의 <code>PMT</code> 메모리 주소를 매핑한다.  </p><p><code>PMT</code>는 페이징 시스템에서 봤던 것과 동일한 모습이다.</p><p><img src="/images/2021-09-09-memory-allocation-and-mapping/11.png?style=centerme"></p><p>이런 형태의 테이블 구조로, 아래와 같이 프로세스를 나눈다.</p><p><img src="/images/2021-09-09-memory-allocation-and-mapping/12.png?style=centerme"></p><p>아래는 다이렉트 매핑 방식에서의 메모리 매핑 플로우이다.</p><p><img src="/images/2021-09-09-memory-allocation-and-mapping/13.png?style=centerme"></p><p>이런 시스템을 사용했을 때, 실제 메모리에 접근하는 것을 포함해서 <strong>세 번을</strong> 접근해야 한다. 또한, 테이블 수도 증가하므로, 메모리 소모도 비교적 커지고, 매핑 과정 자체가 길어진다.  </p><blockquote><p>이런 오버헤드가 있지만, 사용함으로써 얻는 장점이 크기 때문에 사용되는 것이라고 볼 수 있다고 한다. Page sharing, protection에 강점이 있고, 메모리 할당 및 관리에 드는 오버헤드가 작다.</p></blockquote><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://www.youtube.com/playlist?list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN">https://www.youtube.com/playlist?list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN</a></li><li>운영체제 교과서</li></ul>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/os/">os</category>
      
      
      <category domain="https://changhoi.kim/tags/cs/">cs</category>
      
      <category domain="https://changhoi.kim/tags/memory/">memory</category>
      
      
      <comments>https://changhoi.kim/posts/os/memory-allocation-and-mapping/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>HTTPS 설명하기</title>
      <link>https://changhoi.kim/posts/backend/https-dive/</link>
      <guid>https://changhoi.kim/posts/backend/https-dive/</guid>
      <pubDate>Thu, 12 Aug 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;HTTPS를 잘 이해해보자. HTTP는 TCP 연결 이후 평문으로 요청을 전달한다. 즉, 중간에 탈취되었을 때 내용이 모두 노출된다는 것이다. 이런 문제를 해결하기 위해서 HTTPS를 사용한다. 어떻게 암호화 하는 건지 정리해봤다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>HTTPS를 잘 이해해보자. HTTP는 TCP 연결 이후 평문으로 요청을 전달한다. 즉, 중간에 탈취되었을 때 내용이 모두 노출된다는 것이다. 이런 문제를 해결하기 위해서 HTTPS를 사용한다. 어떻게 암호화 하는 건지 정리해봤다.</p><span id="more"></span><p>HTTP Over Secure Socket Layer 의 약자이다. 평문을 암호화 해서 보내는 것이 핵심 기술이다. 여기에 사용되는 방식은 비대칭키, 대칭키 암호화 방식이 사용된다.</p><h2 id="비대칭키-공개키-암호-방식"><a href="#비대칭키-공개키-암호-방식" class="headerlink" title="비대칭키 (공개키 암호 방식)"></a>비대칭키 (공개키 암호 방식)</h2><p>공개키 암호화 방식이라고도 하는 비대칭키 방식은, 두 개의 키를 가지고 암호화 및 복호화가 이루어진다. 하나는 공개키, 다른 하나는 비밀키라고 불린다. 공개키는 누구나 알아도 되지만, 비밀키는 소유자만이 알고 있어야 한다. 공개키 암호 방식은 두 가지 역할을 할 수 있다. 첫 번째는 암호화, 두 번째는 인증이다. 암호화는 암호화 방식이라는 이름에 맞게, 컨텐츠를 암호화 하고, 그 내용을 특정 사람만 확인할 수 있게 하는 방식이다. 공개키로 암호화 한 내용은 개인키로 복호화 할 수 있고, 개인키로 암호화 한 내용은 공개키로 복호화 할 수 있다. 인증은 해당 내용을 특정 대상이 맞음을 확인하는 것이다. 비밀키로 암호화 한 내용은 공개키로만 복호화 가능하기 때문에, 이 내용을 특정인이 보냈음을 확신할 수 있다. 이 두 가지 기능이 HTTPS에서 모두 적절하기 잘 활용된다.</p><blockquote><p>대칭키 방식은 암호화 하는 키와 복호화 하는 키가 같다.</p></blockquote><h2 id="인증"><a href="#인증" class="headerlink" title="인증"></a>인증</h2><p>HTTPS에서 인증이란, 자신이 받은 정보가, 올바른 사람이 전송한 것이 맞는지 확인하는 것을 인증이라고 할 수 있다. 공개키 방식은 누구나 공개키를 획득할 수 있기 때문에, 비밀키로 암호화한 정보는 암호화의 의미가 없다. 그러나 비밀키로 암호화한 정보를 공개키로 복호화 할 수 있다는 것은, 다시 말해 암호화 한 주체가 틀림없이 비밀키를 가지고 있음을 인증한다고 말할 수 있다. 이것이 “인증서”의 원리이다.</p><p><img src="/images/2021-08-13-https-dive/02.png?style=centerme"></p><h3 id="SSL-인증서"><a href="#SSL-인증서" class="headerlink" title="SSL 인증서"></a>SSL 인증서</h3><p>인증서는 다음 두 가지 역할을 하게 된다.</p><ol><li>클라이언트가 접속한 서버가 신뢰할 수 있는 서버임을 보장한다.</li><li>SSL 통신에 사용할 공개키를 클라이언트에게 제공한다.</li></ol><h3 id="CA-Certificate-Authority"><a href="#CA-Certificate-Authority" class="headerlink" title="CA (Certificate Authority)"></a>CA (Certificate Authority)</h3><p>클라이언트가 접속한 서버가 클라이언트가 의도한 서버가 맞는지를 보장하는 역할을 하기 위해서, 특정 민간 기업이 이 역할을 해준다. 이런 기업들을 CA, 혹은 Root Certificate라고 한다. 이 CA는 브라우저에 탑재되어 있다. 브라우저는 CA의 리스트와 함께 인증서를 복호화 하기 위한 CA의 공개키를 가지고 있다.</p><blockquote><p>사설 인증 기관<br>개발이나 사적인 목적을 위해, SSL의 암호화 기능을 이용할 때, 직접 CA 역할을 할 수 있다. 이 경우에는 브라우저가 경고를 표시한다.</p></blockquote><h3 id="서비스의-보증"><a href="#서비스의-보증" class="headerlink" title="서비스의 보증"></a>서비스의 보증</h3><p>인증서 안에는 다음과 같은 내용이 포함되어있다.</p><ul><li>서비스의 정보(CA, 서비스 도메인 등)</li><li>서버의 공개키 (공개키 내용 및 암호화 방법 등)</li></ul><p>브라우저는 처음 서버에 접근할 때, 인증서를 받게 되고, 해당 인증서가 공인된 (브라우저에 저장된) CA 리스트 안에 있는 회사의 인증서임을 확인한다면, 알고 있는 공개키로 인증서를 복호화한다. 복호화가 가능하다는 것은 해당 인증서를 발급한 기관이 틀림 없이 보증된 회사임을 증명하는 것이다.</p><p>그렇다면 이제 브라우저는 위 “서비스의 정보”와 “서버의 공개키”가 생겼다. 이제 브라우저는 서버의 공개키를 통해 HTTP 평문을 암호화 할 수 있게 되었다. 이하 내용은 구체적으로 SSL이 어떻게 동작하게 되는 것인지를 담고 있다.</p><h2 id="SSL-동작"><a href="#SSL-동작" class="headerlink" title="SSL 동작"></a>SSL 동작</h2><p>실제로는 HTTP 내용을 비대칭키 방식으로 데이터를 암호화 하는 것이 아니다. 공개키 방식으로 암, 복호화 하는 과정은 컴퓨팅 파워의 소비가 필요하기 때문에, 실제 내용은 비교적 컴퓨팅 파워가 덜 소모되는 대칭키를 통해  암, 복호화 하게 된다.</p><p>우선 서버와 클라이언트가 연결되면서, Handshake 과정을 거치게 된다. 다음과 같은 과정을 지난다.</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/1/14/Abbreviated_TLS_1.2_Handshake.svg?style=centerme"></p><ol><li><p>Client Hello<br> 클라이언트가 서버에 접속하고 다음 정보를 가져온다.</p><ul><li>클라이언트에서 생성한 랜덤 데이터</li><li>클라이언트가 지원하는 암호화 방식: 클라이언트와 서버측이 사용할 암호화 방식에 대한 협상을 위해 클라이언트가 사용 가능한 암호화 방식을 전송한다.</li><li>세션 아이디: 이미 SSL Handshaking이 이루어진 상태라면, 기존 세션을 재활용하게 된다. 이때 사용할 세션 아이디를 서버에 전송한다.</li></ul></li><li><p>Server Hello<br> 서버는 클라이언트 Hello를 받고 다음 응답을 보내준다.</p><ul><li>서버측에서 생성한 렌덤 데이터</li><li>서버가 선택한 클라이언트 암호방식: 클라이언트가 전달한 암호화 방식 중, 서버에서도 사용할 수 있는 암호화 방식을 선택해 클라이언트로 전달한다.</li><li>인증서</li></ul></li><li><p>클라이언트가 가지고 있는 CA 리스트에서 인증서를 확인한다. CA 리스트 중에 있다면, 가지고 있는 해당 CA의 공개키를 통해 복호화한다.<br> 클라이언트는 서버의 랜덤 데이터와 클라이언트의 랜덤 데이터를 조합해 <code>pre master secret</code>이라는 키를 생성한다. 이 키는 이후 데이터를 암호화 하기 위해 사용된다. 위에서 언급했듯, 데이터를 암호화 하는 기법은 대칭키이므로 외부에 노출되어선 안된다.<br> 이제 만든 <code>pre master secret</code>을 전달해야 한다. 이 값을 안전하게 전달하기 위해서 인증서에서 획득한 공개키로 암호화해 서버로 전송하게 된다. </p></li><li><p>서버는 <code>pre master secret</code>을 개인키로 복호화한다. 이제 클라이언트와 서버 모두 <code>pre master secret</code> 키 값을 가지고 있는데, 일련의 과정을 통해 <code>master secret</code>을 만든다. 그리고 이 키값을 통해 세션 키를 만들게 된다. 이 세션 키를 이용해 서버와 클라이언트는 데이터를 대칭키 방식으로 암호화한 후 주고 받는다. </p></li><li><p>클라이언트와 서버는 핸드쉐이크 단계의 종료를 서로에게 알린다.</p></li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://brunch.co.kr/@sangjinkang/38">https://brunch.co.kr/@sangjinkang/38</a></li><li><a href="https://commons.wikimedia.org/wiki/File:Full_TLS_1.3_Handshake.svg">https://commons.wikimedia.org/wiki/File:Full_TLS_1.3_Handshake.svg</a></li><li><a href="https://opentutorials.org/course/228/4894">https://opentutorials.org/course/228/4894</a></li><li><a href="https://ko.wikipedia.org/wiki/%EB%8C%80%EC%B9%AD_%ED%82%A4_%EC%95%94%ED%98%B8">https://ko.wikipedia.org/wiki/%EB%8C%80%EC%B9%AD_%ED%82%A4_%EC%95%94%ED%98%B8</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://changhoi.kim/categories/backend/">backend</category>
      
      
      <category domain="https://changhoi.kim/tags/cs/">cs</category>
      
      
      <comments>https://changhoi.kim/posts/backend/https-dive/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
